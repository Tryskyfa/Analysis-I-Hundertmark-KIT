\documentclass[11pt, twoside, a4paper]{article}

% Setup
\usepackage[margin=2.4cm, top=3.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}

% Package imports
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{setspace}
\usepackage{float}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[pagestyles]{titlesec}
\usepackage{fancyhdr}
\usepackage{colonequals}
\usepackage{caption}
\usepackage{tikz}
\usepackage{marginnote}
\usepackage{etoolbox}
\usepackage{mdframed}
\usepackage{aligned-overset}

% Font-Encoding
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Theorems
\newtheorem{blockelement}{Blockelement}[subsection]
\newtheoremstyle{plain}{}{}{}{}{\bfseries}{.}{ }{}
\theoremstyle{plain}
\newtheorem{bemerkung}[blockelement]{Bemerkung}
\newtheorem{definition}[blockelement]{Definition}
\newtheorem{lemma}[blockelement]{Lemma}
\newtheorem{satz}[blockelement]{Satz}
\newtheorem{notation}[blockelement]{Notation}
\newtheorem{korollar}[blockelement]{Korollar}
\newtheorem{uebung}[blockelement]{Übung}
\newtheorem{beispiel}[blockelement]{Beispiel}
\newtheorem{folgerung}[blockelement]{Folgerung}
\newtheorem{axiom}[blockelement]{Axiom}
\newtheorem{beobachtung}[blockelement]{Beobachtung}
\newtheorem{konzept}[blockelement]{Konzept}
\newtheorem{visualisierung}[blockelement]{Visualisierung}
\newtheorem{anwendung}[blockelement]{Anwendung}

% Marginnotes left
\makeatletter
\patchcmd{\@mn@@@marginnote}{\begingroup}{\begingroup\@twosidefalse}{}{\fail}
\reversemarginpar
\makeatother

% Long equations
\allowdisplaybreaks

% \left \right
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pair}[1]{\left(#1\right)}
\newcommand{\of}[1]{\left(#1\right)}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\linterv}[1]{\left[#1\right)}
\newcommand{\rinterv}[1]{\left(#1\right]}
\newcommand{\interv}[1]{\left[#1\right]}
\newcommand{\sprod}[1]{\left<#1\right>}

% Shorten commands
\newcommand{\equivalent}[0]{\Leftrightarrow{}}
\newcommand{\impl}[0]{\Rightarrow{}}
\newcommand{\fromto}{\rightarrow{}}
\newcommand{\definedas}[0]{\coloneqq}
\newcommand{\definedasbackwards}[0]{\eqqcolon}
\newcommand{\definedasequiv}[0]{\ratio\Leftrightarrow{}}
\newcommand{\exclude}[0]{\setminus}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\sbset}{\subseteq}

\newcommand{\ntoinf}[0]{n\fromto\infty}
\newcommand{\toinf}{\fromto\infty}
\newcommand{\fa}{\;\forall\,}
\newcommand{\ex}{\;\exists\,}
\newcommand{\conj}[1]{\overline{#1}}

\newcommand{\annot}[3][]{\overset{\text{#3}}#1{#2}}
\newcommand{\biglim}[1]{{\displaystyle \lim_{#1}}}
\newcommand{\nn}[0]{\\[2\baselineskip]}
\newcommand{\anf}[1]{\glqq{}#1\grqq}
\newcommand{\OBDA}{o.B.d.A. }
\newcommand{\theoremescape}{\leavevmode}
\newcommand{\aligntoright}[2]{\hfill#1\hspace{#2\textwidth}~}
\newcommand{\horizontalline}[0]{\par\noindent\rule{0.05\textwidth}{0.1pt}\\}
\newcommand{\rgbcolor}[3]{rgb,255:red,#1;green,#2;blue,#3}

\let\Re\relax
\let\Im\relax

% MathOperators
\DeclareMathOperator{\grad}{Grad}
\DeclareMathOperator{\bild}{Bild}
\DeclareMathOperator{\Re}{Re}
\DeclareMathOperator{\Im}{Im}

% Mengenbezeichner
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}

\newcommand\imaginarysubsection[1]{
    \refstepcounter{subsection}
    \subsectionmark{#1}
}

% Unfassbar hässlich, aber effektiv für temporäre schnelle Lösungen
\def\:={\coloneqq}
\def\->{\fromto}
\def\=>{\impl}
\def\<={\leq}
\def\>={\geq}
\def\!={\neq}
\def\!={\neq}

% Envs
\newenvironment{induktionsanfang}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Anfang}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}
\newenvironment{induktionsschritt}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Schritt}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}

% Section style
\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\large\bfseries}

% Page styles
\newpagestyle{pagenumberonly}{
    \sethead{}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\newpagestyle{headfootdefault}{
    \sethead[][][\thesubsection~\textit{\subsectiontitle}]{\thesection~\textit{\sectiontitle}}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\pagestyle{headfootdefault}

\begin{document}
    \title{\vspace{3cm} Skript zur Vorlesung\\Analysis I\\bei Prof. Dr. Dirk Hundertmark}
    \author{Karlsruher Institut für Technologie}
    \date{Wintersemester 2023/24}
    \maketitle
    \begin{center}
        Dieses Skript ist inoffiziell. Es besteht kein\\ Anspruch auf Vollständigkeit oder Korrektheit.
    \end{center}
    \thispagestyle{empty}
    \newpage

    \tableofcontents
    ~\\
    Alle mit [*] markierten Kapitel sind noch nicht korrektur gelesen und bedürfen eventuell noch Änderungen.
    \newpage


    \section{Aussagenlogik}
    \input{Kapitel/Aussagenlogik}


    \section{Mengen}
    \input{Kapitel/Mengen}


    \section{Die Axiome der reellen Zahlen}
    \input{Kapitel/Reelle_Zahlen}


    \section{Die natürlichen Zahlen $\N$ und vollständige Induktion}
    \input{Kapitel/Natuerliche_Zahlen}


    \section{Summe, Produkt, Wurzeln}
    \input{Kapitel/Summe_Produkt_Wurzeln}


    \section{Folgen und Grenzwerte}
    \input{Kapitel/Folgen_Grenzwerte}


    \section{Dichtheit von $\Q$ in $\R$}
    \input{Kapitel/Dichtheit}


    \section{[*] Reihen (und Konvergenz von Reihen)}
    \thispagestyle{pagenumberonly}

    Bedeutung von endlichen Summen ist klar.\\
    Frage: Gegeben eine reelle Folge $a_n$. Was ist $\pair{a_1 + a_2 + a_3 + \dots = \sum_{n=1}^{\infty} a_n}$?

    \subsection{[*] Konvergenz-Kriterien für Reihen}

    \begin{definition}[Reihen als Partialsummen] % Definition 1
        Das Symbol
        \begin{align*}
            \sum_{n=1}^{\infty} a_n\tag{Sei $a_n$ eine reelle Folge}
        \end{align*}
        wird folgendermaßen verwendet:

        \begin{enumerate}[label=\alph*)]
            \item Es steht für die Folge der Partialsummen:
            \begin{align*}
                s_n&\definedas \sum_{j=1}^{n} a_j\quad\forall n\in\N
            \end{align*}
            \item Die Reihe $\sum_{n=1}^{\infty} a_n$ konvergiert, falls der Grenzwert der Partialsummen $\lim_{n\fromto\infty} s_n$ existiert.\\
            Wir setzen
            \begin{align*}
                \sum_{n=1}^{\infty} a_n &\definedas \lim_{n\fromto\infty} s_n
            \end{align*}
            \item Konvergiert $(s_n)_n$ nicht, so heißt $\sum_{n=1}^{\infty} a_n$ divergent. Falls $s_n$ bestimmt divergiert so setzen wir
            \begin{align*}
                \sum_{n=1}^{\infty} a_n &\definedas \infty \tag{Wenn $\lim_{n\fromto\infty} s_n = \infty$}\\
                \sum_{n=1}^{\infty} a_n &\definedas -\infty \tag{Wenn $\lim_{n\fromto\infty} s_n = -\infty$}
            \end{align*}
        \end{enumerate}
    \end{definition}

    \begin{satz}[Monotone Konvergenz für Reihen] % Satz 2
        \label{satz:mont-konv-reihen}
        Sei $a_n$ eine reelle Folge mit $\forall n\colon a_n\geq 0$. Dann konvergiert die Reihe $\sum_{j=1}^{\infty} a_j$ genau dann, wenn die Folge der Partialsummen $s_n$ nach oben beschränkt ist.

        \begin{proof}
            Betrachte
            \begin{align*}
                s_{n+1} &= \sum_{j=1}^{n+1} a_j = \sum_{j=1}^n a_j + a_{n+1} \geq \sum_{j=1}^{n} a_j = s_n
            \end{align*}
            und wende Satz~\ref{satz:monoton-konv} an.
        \end{proof}
    \end{satz}

    \begin{korollar} % Korollar 3
        Für eine Reihe $\sum_{n=1}^{\infty} a_n$ mit $a_n\geq 0$ gilt entweder
        \begin{align*}
            \sum_{n=1}^{\infty} a_n < \infty\quad\text{oder}\quad\sum_{n=1}^{\infty} a_n = \infty
        \end{align*}

        \begin{proof}
            Folgt direkt aus Satz~\ref{satz:mont-konv-reihen}.
        \end{proof}
    \end{korollar}

    \begin{bemerkung}
        Oft hat man Reihen der Form
        \begin{align*}
            \sum_{n=0}^{\infty} a_n &= a_0+a_1+a_2+\dots\\
            s_n&\definedas \sum_{j=0}^{n} a_j \tag{$n\in\N_0$}
            \intertext{oder}
            s_n &\definedas a_0 + \sum_{j=1}^{\infty} a_j\tag{$n\in\N$}
            \intertext{Sofern ein Limes existiert, gilt dann}
            \sum_{n=0}^{\infty} a_n &\definedas \lim s_n\\[10pt]
            \intertext{Allgemein für $v\in\Z\quad a_v, a_{v+1}, a_{v+2}, \dots$}
            \sum_{n=v}^{\infty} a_n &= a_v + a_{v+1} + \dots\\
            s_n &\definedas \sum_{j=v}^{n} a_j\text{ def. Folge $(s_n)_{n\geq v}$}
        \end{align*}
    \end{bemerkung}

    \begin{beispiel}[Geometrische Folge und Reihe]
        \footnote{Wir setzen $0^0 = 1$}
        \begin{align*}
            q\neq 1 \impl \sum_{j=0}^{n} q^j = \frac{1-q^{n+1}}{1-q}\quad\forall n\in\N_0\\
            \text{Ist } \abs{q} < 1\colon \sum_{n=0}^{\infty} q^n\text{ konvergiert und } \sum_{n=0}^{\infty} q^n = \frac{1}{1-q}\tag{geometrische Reihe}
        \end{align*}
        Zum Beispiel $q=\frac{1}{2}$
        \begin{align*}
            \sum_{j=0}^{n} q^j &= \frac{1-q^{n+1}}{1-q}\\
            \equivalent \pair{1-q}\cdot \sum_{j=0}^{n} q^j &= 1-q^{n+1}\\
            \frac{1}{2}\sum_{j=0}^{n} \pair{\frac{1}{2}}^j &= 1 - \pair{\frac{1}{2}}^{n+1}\\
            \impl 1 - \pair{\frac{1}{2}}^{n+1} &= \sum_{j=0}^{n} \frac{1}{2}\cdot\pair{\frac{1}{2}}^j\\
            &= \sum_{j=0}^{n} \pair{\frac{1}{2}}^{j+1} = \sum_{j=1}^{n+1} \pair{\frac{1}{2}}^j
        \end{align*}
        Das heißt es sollte gelten
        \begin{align*}
            \sum_{j=1}^{n} \pair{\frac{1}{2}}^j &= 1-\pair{\frac{1}{2}}^n\quad \forall n\in\N
        \end{align*}

        \noindent Dass dieser Zusammenhang gelten muss, lässt sich einfach veranschaulichen. Die linke Seite der Gleichung kann als Summe über Teilflächen des Einheitsquadrats\footnote{Original: \anf{Kuchen}} visualisiert werden.\\
        Erst wird eine Hälfte, dann ein Viertel, dann ein Achtel (usw.) des Quadrats hinzugefügt. Der zurückbleibende Flächeninhalt ist immer genauso groß wie das zuletzt hinzugefügte Stück. Dieser Term wird durch den rechten Teil der Gleichung beschrieben.

        \begin{proof}[Beweis der Reihenformel]
            \begin{align*}
                s_n &\definedas \sum_{j=0}^{n} q^n\\
                q\cdot s_n &= q\cdot \sum_{j=0}^{n} q^j = \sum_{j=0}^{n} q^{j+1}\\
                &= \sum_{j=1}^{n+1} q^j\tag{Indexshift}\\
                \impl (1-q)\cdot s_n = s_n - q\cdot s_n &= \sum_{j=0}^{n}  q^j - \sum_{j=1}^{n+1} q^j\tag{Reißverschlusssumme}\\
                = q^0 - q^{n+1} &= 1 - q^{n+1}\\
                \impl s_n &= \frac{1-q^{n+1}}{1-q}\qedhere
            \end{align*}
        \end{proof}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 05. Dezember 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}[Beweis der Konvergenz für $\abs{q} < 1$]
            \marginnote{[5. Dez]}
            \begin{align*}
                s_n\definedas \sum_{j=0}^{n} q^j &= \frac{1-q^{n+1}}{1-q}\\
                \lim_{n\fromto\infty} q^n &= 0 = \lim_{n\fromto\infty} q^{n+1}\tag{Weil $\abs{q} < 1$}\\
                \annot{\impl}{\ref{satz:konvergenzsaetze}} \lim s_n &= \frac{1-\lim_{n\fromto\infty} q^{n+1}}{1-q} = \frac{1-0}{1-q} = \frac{1}{1-q}\qedhere
            \end{align*}
        \end{proof}
        \begin{bemerkung}
            Ist $\abs{q}\geq 1$, dann ist $1+\underbrace{q}_{\geq 1}+\underbrace{q^2}_{\geq 1}+\underbrace{q^3}_{\geq 1}+\dots + \underbrace{q^n}_{\geq 1} \geq 1+n\fromto\infty$.
        \end{bemerkung}
    \end{beispiel}

    % TODO: Wahrscheinlichkeitstheoretische Anschauung
    \newpage

    \begin{beispiel}[Harmonische Reihe]
        \begin{align*}
            s_n &\definedas \sum_{j=1}^{n} \frac{1}{j}
        \end{align*}
        $(s_n)_n$ ist monoton wachsend, aber nicht nach oben beschränkt. Das heißt $\lim_{n\fromto\infty} s_n = \infty \impl \sum_{n=1}^{\infty} \frac{1}{n} = \infty$.

        \begin{proof}
            \begin{align*}
                s_{2n} - s_n &= \sum_{j=n+1}^{2n} \frac{1}{j} \geq \sum_{j=n+1}^{n} \frac{1}{2n} = n \cdot\frac{1}{2n} = \frac{1}{2}\\
                \impl s_2 - s_1 &\geq \frac{1}{2}\\
                \impl s_2 &\geq s_1 + \frac{1}{2} = 1 + \frac{1}{2} > \frac{1}{2}\\
                s_4 - s_2 &\geq \frac{1}{2}\\
                \impl s_4 &\geq s_2 + \frac{1}{2} > \frac{1}{2} + \frac{1}{2} = 1\\
                s_8 - s_4 &\geq \frac{1}{2}\\
                \impl s_8 &\geq s_4 + \frac{1}{2} \geq \frac{3}{2}\\
                \annot{\impl}{Induktion} s_{\pair{2^j}} &> \frac{j}{2}\quad\forall j\in\N
            \end{align*}
            \noindent Also ist $s_{\pair{2^j}}$ nicht nach oben beschränkt $\impl$ $(s_n)_n$ nicht nach oben beschränkt.
            \begin{align*}
                \annot{\impl}{\ref{satz:monoton-konv}} \sum_{n=1}^{\infty} \frac{1}{n} = \lim_{n\fromto\infty} s_n &= +\infty\qedhere
            \end{align*}
        \end{proof}
    \end{beispiel}

    \begin{satz} % Satz 6
        Seien $\sum_{n=1}^{\infty} a_n$, $\sum_{n=1}^{\infty} b_n$ konvergente Reihen. Dann ist
        \begin{align*}
            \forall\lambda, \mu \in\R\colon \sum_{n=1}^{\infty} \pair{\lambda\cdot a_n + \mu\cdot b_n}
        \end{align*}
        konvergent und es gilt
        \begin{align*}
            \sum_{n=1}^{\infty} \pair{\lambda\cdot a_n + \mu\cdot b_n} = \lambda \cdot \sum_{n=1}^{\infty} a_n + \mu\cdot \sum_{n=1}^{\infty} b_n
        \end{align*}
        \begin{proof}
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} a_n \quad t_n \definedas \sum_{j=1}^{n} b_n\\
                d_n &\definedas \sum_{j=1}^{n} \pair{\lambda\cdot a_n + \mu\cdot b_n} =   \lambda \cdot \sum_{n=1}^{n} a_n + \mu\cdot \sum_{n=1}^{n} b_n\\
                &= \lambda\cdot s_n + \mu\cdot t_n \fromto \lambda\cdot s + \mu\cdot t\tag{Mit $s$ und $t$ als Limes}
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    \begin{satz}[Majoranten-Kriterium] % Satz 7
        \label{satz:majoranten-kriterium}
        Gegeben zwei Folgen $0\leq a_n \leq b_n~\forall n\in\N$. Konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} b_n\quad\text{so konvergiert auch}\quad\sum_{n=1}^{\infty} a_n
        \end{align*}
        und es gilt
        \begin{align*}
            0\leq \sum_{n=1}^{\infty} a_n \leq \sum_{n=1}^{\infty} b_n
        \end{align*}
        \begin{proof}
            \begin{align*}
                &s_n = \sum_{j=1}^{n} a_j\quad t_n = \sum_{j=1}^{n} b_j\\
                \impl &s_{n+1} = s_n + a_{n+1} \geq s_n\\
                &t_{n+1} = t_n + b_{n+1} \geq t_n\\
                \impl &(s_n)_n,~(t_n)_n\text{ sind monoton wachsend}\\
                \intertext{Mit der Konvergenz von $(t_n)_n$ und $(t_n)_n$ monoton wachsend folgt mit Satz~\ref{satz:mont-konv-reihen}}
                \impl &(t_n)_n\text{ ist beschränkt}\\
                \impl &\exists M\geq 0\colon t_n \leq M\quad\forall n\in\N\\
                0\leq a_n \leq b_n \impl &0\leq s_n \leq t_n \leq M \quad\forall n\in\N\\
                \impl &(s_n)_n\text{ ist nach oben beschränkt und monoton wachsend}\\
                \annot{\impl}{\ref{satz:mont-konv-reihen}} &\lim_{n\fromto\infty} s_n\text{ existiert }\\
                \quad s &\definedas \lim_{n\fromto\infty} s_n \leq \lim_{n\fromto\infty} t_n = \sum_{n=1}^{\infty} b_n\qedhere\\
                \intertext{Außerdem gilt:}
                t_n - s_n &= \sum_{j=1}^{n} b_j - \sum_{j=1}^{n} a_j = \sum_{j=1}^{n} n \pair{b_j-a_j} \geq 0
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Minoranten-Kriterium] % Satz 8
        Sei $0\leq b_n \leq a_n~\forall n\in\N$ und
        \begin{align*}
            \sum_{n=1}^{\infty} b_n &= \infty\\
            \impl \sum_{n=1}^{\infty} a_n&\text{ divergiert auch bestimmt gegen }\infty
        \end{align*}
        \begin{proof}
            \begin{align*}
                t_n &= \sum_{j=1}^{n} b_n \quad s_n = \sum_{j=1}^{n} a_n
                \intertext{Analog zum Beweis des Majoranten-Kriteriums gilt:}
                (s_n)_n,~(t_n)_n&\text{ sind monoton wachsend und }t_n \leq s_n \quad\forall n\in\N
                \intertext{Dann lässt sich folgern}
                \sum_{n=1}^{\infty} b_n = \infty &\equivalent (t_n)_n \text{ wächst über alle Grenzen}\\
                &\impl (s_n)_n\text{ wächst über alle Grenzen}\\
                &\impl \lim_{n\fromto\infty} s_n = \infty = \sum_{n=1}^{\infty} a_n\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Anwendung des Minoranten-Kriteriums]
        Es sei
        \begin{align*}
            a_n\geq \frac{c}{n}\quad\forall n\in\N\tag{$c>0$}
            \intertext{Nach Minorantenkriterium und der Divergenz der harmonischen Reihe gilt}
            \impl \sum_{n=1}^{\infty} a_n = \infty
        \end{align*}
    \end{beispiel}
    \begin{beispiel}[Anwendung des Majoranten-Kriteriums]
        Es sei wieder $c>0$. Dann folgt aus
        \begin{align*}
            0\leq a_n \leq c\cdot q^n\land 0\leq q < 1
            \intertext{nach Majoranten-Kriterium und dem Konvergenzkriterium der geometrischen Reihe, dass}
            \impl \sum_{n=1}^{\infty} a_n\text{ konvergiert}\tag{$b_n=c\cdot q^n$}
        \end{align*}
    \end{beispiel}

    \begin{bemerkung}[Abgeschwächtes Majoranten-Kriterium]
        Die Konvergenz/Divergenz von Reihen (und Folgen) ändert sich nicht, wenn man endlich viele Summanden (Folgeglieder) abändert.\\
        Für das Majoranten-Kriterium reicht also, dass $0\leq a_n \leq b_n$ für fast alle $n\in\N$, damit
        \begin{align*}
            \sum_{n=1}^{\infty} b_n\text{ konvergiert }\impl \sum_{n=1}^{\infty} a_n\text{ konvergiert}
        \end{align*}
        Das gleiche gilt analog für das Minoranten-Kriterium
    \end{bemerkung}

    \newpage

    \begin{satz}[Cauchyscher Verdichtungssatz] % Satz 9
        \label{satz:cauchy-verdichtung}
        Sei $(a_n)_n$ eine monoton fallende Nullfolge. Dann gilt
        \begin{align*}
            &\sum_{n=0}^{\infty} a_n\text{ konvergiert}\\
            \equivalent &\sum_{n=0}^{\infty} 2^n\cdot a_{\pair{2^n}}\text{ konvergiert}\tag{Verdichtete Reihe}
        \end{align*}
        \begin{proof}
            \anf{$\Leftarrow$} 1. Schritt. Zu zeigen: $a_n\geq 0\quad\forall n\in\N$.
            \begin{align*}
                a_n&\geq a_{n+1} \geq a_{n+2} \geq \dots \geq a_{n+l} \fromto 0\text{ für } l\fromto\infty\\
                \impl a_n &\geq 0\quad\forall n\in\N
            \end{align*}
            2. Schritt:
            \begin{align*}
                s_n &\definedas \sum_{j=0}^{n} a_j\\
                t_n &\definedas \sum_{\nu=0}^{n} 2^{\nu} \cdot a_{\pair{2^\nu}}
                \intertext{Jedes $\overline{n}\in\N$ können wir eindeutig schreiben als $\overline{n}=2^\nu + l$ mit $\nu\in\N_0,~0\leq l < 2^\nu$~\footnotemark.\endgraf \noindent Sei $1\leq n< 2^k$ für ein $k\in\N_0$}
                s_n &= \sum_{j=0}^{n} a_j = a_0 + \sum_{j=1}^{n} a_j\\
                &\leq a_0 + \sum_{j=1}^{2^k-1} a_j = a_0 + \sum_{\nu=0}^{k-1} \pair{\sum_{l=0}^{2^\nu - 1} \underbrace{a_{\pair{2^\nu + l}}}_{\leq a_{\pair{2^\nu}}}}\\
                &\leq a_0 + \sum_{\nu=0}^{k-1} \pair{\sum_{l=0}^{2^\nu-1} a_{\pair{2^\nu}}}\\
                &= a_0 + \sum_{\nu = 0}^{k-1} 2^{\nu}\cdot a_{\pair{2^\nu}}\\
                &= a_0 + t_{k-1}\\[10pt]
                \impl &\forall n < 2^k\text{ gilt }s_n\leq a_0 + t_{k-1}
            \end{align*}
            \footnotetext{Es lässt sich zeigen, dass $l$ und $\nu$ in diesem Fall eindeutig sind.}
            Angenommen
            \begin{align*}
                \sum_{\nu = 0}^{\infty} 2^{\nu} \cdot a_{2^\nu}\text{ konvergent} &\equivalent \lim_{n\fromto\infty} t_n = t\text{ existiert}\\
                &\impl s_n \leq a_0 + \lim_{k\fromto\infty} t_{k-1} = a_0 + t\quad\forall n\in\N
                \intertext{Somit ist $a_0 + l$ eine obere Schranke von $(s_n)_n$. Da $s_n\leq s_{n+1} \annot{\impl}{\ref{satz:monoton-konv}} \lim_{n\fromto\infty} s_n$ existiert}
                \impl \sum_{n=0}^{\infty} a_n&\text{ konvergent}
            \end{align*}
            \anf{$\impl$} Sei $n\geq 2^k$
            \begin{align*}
                s_n &= \sum_{j=0}^{n} a_j \geq \sum_{j=0}^{2^k} a_j\\
                &= \sum_{\nu=0}^{k} \pair{\sum_{l=0}^{2^\nu-1} \underbrace{a_{\pair{2^\nu + l}}}_{\geq a_{\pair{2^\nu+1}}}}\\
                &\geq \sum_{\nu=0}^{k} \pair{\sum_{l=0}^{2^\nu-1} a_{\pair{2^\nu+1}}} = \sum_{\nu=0}^{k} 2^{\nu}\cdot a_{\pair{2^\nu}} + 1\\
                &= \sum_{\nu = 1}^{k+1} 2^{\nu-1} a_{\pair{2^\nu}} = \frac{1}{2}\sum_{\nu=1}^{k+1} 2^{\nu} a_{\pair{2^\nu}}\\
                &= \frac{1}{2}\pair{\sum_{\nu=0}^{k+1} 2^\nu a_{\pair{2^\nu}} - a_0}\\
                &= t_{k+1} - a_0\\
                \impl t_k \leq t_{k+1} &\leq s_n + a_0\quad\forall 2^k \geq n\\
                \impl t_k &\leq \lim_{n\fromto\infty} s_n + a_0 = s + a_0 < \infty\\
                \text{sofern} \sum_{n=0}^{\infty} a_0\text{ konvergiert}
            \end{align*}
            Da $t_k < t_{k+1}$ konvergiert, konvergiert auch $\sum_{\nu=0}^{\infty} 2^\nu \cdot a_{2^\nu}$
        \end{proof}
    \end{satz}

    \begin{beispiel}[Cauchyscher Verdichtungssatz als Konvergenzkriterium]
        Es sei
        \begin{align*}
            a_n &= \frac{1}{n^\alpha}\\
            2^{n} \cdot a_{\pair{2^\nu}} &= \frac{2^n}{(2^n)^\alpha} = \frac{2^n}{2^{n\cdot\alpha}}\\
            &= 2^{n-n\cdot\alpha} = 2^{(1-\alpha)\cdot n} = \pair{2^{1-\alpha}}^n = q^n
            \intertext{Damit $q^n$ und damit auch $(a_n)_n$ konvergiert muss wie bereits gezeigt gelten}
            q &\definedas 2^{1-\alpha} < 1 \equivalent 1-\alpha < 0 \equivalent \alpha > 1
            \intertext{Es sei}
            a_n &= \frac{1}{n}\\
            2^n \cdot a_{\pair{2^\nu}} &= 2^n \cdot \frac{1}{2^n} = 1\impl (a_n)_n\text{ konvergiert}
        \end{align*}
    \end{beispiel}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 7. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{definition}[Alternierende Reihe] % Definition 10
        \marginnote{[7. Dez]}
        Sei $(a_n)_n$ eine reelle Folge nicht-negativer reeller Zahlen. Dann heißt
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1} \cdot a_n = a_1 - a_2 + a_3 - a_4 \dots
        \end{align*}
        alternierende Reihe. Alternativ $a_n\geq 0$, $n\in\N_0$.
        \begin{align*}
            \sum_{n=0}^{\infty} (-1)^n\cdot a_n = a_0 - a_1 + a_2 - a_3 \dots
        \end{align*}
    \end{definition}

    \begin{satz}[Leibniz-Kriterium] % Satz 11
        Sei $(a_n)_n$ eine monoton fallende Nullfolge. Dann konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1} \cdot a_n
        \end{align*}

        \begin{proof}
            Idee: Wir unterscheiden zwischen geraden und ungeraden $n$.
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} (-1)^{j+1} \cdot a_j\\
                s_{2(n+1)} &= \sum_{j=1}^{2n+2} (-1)^{j+1} \cdot a_j\\
                &= \sum_{j=1}^{2n} (-1)^{j+1} \cdot a_j + (-1)^{(2n+1)+1} \cdot a_{2n+1} + (-1)^{(2n+2)+1} \cdot a_{2n+2}\\
                &= s_{2n} + \underbrace{a_{2n+1} - a_{2n+2}}_{\geq 0}\\
                &\geq s_{2n}
                \intertext{Also ist $(s_{2n})_n$ monoton wachsend}
                s_{2(n+1)+1} &= s_{2n+3} = \sum_{j=1}^{2n+3} (-1)^{j+1} \cdot a_j\\
                &= s_{2n+1} + (-1)^{(2n+2)+1} \cdot a_{2n+2} + (-1)^{(2n+3)+1} \cdot a_{2n+3}\\
                &= s_{2n+1} \underbrace{- a_{2n+2} + a_{2n+3}}_{\leq 0}\\
                &\leq s_{2n+1}
            \end{align*}
            Also ist $(s_{2n+1})_n$ ist monoton fallend und
            \begin{align*}
                s_{2n+1} - s_{2n} &= \sum_{j=1}^{2n+1} (-1)^{j+1} \cdot a_j - \sum_{j=1}^{2n} (-1)^{j+1}\cdot a_j\\
                &= (-1)^{(2n+1)+1} \cdot a_{2n+1} = a_{2n+1} \geq 0
                \intertext{$\impl \abs{s_{2n+1}-s_{2n}} = a_{2n+1}$ und $s_{2n+1} \geq s_{2n}$}
                0 \leq a_1 - a_2 &= s_2 \leq s_{2n} \leq s_{2n+1} \leq s_1 = a_1\\
                \annot{\impl}{\ref{satz:monoton-konv}} s_g &\definedas \lim_{n\fromto\infty} s_{2n}\text{ existiert}\\
                s_u &\definedas \lim_{n\fromto\infty} s_{2n-1}\text{ existiert}\\
                \text{und } s_g &= s_u\\
                \impl (s_n)_n&\text{ konvergiert gegen $s=s_g=s_u$}\qedhere
            \end{align*}
        \end{proof}
        \begin{uebung}
            Weisen Sie nach, dass eine Folge konvergiert, wenn die Teilfolgen der geraden und der ungeraden Folgeglieder konvergieren und die Differenz eine Nullfolge ist.
        \end{uebung}
    \end{satz}

    \begin{beispiel}
        \begin{align*}
            &\sum_{n=1}^{\infty} \pair{-1}^{n+1} \cdot \frac{1}{\sqrt{n}}\text{ konvergiert}\\
            \text{aber } &\sum_{n=1}^{\infty} \frac{1}{\sqrt {n}} \text{ divergiert}\\
            &\sum_{n=1}^{\infty} (-1)^{n} \cdot \frac{1}{n}\text{ konvergiert}\\
            &\sum_{n=2}^{\infty} (-1)^n \cdot \frac{1}{\log\pair{n}}\text{ konvergiert}
        \end{align*}
    \end{beispiel}

    \begin{satz}[Cauchy-Kriterium] % Satz 12
        \label{satz:cauchy-kriterium}
        Sei $(a_n)_n$ eine Folge reeller Zahlen. Dann konvergiert
        \begin{align*}
            \sum_{n=1}^{\infty} a_n
        \end{align*}
        genau dann, wenn
        \begin{align*}
            \forall \varepsilon > 0~\exists N_{\varepsilon}\in\N\colon \abs{\sum_{j=n+1}^{m} a_j} <\varepsilon\quad\forall m>n\geq N_{\varepsilon}
        \end{align*}
        \begin{proof}
            \begin{align*}
                s_n &\definedas \sum_{j=1}^{n} a_j\\
                \intertext{$(s_n)_n$ konvergiert nach Satz~\ref{satz:jede-konv-cauchy} genau dann, wenn es eine Cauchy-Folge ist. Das heißt}
                \forall\varepsilon > 0~\exists N_{\varepsilon}\in\N\colon &\abs{s_{m} - s_{n}} < \varepsilon\quad\forall m> n \geq N_{\varepsilon}\\
                \abs{s_m - s_n} &= \sum_{j=1}^{m} a_j = \sum_{j=1}^{n} a_j\\
                &= \sum_{j=n+1}^{m} a_j\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{korollar} % Korollar 12
        \label{korollar:folge-von-reihe-nullfolge}
        Ist die reelle Reihe $\sum_{n=1}^{\infty} a_n$ konvergent, so ist $(a_n)_n$ eine Nullfolge.
        \begin{proof}
            Nach Satz~\ref{satz:cauchy-kriterium} $\impl$
            \begin{align*}
                \forall \varepsilon > 0~\exists N_{\varepsilon}\in\N\colon &\abs{\sum_{j=n+1}^{n+p} a_j} < \varepsilon\quad\forall n\geq N_{\varepsilon}, p\in\N\\
                \intertext{Wähle $p=1$}
                \sum_{j=n+1}^{n+1} a_{j} &= a_{j+1}\\
                \impl \abs{a_{n+1}} &< \varepsilon\quad \forall n\geq N_{\varepsilon}\\
                \impl \lim_{\ntoinf} a_{n+1} &= 0\\
                \impl \lim_{\ntoinf} a_{n} &= 0\qedhere
            \end{align*}
        \end{proof}
    \end{korollar}

    \subsection{[*] Absolut konvergente Reihen und Umordnungen}

    \begin{definition}[Absolute Konvergenz] % Definition 1
        Eine Reihe$\sum_{n=1}^{\infty} a_n$ heißt absolut konvergent, falls
        \begin{align*}
            \sum_{n=1}^{\infty} \abs{a_n}
        \end{align*}
        konvergiert. Das heißt falls
        \begin{align*}
            \sum_{n=1}^{\infty} \abs{a_n} < \infty
        \end{align*}
    \end{definition}

    \begin{satz}[Absolute Konvergenz als Konvergenzkriterium] % Satz 2
        \label{satz:absolut-konvergenz-konvergenkriterium}
        Ist eine Folge $\sum_{n}^{\infty} a_n$ absolut konvergent, so ist sie auch konvergent und
        \begin{align*}
            \abs{\sum_{n=1}^{\infty} a_n} \leq \sum_{n=1}^{\infty} \abs{a_n}
        \end{align*}

        \begin{proof}
            Wir haben für $m>n$
            \begin{align*}
                \abs{\sum_{j=n+1}^{m} a_j} \leq \sum_{j=n+1}^{m} \abs{a_j}
            \end{align*}
            Wir nehmen an, dass $\sum_{n=1}^{\infty} \abs{a_n}$ konvergiert. Das heißt Cauchy ist erfüllt.
            \begin{align*}
                \impl \forall \varepsilon > 0~\exists N_{\varepsilon}\colon \sum_{j=n+1}^{m} \abs{a_j} &< \varepsilon \quad\forall m> n\geq N_{\varepsilon}\\
                \impl \abs{\sum_{j=n+1}^{m} a_j} &< \varepsilon\quad\forall m>n\geq N_{\varepsilon}\\
                \impl \sum_{j=1}^{\infty} a_j&\text{ konvergiert}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}[Konvergenz ohne absolute Konvergenz]
        \begin{align*}
            \sum_{n=1}^{\infty} (-1)^{n+1}\cdot \frac{1}{n}
        \end{align*}
        ist konvergent, aber nicht absolut konvergent.
    \end{beispiel}

    \begin{definition}[Majorante] % Def 3
        Die Reihe
        \begin{align*}
            \sum_{n=1}^{\infty} c_n\quad c_n\geq 0~\forall n\in\N
        \end{align*}
        ist eine Majorante der Reihe $\sum_{n}^{\infty} a_n$ falls
        \begin{align*}
            \abs{a_n} &\leq c_n\text{ für fast alle }n\in\N
            \intertext{Das heißt}
            \exists n_0\in\N\colon \abs{a_n} &< c_n\quad\forall n\geq n_0
        \end{align*}
    \end{definition}

    \begin{satz}[Majoranten-Konvergenz-Kriterium für Reihen] % Satz 4
        \label{satz:majorante-reihen}
        Hat die Reihe $\sum_{n=1}^{\infty} a_n$ eine konvergente Majorante $\sum_{n=1}^{\infty} c_n$, so ist diese Reihe absolut konvergent und somit auch konvergent.
        \begin{proof}
            Folgt aus Satz~\ref{satz:absolut-konvergenz-konvergenkriterium} und Satz~\ref{satz:majoranten-kriterium}.
        \end{proof}
    \end{satz}

    \begin{satz}[Quotientenkriterium] % Satz 5
        \label{satz:quotientenkriterium}
        Sei
        \begin{align*}
            s_n &\definedas \sum_{n=0}^{\infty} a_n
        \end{align*}
        eine Reihe mit $a_n\neq 0$. Ferner gebe es ein $0\leq q < 1$ so dass
        \begin{align*}
            \frac{\abs{a_{n+1}}}{\abs{a_n}} \leq q\text{ für fast alle } n\in\N\\
            \impl \sum_{n=0}^{\infty} a_n\text{ absolut konvergent}
        \end{align*}

        \begin{proof}
            Wir haben $n_0\in\N$
            \begin{align*}
                \frac{\abs{a_{n+1}}}{\abs{a_n}} &\leq q\quad\forall n\geq n_0\\[10pt]
                \abs{a_{n+1}} \leq q\cdot\abs{a_n} &\leq q^2 \cdot \abs{a_{n-1}} \leq q^3 \cdot \abs{a_{n-2}}\\[10pt]
                \leq \dots &\leq q^{p+1} \cdot\abs{a_{n_0}} = q^{n-n_0+1} \cdot\abs{a_{n_0}}\tag{$p\in\N$, $n=n_0+p$}\\[10pt]
                &= q^{n+1} \cdot q^{-n_0} \cdot\abs{a_{n_0}}\\[10pt]
                \impl \abs{a_n} &\leq \underbrace{q^n \cdot K}_{\definedasbackwards c_n}\tag{$K \definedas q^{-n_0} \cdot \abs{a_{n_0}}$}\\
                \impl \abs{a_{n_0}} &\leq c_n\quad\forall n\geq n_0\\
                \intertext{und}
                \sum_{n=0}^{\infty} c_n &= \sum_{n=0}^{\infty} K\cdot q^{n} = K\cdot \sum_{n=0}^{\infty} q^{n} < \infty
                \intertext{Da $0< q < 1$}
                \impl \sum_{n=c}^{\infty} &a_n\text{ hat die konvergente Majorante } K \cdot \sum_{n=c}^{\infty} q^{n}
            \end{align*}
            Damit lässt sich aus Satz~\ref{satz:majorante-reihen} folgern, dass die Reihe konvergiert.
        \end{proof}
    \end{satz}

    \begin{bemerkung}[Quotientenkriterium über $\limsup$ und $\liminf$]
        \theoremescape
        \begin{enumerate}[label=(\roman*)]
            \item Ist $\limsup_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} < 1 \equivalent$ Quotientenkriterium
            \item Ist $\liminf_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} > 1\impl \sum_{n=0}^{\infty} a_n$ divergent
            \item Ist $\limsup_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} = 1\impl \text{Keine Aussage über absolute Konvergenz von } \sum_{n=0}^{\infty} a_n$ möglich
        \end{enumerate}
        \begin{proof}[Beweis (ii).]
            \begin{align*}
                \text{Ist } \overline{q}\definedas\liminf_{n\fromto\infty} \frac{\abs{a_{n+1}}}{\abs{a_n}} &> 1\\[8pt]
                \impl \forall \varepsilon > 0~\exists n_0\colon \frac{\abs{a_{n+1}}}{\abs{a_n}} \geq \overline{q} - \varepsilon = \frac{\overline{q}+1}{2} &\geq q > 1\tag{Wähle $\varepsilon=\frac{\overline{q}-1}{2} > 0$}\\[8pt]
                \impl \frac{\abs{a_n+1}}{\abs{a_n}} &\geq q > 1\quad\forall n\geq n_0
                \intertext{Wir wenden ein ähnliches Prinzip wie im vorherigen Beweis an}
                \impl \abs{a_{n+1}} &\geq q^{n+1} \cdot q^{-n_0}\cdot\abs{a_{n_0}}\\[8pt]
                \impl \abs{a_n} &\geq q^n\cdot K\tag{$K=q^{-n_0}\cdot\abs{a_{n_0}}$}\\[8pt]
                \impl \sum a_j\text{ divergiert nach}&\text{ Korollar~\ref{korollar:folge-von-reihe-nullfolge}}\qedhere
            \end{align*}
        \end{proof}
    \end{bemerkung}

    \begin{beispiel}[Divergenz bei nicht-eindeutigem Quotientenkriterium]
        $a_n \definedas \frac{1}{n}$
        \begin{align*}
            \frac{\abs{a_{n+1}}}{\abs{a_n}} = \frac{a_{n+1}}{a_n} &= \frac{n}{n+1} = 1 + \frac{1}{n} \fromto 1
            \intertext{Und}
            \sum_{n=1}^{\infty} \frac{1}{n}&\text{ divergiert (Harmonische Reihe)}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}[Konvergenz bei nicht-eindeutigem Quotientenkriterium]
        $a_n \definedas \frac{1}{n^2}$
        \begin{align*}
            \frac{a_{n+1}}{a_n} = \frac{n^2}{(n+1)^2} &= \pair{\frac{n}{n+1}}^2 = \pair{1-\frac{1}{n+1}}^2 \fromto 1
            \intertext{Aber}
            \sum_{n=1}^{\infty} &a_n
            \intertext{konvergiert absolut:}
            \pair{1-\frac{1}{n}}^2 &= 1 - \frac{2}{n+1}+ \pair{\frac{1}{n+1}}^2\\
            &= 1 - \frac{2}{n+1}\cdot\pair{1-\frac{1}{2(n+1)}}\\
            &\leq 1- \frac{s-\delta}{n+1}\tag{Für $\delta>0$ und fast alle $n$}
        \end{align*}
    \end{beispiel}

    \newpage

    \begin{beispiel}[Eulersche Zahl über Reihendarstellung]
        Die Reihe
        \begin{align*}
            \sum_{n=0}^{\infty} \frac{1}{n!}
        \end{align*}
        ist absolut konvergent.
        \begin{align*}
            a_n &= \frac{1}{n!}\\
            \frac{a_{n+1}}{a_n} &= \frac{n!}{(n+1)!} = \frac{1}{n+1}\fromto 0
        \end{align*}
        Behauptung:
        \begin{align*}
            e'\definedas\sum_{n=0}^{\infty} \frac{1}{n!} &= e\tag{Eulersche Zahl}
        \end{align*}
        \begin{proof}
            Wir wenden die bereits gezeigt Formel für $e$ an:
            \begin{align*}
                e &= \lim_{\ntoinf} \pair{1+\frac{1}{n}}^n\\[10pt]
                \pair{1+\frac{1}{n}}^n &= \sum_{k=0}^{n}\binom{n}{k} \pair{\frac{1}{n}}^k\\
                &= \sum_{k=0}^{n} \frac{n\cdot(n-1)\cdot(n-k+1)}{k!\cdot n^k}\\
                &= \sum_{k=0}^{n} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} \frac{n-j}{n}\\
                &\leq \sum_{k=0}^{n} \frac{1}{k!} \leq \sum_{k=0}^{\infty} \frac{1}{k!}\\[10pt]
                \impl e &\leq \sum_{n=0}^{\infty} \frac{1}{n!}
                \intertext{Noch zu zeigen: $e'\leq e$}
                \pair{1+\frac{1}{n}}^n &= \sum_{k=0}^{n} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} 1-\frac{j}{n}\\
                &\geq \sum_{k=0}^{m} \frac{1}{k!}\cdot \prod_{j=0}^{k-1} \pair{1-\frac{j}{n}}\tag{$\forall n>m$}\\
                \intertext{Wir halten $m\in\N$ fest}
                \impl e &= \lim_{\ntoinf} \pair{1+\frac{1}{n}}^n \geq \lim_{\ntoinf} \sum_{k=0}^{m} \frac{1}{k!}\cdot \prod_{j=0}^{k-1} \pair{1-\frac{j}{n}}\\
                &= \sum_{k=0}^{m} \frac{1}{k!} \cdot \prod_{j=0}^{k-1} \underbrace{\lim_{\ntoinf} \pair{1-\frac{j}{n}}}_{=1}\\
                &= \sum_{n=0}^{m} \frac{1}{k!}\tag{$\forall m\in\N$}\\
                \impl e&\geq \lim_{\ntoinf} \sum_{k=0}^{m} \frac{1}{k!} = \sum_{k=0}^{\infty} \frac{1}{k!} = e\\
                \impl e &\leq e' \land e'\leq e\\
                \impl e &= e'\qedhere
            \end{align*}
        \end{proof}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 12. Dezember 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{bemerkung}[Ännäherung von $e$ über Reihen]
            \marginnote{[12. Dez]}
            \begin{align*}
                s_n &\definedas \sum_{k=0}^{n} \frac{1}{k!}\\
                r_{n,p} &\definedas \sum_{k=n+1}^{n+p} \frac{1}{k!}\\
                r_{n,p} &= \sum_{k=n+1}^{n+p} \frac{1}{k!} = \frac{1}{(n+1)!} + \frac{1}{(n+2)!} + \dots + \frac{1}{(n+p)!}\\
                &= \frac{1}{(n+1)!}\cdot\interv{1+\frac{1}{n+2}+\frac{1}{(n+2)\cdot(n+3)} + \dots + \frac{1}{(n+2)\cdot(n+3)\cdot\ldots\cdot(n+p)}}\\
                &> \frac{1}{(n+1)!}
                \intertext{Wir betrachten den zweiten Faktor}
                &1+\frac{1}{n+2}+\frac{1}{(n+2)\cdot(n+3)} + \dots + \frac{1}{(n+2)\cdot(n+3)\cdot\ldots\cdot(n+p)}\\
                &< 1 + \frac{1}{2} + \frac{1}{2\cdot 3}+\dots + \frac{1}{2\cdot 3 \cdot\ldots\cdot p}\\
                &= \sum_{k=0}^{p} \frac{1}{k!} - 1 < \sum_{k=0}^{\infty} \frac{1}{k!} - 1 = e-1
                \intertext{Wir kombinieren die Abschätzung über beide Faktoren und erhalten}
                \impl &\frac{1}{(n+1)!} < r_{n,p} < \frac{e-1}{(n+1)!}\\
                \equivalent &\frac{1}{(n+1)!} < s_{n+p} - s_{n} < \frac{e-1}{(n+1)!}\\
                &s_{n+p} - s_{n} \fromto e - s_n\text{ für }p\fromto\infty\\
                \impl &\frac{1}{(n+1)!} \leq e - s_n \leq \frac{e-1}{(n+1)!}
                \intertext{Wir erhalten also ein Verfahren, um einen Näherungswert für $e$ zu bestimmen}
                &2,5 \leq e \leq 3\quad(n=1)\\
                &2,66 \leq e \leq 2,8\quad(n=2)\\
                \vdots\\
                &e = 2,71828182\ldots
            \end{align*}
        \end{bemerkung}
    \end{beispiel}


    \begin{bemerkung}[Ausblick: Definition von Exponentialfunktionen über Reihen]
        \begin{align*}
            a_n &\definedas\sum_{n=0}^{\infty} \frac{x^n}{n!}\\
            \frac{\abs{a_{n+1}}}{\abs{a_n}} &= \abs{\frac{x^{n+1}\cdot n!}{(n+1)!\cdot x^n}} = \frac{\abs{x}}{n+1}\fromto 0
        \end{align*}
        Diese Konvergenz werden wir in einem späteren Kapitel nutzen, um die Exponentialfunktion über
        \begin{align*}
            \exp(x) &= \sum_{k=0}^{\infty} \frac{x^n}{n!} = e^x
        \end{align*}
        zu definieren.
    \end{bemerkung}

    \begin{satz}[Nach Lambert 1707] % Satz 7
        Die eulersche Zahl $e$ ist irrational.
        \begin{proof}
            Wir haben
            \begin{align*}
                \frac{1}{(n+1)!} &\leq e-s_n \leq \frac{e-1}{(n+1)!} < \frac{2}{(n+1)!}
                \intertext{Angenommen $e=\frac{p}{q}$\quad$p,q\in\N$. Wir nehmen $p=q\cdot m$}
                \impl \frac{1}{(q+1)!} &\leq \frac{p}{q} - s_q < \frac{2}{(q+1)!}\\
                0 &< \frac{1}{q+1} \leq \frac{p}{q}\cdot q! - q!\cdot s_q < \frac{2}{q+1}<1
                \intertext{Es lässt sich zeigen, dass der dritte Term eine ganze Zahl ist:}
                \frac{p}{q}\cdot q! &= p\cdot(q-1)!\in\N\\
                q!\cdot s_q &= q! \cdot \sum_{k=0}^{q} \frac{1}{k!}\in\N
            \end{align*}
            Damit ergibt sich ein Widerspruch, weil keine ganze Zahl zwischen $0$ und $1$ liegt.
        \end{proof}
    \end{satz}

    \newpage

    \begin{satz}[Wurzelkriterium] % Satz 8
        \label{satz:wurzelkriterium}
        Sei $(a_n)_n$ eine reelle Folge.
        \begin{enumerate}[label=(\roman*)]
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} < 1$, dann konvergiert $\sum_{n=0}^{\infty} a_n$ absolut.
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} > 1$, dann ist $\sum_{n=0}^{\infty} a_n$ divergent.
            \item Ist $\limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} = 1$, so ist keine Aussage möglich.
        \end{enumerate}
        \begin{proof}[Beweis (iii)]
            \begin{align*}
                a_n &\definedas \frac{1}{n^p}\\
                \sqrt[n]{\abs{a_n}} &= \pair{\frac{1}{\sqrt[n]{n}}}^p \fromto \pair{\frac{1}{1}}^p = 1\tag{$n\fromto\infty$}\\
                \sum_{n=1}^{\infty} \frac{1}{n^p}&\text{ divergiert für $p=1$ und konvergiert für $p>1$}\\
                \impl &\text{ keine Aussage möglich}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (i)]
            Sei
            \begin{align*}
                \hat{q}&\definedas \limsup \sqrt[n]{\abs{a_n}} < 1
                \intertext{Wähle $\varepsilon\definedas \frac{1-\hat{q}}{2} > 0$}
                \annot{\impl}{\ref{lemma:limsup-charak}} \sqrt[n]{\abs{a_n}} &< \hat{q} + \varepsilon = \frac{1+\hat{q}}{2}\text{ für fast alle $n$}\\
                \impl \exists n_{0}\in\N\colon \sqrt[n]{\abs{a_n}} &\leq q\quad\forall n\geq n_0\\
                \equivalent \abs{a_n} &\leq q^n\quad\forall n\geq n_0\\
                \intertext{Das heißt $\sum_{n=0}^{\infty} q^n$ ist eine konvergente Majorante für $\sum a_n$}
                \impl \sum_{n=0}^{\infty} a_n&\text{ ist absolut konvergent}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (ii)]
            Sei
            \begin{align*}
                \hat{q}&\definedas \limsup_{\ntoinf} \sqrt[n]{\abs{a_n}} > 1\\
                \varepsilon &\definedas \frac{\hat{q}-1}{2}>0\\
                q&\definedas \hat{q}-\varepsilon = \frac{1+\hat{q}}{2} > 1\\
                \impl \sqrt[n]{\abs{a_n}} &> \hat{q}-\varepsilon \definedasbackwards q > 1\tag{für unendlich viele $n$}\\
                \impl \abs{a_n} &> q^n\tag{für unendlich viele $n$}\\
                \impl (a_n)_n&\text{ keine Nullfolge}
            \end{align*}
            Somit konvergiert $\sum a_n$ nicht.
        \end{proof}
    \end{satz}

    \newpage

    \begin{definition}[Umordnung von Reihen] % Definition 9
        Seien
        \begin{align*}
            \sum_{n=0}^{\infty} a_n\quad \sum_{n=0}^{\infty} b_n
        \end{align*}
        Reihen mit Gliedern $a_n, b_n\in\R$, $n\in\N_0$. Wir nennen $\sum_{n=0}^{\infty} b_n$ eine Umordnung von $\sum_{n=0}^{\infty} a_n$, falls eine Bijektion
        \begin{align*}
            \sigma: \N_0 \fromto \N_0
        \end{align*}
        existiert mit $b_n = a_{\sigma(n)}~\forall n\in\N_0$.\\
        Ähnlich für Reihen
        \begin{align*}
            \sum_{n=1}^{\infty} a_n\quad \sum_{n=1}^{\infty} b_n
        \end{align*}
        $\sum_{n=1}^{\infty} b_n$ Umordnung von $\sum_{n=1}^{\infty} a_n$, falls Bijektion $\sigma: \N \fromto\N$ existiert mit $b_n = a_{\sigma(n)}$.
    \end{definition}

    \begin{definition}[Unbedingte Konvergenz] % Definition 10
        Eine Reihe $\sum_{n=0}^{\infty} a_n$ heißt unbedingt konvergent, falls jede Umordnung $\sum_{n=0}^{\infty} b_n$ von dieser Reihe ebenfalls konvergiert und die selbe Summe hat.\\
        Andernfalls heißt $\sum_{n=0}^{\infty} a_n$ bedingt konvergent.
    \end{definition}

    \begin{satz}[Direcklet 1837] % Satz 11
        Eine Reihe $\sum_{n=0}^{\infty} a_n$, $a_n\in\R$ ist absolut konvergent genau dann, wenn sie unbedingt konvergiert.
        \begin{proof}
            \anf{$\impl$} Sei
            \begin{align*}
                \sum_{n=0}^{\infty} a_n\text{ absolut konvergent}\\
                \impl \sum_{n=0}^{\infty} \abs{a_n}\text{ konvergent}\\
                \equivalent \sum_{n=0}^{\infty} \abs{a_n} < \infty
                \intertext{Wir wenden das Cauchy-Kriterium an}
                \forall \varepsilon>0~\exists N\in\N\colon \sum_{j=n+1}^{n+p} \abs{a_j} < \varepsilon\quad\forall n\geq N, p\in\N\\
                \impl \sum_{j=n+1}^{\infty}\abs{a_j} = \lim_{p\fromto\infty} \sum_{j=n+1}^{n+p} \abs{a_j} \leq \varepsilon\quad\forall n\geq N\tag{3}
                \intertext{Wir definieren}
                s_n \definedas \sum_{j=0}^{\infty} a_j\quad \sum_{n=0}^{\infty} b_n\text{ Umordnung von } s_n\\
                b_n = a_{\sigma(n)}\quad \sigma: \N_0 \fromto\N_0\text{ Bijektion}\\
                t_n \definedas \sum_{j=0}^{n} b_j
                \intertext{Wir wissen $s_n\fromto s$. Zu zeigen: $t_n\fromto s$}
                \set{1,2,\dots, N} \subseteq \set{\sigma(1), \sigma(2), \dots, \sigma(M)}\tag{Nehmen $M\in\N$}\\
                \intertext{Ist dann $n\geq M$, dann ist}
                \set{a_1, a_2, a_3, \dots, a_N}\subseteq \set{b_1, b_2, \dots b_M} = \set{a_{\sigma(1)}, a_{\sigma(2)}, \dots, a_{\sigma(M)}}\\
                \impl\text{ Alle Glieder $a_1, \dots, a_n$ in der Summe $s_n$ treten in $t_n = t_1 + t_2 + \dots + t_n$ auf}\\
                \impl\text{ Diese Terme heben sich in $s_n-t_n$ gegenseitig auf, sofern $n\geq M$ ist}\\
                \impl \abs{s_n-t_n} \leq \sum_{j\geq N+1, j=\sigma{k}\text{ für ein }k\in\set{1,\dots, M}}^{} \abs{a_j}\\
                \leq \sum_{j=??}^{\infty} \abs{a_j} \leq \varepsilon\\
                \impl s_n - t_n \fromto 0\text{ für }\ntoinf
            \end{align*}
            Da $(s_n)_n$ gegen $s$ konvergiert, konvergiert auch $(t_n)_n$ gegen $s$. Somit konvergiert $\sum_{n=0}^{\infty} b_n$ und hat die selbe Summe wie $\sum_{n=0}^{\infty} a_n$.\\[10pt]
            \anf{$\Leftarrow$} Angenommen $\sum_{n=0}^{\infty} a_n$ ist unbedingt konvergent, aber nicht absolut konvergent.
            \begin{align*}
                p_n &\definedas (a_n)_{+} \definedas \max\pair{0, a_n}\\
                q_n &\definedas (a_n)_{-} \definedas \max\pair{0,-a_n} = -\min\pair{0,a_n}\\
                \impl \abs{a_n} &= p_n + q_n\quad\forall n\in\N_0\\
                \intertext{Wir haben $\sum_{n=0}^{\infty} \abs{a_n}$ konvergiert, aber $\sum_{n=0}^{\infty} p_n = \infty$}
            \end{align*}
            Behauptung: $\sum_{n=0}^{\infty} p_n = \infty$ und $\sum_{n=0}^{\infty} q_n = \infty$. Angenommen $0\leq \sum_{n=0}^{\infty} p_n < \infty$.
            \begin{align*}
                \impl \sum_{n=0}^{\infty} \pair{p_n - a_n}\text{ konvergiert}\\
                \impl \sum_{n=0}^{\infty} a_n < \infty
                \intertext{Da $\abs{a_n} = p_n + q_n$}
                \impl \sum_{n=0}^{\infty} \abs{a_n} = \sum_{n=0}^{\infty} \pair{p_n+q_n} = \sum_{n=0}^{\infty} p_n + \sum_{n=0}^{\infty} q_n < \infty\\
                \text{Widerspruch zu } \sum_{n=0}^{\infty} b_n\text{ ist nicht absolut konvergent}
            \end{align*}
            Jetzt setze $r_0=0$ und bestimme induktiv $(r_n)_n~r_n < r_{n+1}$ mit $p_0 + p_1 + \dots + p_{r_n} > n + q_0 + q_1 + \dots + q_n~\forall n\in\N$.
            $r_q\definedas$ kleinste natürliche Zahl mit $p_0 + p_q + \dots + p_{r_1} > 1 + q_? + q_1$.\\
            $r_2\definedas$ kleinste natürliche Zahl $\geq r_1 + 1$: $p_0 + \dots + p_{r_2} > 2 + q_0 + q_1 + q_2$.\\
            Machen induktiv weiter: Gegeben $r_n$ wähle $r_{n+1} =$ kleinste natürliche Zahl $\geq r_n + 1$ mit $p_0 + p_1 + \dots + p_{r_{n+1}} > n + q_0 + q_1 + \dots + q_n$.\\[10pt]
            Umordnung $p_0 - q_0 + p_1 + \dots + p_{r_1} - q_1 + p_{r_{1+1}} + \dots + p_{r_2} - q_2 + p_{r_{2+1}} + \dots + p_{r_3} - q_3 + \dots$. Diese Umordnung divergiert gegen $+\infty$.
        \end{proof}
    \end{satz}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 14. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{satz}[Nach Riemann 1854]
        \marginnote{[14. Dez]}
        Ist $\sum_n a_n$ konvergent, aber nicht absolut konvergent. Dann gibt es zu jedem $c\in\R$ eine Umordnung $\sum_{n}^{} b_n$ von $\sum_{n}^{} a_n$ so, dass $\sum_n b_n$ konvergiert und den Wert $c$ hat ($\sum_{n} b_n = c$).

        \begin{proof}
        (Später)
        \end{proof}
        % Skizze zu Riemann-Satz
    \end{satz}

    \newpage


    \section{[*] $\R^d$, Konvergenz im $\R^d$, die komplexen Zahlen $\C$ und der Raum $\C^d$}

    \subsection{[*] Der Raum $\R^d$ und Normen}

    \thispagestyle{pagenumberonly}

    \begin{definition}
        \begin{align*}
            \R^d &\definedas\text{ Vektorraum der reellen $d$-Tupel}\\
            &=\set{\pair{x_1, x_2, \dots, x_d} ~\middle|~ x_j\in\R,~ j=1,\dots,d }\\
        \end{align*}
    \end{definition}

    \begin{notation}[Linearkombination von Vektoren]
        Es sei
        \begin{align*}
            x&= \pair{x_1, \dots, x_d}\\
            y&= \pair{y_1, \dots, y_d}
            \intertext{und $\alpha, \beta \in \R$, dann gilt}
            \alpha x + \beta y &\definedas \pair{\alpha x_1 + \beta y_1, \alpha x_2 + \beta y_2, \dots, \alpha x_d + \beta y_d}
        \end{align*}
    \end{notation}

    \begin{notation}[Vektorschreibweise]
        \begin{align*}
            x = \begin{pmatrix}
                    x_1 \\ \vdots \\ x_d
            \end{pmatrix}
        \end{align*}
    \end{notation}

    \horizontalline
    Im $\R$ haben wir Konvergenz über den Betrag definiert. Im $\R^d$ benötigen wir daher ein ähnliches Konzept. Wir betrachten dafür zunächst einige Beispiele solcher \textit{Normen}.

    \begin{beispiel}[Euklidische Länge eines Vektors]
        Für $d=2$ gilt für die euklidische Länge $\norm{x}$ eines Vektors $x\in\R^2$
        \begin{align*}
            \norm{x}^2 &= (x_1)^2 + (x_2)^2\\
            \norm{x} &= \sqrt{(x_1)^2 + (x_2)^2}
        \end{align*}
        Allgemein gilt
        \begin{align*}
            \norm{x} &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
            \intertext{Wir schreiben auch}
            \norm{x}_2 &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}[Andere Normen]
        Neben der euklidischen lassen sich noch weitere Normen definieren. Zum Beispiel
        \begin{align*}
            \norm{x}_1 &\definedas \sum_{j=1}^{d} \abs{x_j} \tag{Manhattan-Norm}\\
            \norm{x}_{\infty} &\definedas \max_{1\leq j \leq d} \abs{x_j}\tag{Maximums-Norm}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Norm] % Definition 1
        Eine Norm auf $\R^d$ (oder einem reellen Vektorraum) ist eine Abbildung
        \begin{align*}
            \norm{.}: \R^d\fromto \R
        \end{align*}
        mit folgenden Eigenschaften:
        \begin{enumerate}[label=\alph*)]
            \item $\norm{x} \geq 0~\forall x\in\R^d$ sowie $\norm{x} = 0\impl x=0$
            \item $\forall\lambda\in\R,~x\in\R^d\colon \norm{\lambda x} = \abs{\lambda}\cdot\norm{x}$
            \item $\forall x,y\in\R^d\colon\norm{x+y} \leq \norm{x} + \norm{y}$\quad\text{(Dreiecksungleichung)}
        \end{enumerate}
    \end{definition}

    \begin{bemerkung}
        Dass a), b) und c) für $\norm{\cdot}_1$ und $\norm{\cdot}_{\infty}$ gelten, ist einfach zu zeigen. Außerdem sind a) und b) für $\norm{\cdot}_2$ einfach zu zeigen, c) ist tricky. (Übung)
    \end{bemerkung}

    \begin{definition}[Äquivalenz von Normen]
        2 Normen $\norm{\cdot}_a$ und $\norm{\cdot}_b$ sind äquivalent, falls
        \begin{align*}
            \exists c_1, c_2\in\R\colon c_1\cdot\norm{x}_a \leq \norm{x}_b \leq c_2 \norm{x}_a\quad\forall x\in V
        \end{align*}
    \end{definition}

    \begin{beispiel}[Äquivalenz von euklidischer und Maximums-Norm]
        \label{beispiel:norm-equiv}
        Wir zeigen, dass $\norm{\cdot}_{\infty}$ und $\norm{\cdot}_{2}$ äquivalent sind.
        \begin{align*}
            \abs{x_k} &\leq \sqrt{\sum_{j=1}^{d} \abs{x_j}^2} = \norm{x}_2\tag{$1\leq k \leq d$}\\
            \impl \norm{x}_{\infty} &= \max_{k=1,\dots, d} \abs{x_k} \leq \norm{x}_2\tag{1}
            \intertext{Umgekehrt}
            \norm{x}_2^2 = \sum_{j=1}^{d} \abs{x_j}^2 &\leq \sum_{j=1}^{d} \pair{\max_{k=1,\dots, d}\pair{\abs{x_k}}}^2 = d \cdot \norm{x}_{\infty}^2\\
            \impl \norm{x}_2 &\leq \sqrt {d}\cdot \norm{x}_{\infty}\tag{2}
            \intertext{Mit (1) und (2) gilt dann}
            \impl \frac{1}{\sqrt{d}}\cdot \norm{x}_2 &\leq\norm{x}_{\infty} \leq \norm{x}_2
        \end{align*}
    \end{beispiel}

    \begin{uebung}
        Weisen Sie die Äquivalenz von $\norm{x}_1$ und $\norm{x}_\infty$ analog zu Beispiel~\ref{beispiel:norm-equiv} nach.
    \end{uebung}

    \subsection{[*] Konvergenz im $\R^d$}

    \begin{bemerkung}[Abstand zwischen 2 Vektoren im $\R^d$]
        Zu jeder Norm auf $\R^d$ (oder reellen Vektorräumen) definieren wir den Abstand von 2 Vektoren $x,y\in\R^d$ als $\norm{x-y}$.
        \begin{align*}
            d(x,y) &\definedas \norm{x-y}
            \intertext{Mit $z$ als weiterem Vektor gilt}
            \norm{x-y} &= \norm{x-z+z-y}\\
            &\leq \norm{x-z} + \norm{z-y}\\
            \norm{x-y} &= \norm{-(y-x)} = \abs{-1}\cdot \norm{y-x} = \norm{y-x}
        \end{align*}
    \end{bemerkung}

    \begin{folgerung}[Mehrdimensionale $\varepsilon$-Umgebung]
        Bisher basierte unser Konvergenz-Begriff auf dem Abstand von $(x_n)_n$ und $x$ und somit auf einer eindimensionalen $\varepsilon$-Umgebung.\\
        Wir verallgemeinern dieses Konzept für eine offene Kugel im $\R^d$ mit $x\in\R^d$
        \begin{align*}
            B_\varepsilon(x) \definedas \set{y\in\R^d\middle |~ \norm{x-y}_2 < \varepsilon}
        \end{align*}
    \end{folgerung}

    \begin{visualisierung}[Zweidimensionale $\varepsilon$-Umgebung]
        Wir formen die Bedingung um
        \begin{align*}
            \norm{x-y}_2 &< \varepsilon\\
            \impl \sqrt{(x_1-y_1)^2 + (x_2 - y_2)^2} &< \varepsilon\\
            \impl \pair{x_1-y_1}^2 + \pair{x_2-y_2}^2 &< \varepsilon^2
        \end{align*}
        In der Visualisierung erhalten wir einen offenen Ball um $x$ mit Radius $\varepsilon$.

        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (0,0) circle (0.75cm);
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (2,1) circle (0.75cm);
                \draw[->] (-3,0) -- (3,0);
                \draw[->] (0,-3) -- (0,3);
                \draw[->] (0,0) node {$\times$} -- (0.52, 0.52) node[below, pos=0.8] {$\varepsilon$};
                \draw[->] (2,1) node {$\times$} -- (2, 1.75) node[right, pos=0.5] {$\varepsilon$};
                \draw (-0.25, 0.35) -- (-1.5, 0.35) node[left] {$B_{\varepsilon}\pair{(0,0)}$};
                \draw (1.75, 1.35) -- (-1.5, 1.35) node[left] {$B_{\varepsilon}\pair{(x_1,x_2)}$};
                \node at (-0.75,-0.75) {1.};
                \node at (2.75,0.25) {2.};
                \node at (3,-2) {\begin{tabular}{l}
                                     1. $x=(0,0)$ \\ 2. $x=(x_1, x_2)$
                \end{tabular}};
            \end{tikzpicture}
            \caption{Zweidimensionale $\varepsilon$-Umgebungen}
        \end{figure}
    \end{visualisierung}

    \begin{definition}[Konvergenz im $\R^d$] % Definition 2
        Sei $(x_n)_n$ eine Folge in $\R^d$ mit $x_n\in\R^d~\forall n$. Dann konvergiert $(x_n)_n$ gegen $x\in\R^d$, falls
        \begin{alignat*}{2}
            \forall\varepsilon > 0~\exists N\in\N\colon& \norm{x_1-x}_2 <\varepsilon\quad&&\forall n\geq N
            \intertext{Das heißt}
            \forall\varepsilon > 0~\exists N\in\N\colon& x_n\in B_{\varepsilon}(x)\quad&&\forall n\geq N
        \end{alignat*}
    \end{definition}

    \begin{beobachtung}[Konvergenz in $\R$ vs $\R^d$]
        Es sei ${x_n}\in\R^d$ mit $x_n = \pair{x_n^1, x_n^2, \dots, x_n^d}$\footnote{Koordinaten von $(x_n)_n$}. Damit ergeben sich die Folgen $(x_n^1)_n$, $(x_n^2)_n$, \dots, $(x_n^d)_n$ in $\R$.
        Angenommen $(x_n)_n$ konvergiert gegen $x\in\R^d$. Dann konvergieren alle Folgen $(x_n^l)_n$ in $\R$ und $\lim_{\ntoinf} x_n^l = x^l$

        \begin{proof}
            \begin{align*}
                \abs{x_n^{l} - x^{l}}^2 &\leq \sum_{j=1}^{d} \abs{x_n^{j}-x^{j}}^2 = \norm{x_n -x}_2^2\quad \forall l=1,\dots, d\\
                \impl \abs{x_n^l-x^l} &\leq \norm{x_n-x}_2 \fromto 0\text{ für } n\fromto\infty
            \end{align*}
            Also konvergiert $(x_n^l)$ gegen $x^l$ in $\R$ für alle $l=1,\dots,d$.\qedhere
        \end{proof}
    \end{beobachtung}

    \noindent Es gilt sogar die Umkehrung:

    \begin{satz}[Konvergenz im $\R^d$]
        Eine Folge $(x_n)_n$ in $\R^d$ konvergiert genau dann, wenn jede der Koordinatenfolge $(x_n^l)_n$ in $\R$ konvergiert $\forall l=1,\dots, d$.

        \begin{proof}
            ~\\\anf{$\impl$} Gerade gezeigt.\\
            \anf{$\Leftarrow$} Angenommen
            \begin{align*}
                \exists x^l &\definedas \lim_{\ntoinf} x^l_n\quad\forall l=1,\dots, d\\
                \impl \abs{x_n^l - x^l} &\fromto 0 \text{ für }\ntoinf\quad\forall l=1,\dots, d\colon\\
                \intertext{Das heißt}
                \forall\varepsilon > 0~\exists N_l\in\N\colon \abs{x_n^l - x^l} &< \frac{\varepsilon}{\sqrt{d}}\quad\forall n\geq N_{l}
                \intertext{Wir definieren}
                N&\definedas\max\pair{N_1, N_2, \dots, N_d}
                \intertext{Dann gilt $\forall n>N$}
                \norm{x_n-x}^2_2 &= \sum_{j=1}^{d} \abs{x_n^j - x^j}^2 < \sum_{j=1}^{d} \pair{\frac{\varepsilon}{\sqrt{d}}}^2\\
                &= d\cdot\frac{\varepsilon^2}{d} = \varepsilon^2\\
                \impl \norm{x_n-x}_2 &< \varepsilon\quad\forall n\geq N
                \intertext{Wir definieren den Grenzwert}
                x&\definedas (x^1, x^2, \dots, x^d)\quad x^j\definedas \lim_{\ntoinf} x_n^j\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 19. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{bemerkung}
        \marginnote{[19. Dez]}
        Sei $(a_n)_n\in\R^d$ mit $a_n = \pair{a_n^1, a_n^2, \dots, a_n^d}$. Reihe $\sum_{n=1}^{\infty} a_n = ??$. Wir betrachten die Partialsummen
        \begin{align*}
            s_n &\definedas \sum_{j=1}^{n} a_j
        \end{align*}
    \end{bemerkung}

    \begin{definition}
        $\sum_{n} a_n$ konvergiert, falls $(s_n)_n$ im $\R^d$ konvergiert
    \end{definition}

    \begin{satz}[Cauchy-Kriterium für Konvergenz im $\R^d$]
        Eine Folge $(x_n)_n$ ist genau dann im $\R^d$ konvergent, wenn $(x_n)_n$ eine Cauchy-Folge ist. Das heißt
        \begin{align*}
            \forall\varepsilon > 0~\exists N\in\N\colon \norm{x_n-x_m}_2 < \varepsilon\quad\forall n,m\geq N
        \end{align*}

        \begin{proof}
            \anf{$\impl$} Wie im Fall $\R$.\\
            \anf{$\Leftarrow$} Sei $(x_n)_n$ Cauchy-Folge.
            \begin{align*}
                \impl\text{ Alle Koordinaten } &(x_n^j)_n\text{ sind Cauchy-Folgen in }\R\text{, weil}\\
                \abs{x_n^j-x_m^j} &= \sqrt {\abs{x_n^j-x_m^j}^2} \leq \sqrt {\sum_{l=1}^{d} \abs{x_n^l - x_m^l}^2}\\
                &= \norm{x_1-x_m}_2\\
                \impl x_n &\definedas \lim_{\ntoinf} x_n^j\text{ existiert}\\
                \impl x &= \lim_{\ntoinf} x_n\text{ existiert}\qedhere
            \end{align*}
        \end{proof}

        \begin{proof}[2. Beweis]
            Wir wollen Satz~\ref{satz:bolzano-weierstrass} im $\R^d$ zeigen:
            Jede beschränkte Folge $(x_n)_n$ in $\R^d$ besitzt eine konvergente Teilfolge. ($(x_n)_n$ ist beschränkt, wenn $\exists R\geq 0\colon \norm{x_n}_2 \leq R~\forall n\in\N$ .Bzw., wenn $x_n\in\set{y\in\R^d \middle|~ \norm{y}_2 \leq R}$ (abgeschlossene Kugel mit Radius $R$ um 0).).\\
            \begin{align*}
                \impl \forall j=1,\dots, d\colon (x_n^j)_n\text{ beschränkte Folge im }\R^d\\
                \impl \exists\text{ Teilfolge } (x_n^1)_k\text{ von } (x_n^1)_n\text{, welche in }\R\text{ konvergiert}\\
                \impl \text{ Ausdünnung }\sigma: \N\fromto\N\text{ mit } \sigma(k) < \sigma(k+1)\\
                n_k \definedas \sigma(k)\quad\text{Existenz des Grenzwert} x_1 \definedas \lim_{\ntoinf} x_{\sigma(k)}
                \intertext{Genauso für $\lim (x^2_n)_n$}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists \kappa\colon \N\fromto\N\colon (x^2_{\kappa(k)})_k\text{ konvergent}
                \intertext{Catch: $(x^1_{\sigma(k)}, x^2_{\sigma(k)})_k$ ist im Allgemeinen keine Teilfolge von $(x^1_n, x^2_n)_n$. Lösung betrachte}
                \pair{x_{\sigma(k)}}_k\text{ Teilfolge von }(x_n)_n\\
                = \pair{x^1_{\sigma(k)}, x^2_{\sigma(k)}, x^3_{\sigma(k)}, \dots, x^d_{\sigma(k)}, }
                \intertext{Mache mit $(x^2_{\sigma(k)})_k$ weiter}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists\text{ konvergente Teilfolge von } (x^2_{\sigma(k)})_k\\
                \impl\text{ Ausdünnung } \sigma_2: \N\fromto\N\\
                \impl \pair{x^2_{\sigma(\sigma_2(k))}}_k\text{ konvergent}\\
                x_2 \definedas \sigma \circ \sigma_{2}\\
                \impl\text{ Neue Teilfolge } (x_{\kappa_{2}(k)}) = (x^1_{\kappa_{2}(k)},x^2_{\kappa_{2}(k)},x^3_{\kappa_{2}(k)},\dots, x^d_{\kappa_{2}(k)})
                \intertext{mit $\lim_{k\fromto\infty} x^1_{\kappa_{2}(k)}$ und $\lim_{k\fromto\infty} x^2_{\kappa_{2}(k)}$ existent}
            \end{align*}
            Mache induktiv so weiter, nach maximal $d$ Schritten sind wir fertig.\\
            Jede Cauchy-Folge in $\R^d$ ist beschränkt.
            \begin{proof}
                \begin{align*}
                    \varepsilon = 1\\
                    \impl \exists N\colon\norm{x_n-x_m}_2 \leq 1\quad\forall n,m\geq N\\
                    \impl \norm{x_n}_2 = \norm{x_n-x_N+x_N}_2 \leq \norm{x_n-x_N}_2 + \norm{x}_2\quad\forall n\geq N\\
                    < 1 + \norm{x_n}\\
                    \impl \norm{x}_2 \leq \max\pair{\norm{x_1}_2, \norm{x_2}_2,\dots\norm{x_{N-1}}_2, 1+\norm{x_N}_2}
                \end{align*}
            \end{proof}
            Auch: Eine Cauchy-Folge im $\R^d$ ist genau dann konvergent, wenn sie eine konvergente Teilfolge besitzt. (Beweis wie im Fall $d=1$).\\
            Alle bisherigen Konvergenz-Sätze, welche nicht die Anordnung im $\R$ benötigen, übertragen sich auf $\R^d$.\\
            Insbesondere: Reihe $\sum_{n=1}^{\infty} a_n$ ist absolut konvergent, falls $\sum_{n=1}^{\infty} \norm{a_n}_2 < \infty$.\\
            Ist eine Reihe $\sum_{n=1}^{\infty} a_n$ in $\R^d$ konvergent, so konvergieren alle Umordnungen gegen den selben Wert. Und es gilt die Umkehrung! (Satz von Direcklet in $\R^d$)
        \end{proof}
    \end{satz}

    \subsection{[*] Die Komplexen Zahlen}

    Was sind die komplexen Zahlen?\\
    $x^2+1$ ist nie Null $\forall x\in\R$. Wir definieren eine Zahl $i$ mit $i^2=-1$.\\
    Schreiben $x+iy$ mit $x,y\in\R$.
    \begin{align*}
    (x_1 + y_1\cdot i)
        \cdot (x_2 + y_2\cdot i) &= x_1\cdot x_2 + x_1\cdot i\cdot y_2 + i\cdot y_1 \cdot x_2 + (i\cdot y_1)\cdot(i\cdot y_2)\\
        &= x_1\cdot x_2 - y_1\cdot y_2 + \pair{x_1\cdot y_2 + y_1\cdot x_2}\cdot i\\
        (x_1+y_1\cdot i) + (x_2 + y_2\cdot i) &= x_1 + x_2 + \pair{y_1+y_2}\cdot i
    \end{align*}
    Betrachte $\R^2 = \set{(x,y) \middle|~ x,y\in\R}$.
    % Visualisierung: Eukldische Ebene
    \begin{align*}
        z &= (x,y)\\
        z_1 + z_2 &\definedas (x_1, y_1) + (x_2,y_2)\\
        &\definedas (x_1 + x_2, y_1 + y_2)
        \intertext{Wir definieren eine \anf{seltsame} Multiplikation}
        z_1 \cdot z_2 &\definedas (x_1, y_1)\cdot (x_2, y_2)\\
        &= \definedas \pair{x_1 x_2 - y_1 y_2, x_1 y_2 + x_2 y_1}
        \intertext{Wir definieren den Betrag}
        \abs{z} &\definedas\text{ Länge des Vektors } (x,y) = \sqrt {x^2+y^2}\\
        \intertext{Wir nennen}
        x&= \text{ Realteil von } z\\
        y&= \text{ Imaginärteil von } z\\
    \end{align*}

    Man rechnet einfach nach, dass Multiplikation und Addition Assoziativität, Kommutativität und Distributivität erfüllen.
    \begin{align*}
    (1,0)
        \cdot (1,0) &= (1,0)\\
        (0,1) \cdot (0,1) &= (0-1,0) = -(1,0)\\
        z\cdot (1,0) &= (x,y)\cdot(1,0)= (x,y) = z
        \intertext{in $\R^2$}
        (x,y) &= x\cdot e_1 + y \cdot e_2\tag{$e_1 = (1,0)$, $e_2 = (0,1)$}\\
        (e_1)^2 &= e_1\quad (e_2)^2 = -e_1
    \end{align*}
    Wir schreiben $1$ für $e_1$ und $i$ für $e_2$.
    \begin{align*}
        z &= (x,y) = x\cdot e_1 + y\cdot e_2\\
        &= x\cdot 1 + y\cdot i\\
        &= x + y\cdot i
    \end{align*}
    $\C = \R^2$ mit obiger Multiplikation und Addition. Wir identifizieren $\R$ mit $\R\times\set{0}$ als Teilmenge von $\C$.\\
    Was ist das Inverse von $z=x+y\cdot i$?
    \begin{definition}[Komplexe Konjugation]
        $\overline{z} \definedas \overline{x+yi} \definedas x-yi$
    \end{definition}

    \begin{align*}
        z\cdot\overline{z} &= (x+yi) \cdot (x-yi)\\
        &= (x^2-(yi)^2) = x^2+y^2 = \abs{z}^2\\
        \impl \abs{z} &= \sqrt{z\cdot\overline{z}}\\
        \frac{1}{z} &= \frac{\overline{z}}{z\cdot\overline{z}} = \frac{z}{\abs{z}^2} = \frac{x-yi}{x^2+y^2} = \frac{x}{x^2+y^2} - \frac{y}{x^2+y^2}\cdot i
    \end{align*}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 21. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \marginnote{[21. Dez]}

    Wie $\R^d$ wollen wir auch $\C^d$ definieren.

    \begin{definition}[Der Raum $\C^d$]
        \begin{align*}
            \C^d &\definedas \set{\pair{z_1, \dots, z_d} ~\middle | ~ z_j \in\C}\\
            u &= \pair{u_1, \dots, u_d} \in\R^d\\
            w &= \pair{w_1, \dots, w_d} \in\R^d\\
            u+w &= \pair{u_1+w_1,\dots,u_d+w_d}\\
            \lambda\cdot u &= \pair{\lambda u_1,\dots,\lambda u_d}\tag{$\lambda\in\C$}
        \end{align*}
        $\C^d$ ist ein komplexer Vektorraum.

        \begin{align*}
            \abs{u} &\definedas \sqrt{\pair{\sum_{j=1}^{d} \abs{u_j}^2}}\tag{Euklidische Länge}\\
            u &= \pair{u_1, \dots, u_d}\\
            &= \pair{x_1+y_1i, x_2 + y_2 i,\dots, x_d + y_d i}\\
            &= \pair{x_1, x_2,\dots,x_d} + \pair{y_1,y_2,\dots,y_d}i\\
            ???
        \end{align*}
    \end{definition}

    \begin{definition}[]
        \begin{align*}
            \overline{u} &\definedas x - yi\quad (u=x+iy, x,y\in\R^d)\\
            \C^d &= \R^{2d}\\[10pt]
            u &= x + yi\\
            x &= \frac{1}{2}\pair{u+\overline{u}}\quad y = \frac{1}{2i}\pair{u-\overline{u}}
        \end{align*}
    \end{definition}

    Zu ?? im $\R^d$
    \begin{align*}
        \norm{x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{x_j}^2}} \geq c\\
        \norm{\lambda x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{\lambda x_j}^2}} = \abs{\lambda}\norm{x}_2
    \end{align*}

    Wann gilt die Dreiecksungleichung?\\
    Auf $\R^d$ gibt es ein Skalarprodukt.\\
    \begin{align*}
        \sprod{x,y} &\definedas \sum_{j=1}^{d} x_j\cdot y_j\tag{$x,y\in\R^d$}\\
        \impl \sprod{x,x} &\definedas \sum_{j=1}^{d} \pair{x_j}^2 = \norm{x}^2_2\\
        \norm{x}_2 &= \sqrt {\sprod{x,x}}
        \intertext{Auch}
        \sprod{x_1+x_2,y} &= \sprod{x_1,y} + \sprod{x_2,y}\\
        \sprod{x,y_1+y_2} &= \sprod{x,y_1} + \sprod{x,y_2}\\
        \sprod{\alpha x,y} &= \alpha \sprod{x,y}\\
        \sprod{x,\alpha y} &= \alpha \sprod{x,y}
    \end{align*}

    \begin{uebung}
        Rechnen Sie die vorherigen Eigenschaften des Skalarprodukts nach.
    \end{uebung}

    \begin{align*}
        \norm{x}_2^2 &= \sprod{x,x}\quad\forall x\in\R^d
        \intertext{Es sei $t\in\R$}
        \norm{x+ty}^2_2 &= \sprod{x+ty, x+ty}\\
        &= \sprod{x,x+ty} + \sprod{ty,x+ty}\\
        &= \sprod{x,x} + \sprod{x+ty} + \sprod{ty,x} + \sprod{ty+ty}\\
        &= t\sprod{x,y}\\
        &= \sprod{x,x} + 2t\sprod{x,y} + t^2\sprod{y,y}
        \intertext{Genauso}
        \norm{x-ty}_2^2 &= \sprod{x-ty, x-ty}\\
        &= \sprod{x,x} - 2t\sprod{x,y} + t^2\sprod{y,y}\\
        &= \norm{x}_2^2 t^2 - 2\sprod{x,y}t + \norm{x}_2^2
        \intertext{Sei $y\neq 0$}
        &= \norm{x}_2^2 \cdot\pair{t^2 - \frac{2\sprod{x,y}}{\norm{y}^2} + \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2 - \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2} + \norm{x}_2^2\\
        \intertext{Wir erhalten im Sinne eines Polynoms $a = \norm{y}_2^2\quad b= \sprod{x,y}\quad c= \norm{x}_2^2$}
        &= a\cdot\pair{t^2 - \frac{2b}{a}t + \pair{\frac{b}{a}}^2} + c\\
        &= a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c
        \intertext{Da wir am Anfang der Rechnung eine Norm verwendet haben, muss der Ausdruck nicht-negativ sein}
        a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c &\geq 0\quad\forall t\in\R
        \intertext{Das heißt wir müssen haben}
        \frac{b^2}{a} + c &\geq 0\\
        \equivalent b^2 \leq ac\\
        \equivalent \sprod{x,y}^2 &\leq \norm{y}_2^2 \cdot\norm{x}_2^2\\
        \equivalent \abs{\sprod{x,y}} &\leq \norm{y}_2 \norm{x}_2\tag{Cauchy-Schwarzer-Ungl.}
    \end{align*}

    Und ist $y \neq 0$ und gilt $\abs{\prod{x+y}} = \norm{x}_2 \norm{y}_2$. Dann sind $x$ und $y$ linear abhängig. Das heißt
    \begin{align*}
        \exists t\in\R \text{ mit } x = ty
    \end{align*}
    \begin{proof}
        Dann gilt
        \begin{align*}
            b^2 &= ac\quad \frac{b^2}{a} ac = 0\\
            \impl 0 &\leq \norm{x-ty}^2_2 = a\abs{t-b}^2\\
            &= 0 \text{ für $t=b$ }\\
            \impl \norm{x-ty}_2 &= 0 \text{ für } t=b\\
            \impl x-ty &= 0\\
            \impl x&= ty\qedhere
        \end{align*}
    \end{proof}
    Erkentnis: Aus Cauchy-Schwarzer folgt die Dreiecksungleichung für die Euklidische Norm.

    \begin{align*}
        \norm{x+y}_2^2 &= \sprod{x+y,x+y}\\
        &= \sprod{x,x+y}+ \sprod{y,x+y}\\
        &= \sprod{x,x} + 2 \sprod{x,y} + \sprod{y,y}\\
        &= \norm{x}_2^2 + 2\sprod{x,y} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\abs{\sprod{x,y}} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\norm{x}_2 \norm{y}_2 + \norm{y}^2\\
        &= \pair{\norm{x}_2 + \norm{y}_2}^2\\
        \impl \norm{x+y}_2 &\leq \norm{x}_2 + \norm{y}_2\tag{Dreiecksungleichung für Eukl. Norm}
    \end{align*}

    \noindent Frage: Was passiert, wenn $\norm{x+y}_2 = \norm{x}_2 + \norm{y}_2$?\\
    (Später)

    \newpage


    \section{Polynome}
    \input{Kapitel/Polynome}


    \section{[*] Cauchyprodukt und Exponentialfunktionen}
    \thispagestyle{pagenumberonly}

    \subsection{[*] Cauchyprodukt}
    Frage: Gegeben Reihen $\sum_{n=0}^{\infty} a_n$, $\sum_{n=0}^{\infty} b_n$, beide konvergent. Wie kann man das Produkt $\pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n}$ geschickt berechnen?\\
    \begin{align*}
        u &= \sum_{n=0}^{\infty} a_n = \lim_{n\fromto\infty} s_n\quad s_n \definedas \sum_{l=0}^{n} a_l\\
        v &= \sum_{n=0}^{\infty} b_n = \lim_{n\fromto\infty} t_n \quad t_n \definedas \sum_{j=0}^{n} b_j\\
        \impl u\cdot v &= \lim_{n\fromto\infty} s_n \cdot \lim_{n\fromto\infty} t_n = \lim_{n\fromto\infty} \pair{s_n\cdot t_n}\\[10pt]
        s_n \cdot t_n &= \sum_{l=0}^{n} a_l \cdot \sum_{j=0}^{n} b_j = \sum_{l=0}^{n} \sum_{j=0}^{n} a_l\cdot b_j
    \end{align*}
    Fakt: Indexmenge der Produkte $a_l b_j$ ist $\N_0 \times \N_0$.
    \begin{align*}
        = \set{(l,j):~l,j\in\N_0} &= \N_0\times\N_0
    \end{align*}
    Es gibt (viele) Bijektionen $\sigma: \N_0 \fromto \N_0\times\N_0$ zum Beispiel durch Schrägabzählen.\\
    Frage: Ist $\sigma: \N_0 \fromto \N_0\times\N_0$ eine beliebige Bijektion, gilt dann
    \begin{align*}
        \pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n} &= \sum_{n=0}^{\infty} a_{\sigma_1(n)}\cdot b_{\sigma_2(n)}\\
        \sigma(n) &= \pair{\sigma_1(n), \sigma_2(n)}
    \end{align*}
    Antwort: Im Allgemeinen nein, aber okay, wenn $\sum_{n}^{} a_n$, $\sum_{n}^{} b_n$ absolut konvergent sind.

    \begin{satz} % Satz 1
        \label{satz:cauchyprodukt}
        Seien $\sum_{n=0}^{\infty} a_n$, $\sum_{n=0}^{\infty} b_n$ absolut konvergente Reihen. Dann gilt für jede Bijektion $\sigma: \N_0 \fromto \N_0\times\N_0$
        \begin{align*}
            \pair{\sum_{n=0}^{\infty} a_n} \cdot \sum_{n=0}^{\infty} b_n &= \sum_{n=0}^{\infty} a_{\sigma_1(n)} \cdot b_{\sigma_2(n)}
            \intertext{Das heißt mit $\sigma(n)=\pair{\sigma_1(n), \sigma_2(n)}$}
            c_n &\definedas a_{\sigma_1(n)}\cdot b_{\sigma_2(n)}\\
            u\cdot v &= \sum_{n=0}^{\infty} c_n
            \intertext{mit der Reihe $\sum_{n=0}^{\infty} c_n$ auch absolut konvergent}
        \end{align*}
        Ferner gilt
        \begin{align*}
            u\cdot v &= \sum_{l=0}^{\infty} \pair{\sum_{j=0}^{\infty} a_l\cdot b_j} \tag{Vertikal zuerst}\\
            &= \sum_{j=0}^{\infty} \pair{\sum_{l=0}^{\infty} a_l\cdot b_j}\tag{Horizontal zuerst}
        \end{align*}
        und
        \begin{align*}
            u\cdot v &= \sum_{k=0}^{\infty} \pair{\sum_{0\leq j,l~l+j=k}^{} a_l\cdot b_j} \tag{Schräg abzählen}
        \end{align*}

        \begin{align*}
            \sum_{k=0}^{L} \abs{a_{\sigma_1(k)}\cdot b_{\sigma_2(k)}} &\leq \sum_{0\leq l\leq M_L~0\leq j\leq M_L}^{} \abs{a_l\cdot b_j} = \pair{\sum_{l=0}^{M_L} \abs{a_l}} \cdot \pair{\sum_{j=0}^{M_L} \abs{b_j}}\\
            &\leq \pair{\sum_{l=0}^{\infty} \abs{a_l}} \cdot \pair{\sum_{j=0}^{\infty} \abs{b_j}}\\
            M_L &\definedas \max_{0\leq k\leq L}\pair{\max\pair{\sigma_1(k), \sigma_2(k)}}
        \end{align*}
        \marginnote{[11. Jan]}
        Insbesondere gilt
        \begin{align*}
            \pair{\sum_{j=0}^{\infty} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k} &= \sum_{n=0}^{\infty} \pair{\sum_{j,k\geq 0~j+k=n}^{} a_j\cdot b_k}\\
            &= \sum_{n=0}^{\infty} \pair{a_n b_0 + a_{n-1} b_1 + \dots + a_0 b_n}\tag{Cauchy-Produkt}
        \end{align*}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 11. Januar 2024
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}
            1. Schritt:
            \begin{align*}
                k' \definedas \sum_{j=0}^{\infty} \abs{a_j} &< \infty\\
                k'' \definedas \sum_{k=0}^{\infty} \abs{b_k} &< \infty\\
                n\in\N_0: \pair{\sum_{j=0}^{n} \abs{a_j}}\cdot\pair{\sum_{k=0}^{n} \abs{b_k}}\\
                &= \sum_{j=0}^{n} \sum_{k=0}^{n} \abs{a_j}\abs{b_k} \leq k'\cdot k''\quad\forall n\in\N_0
                \intertext{Sei}
                \sigma: \N_0\fromto\N\times\N
                \intertext{eine beliebige Bijektion. Behauptung 1: $ \sum_{n=0}^{\infty} c_n$ ist absolut konvergent, wobei}
                c_n &\definedas a_{\sigma_1(n)}b_{\sigma_2(n)} = a_j b_k\tag{$j=\sigma_1(n)$, $k=\sigma_2(n)$}
                \intertext{Sei $L\in\N_0$}
                M_L^1 &\definedas \max_{n=0,1,\dots, L}\pair{\sigma_1(n)}\\
                M_L^2 &\definedas \max_{n=0,1,\dots, L}\pair{\sigma_2(n)}\\
                M_L &\definedas \max\pair{M_L^1, M_L^2}\\[10pt]
                \impl \abs{c_n} &\leq \abs{a_j}\abs{b_n} \text{ für } 0\leq j \leq M_L^1, 0\leq n \leq M_L^2\\
                \sum_{n=0}^{L} \abs{c_n} &\leq \sum_{j=0}^{M_L} \sum_{k=0}^{M_L} \abs{a_j}\abs{b_k}\\
                &= \pair{\sum_{j=0}^{M_L} \abs{a_j}}\cdot\pair{\sum_{k=0}^{M_L} \abs{b_k}} \leq k' \cdot k'' < \infty\quad\forall L\in\N_0\\
                \impl \sum_{n=0}^{\infty} \abs{c_n} &= \sup_{L\in\N_0} \sum_{n=0}^{L} \abs{c_n} \leq k'\cdot k''<\infty
                \intertext{Schritt 2:}
                s&\definedas \sum_{n=0}^{\infty} c_n \in\R
                \intertext{unabhängig von der Reihenfolge, in der man die $c_n$ aufsummiert, wegen absoluter und damit unbedingter Konvergenz. Das heißt für jede Bijektion $\kappa: \N_0\fromto\N_0\times\N_0$ ist}
                s &= \sum_{n=0}^{\infty} a_{\kappa_1(n)}b_{\kappa_2(n)}\tag{$\sigma\circ\kappa^{-1}$ Bijektion}
                \intertext{Schritt 3: Wir zeigen, dass}
                s &= \pair{\sum_{n=0}^{\infty} a_n}\cdot\pair{\sum_{n=0}^{\infty} b_n}
                \intertext{Sei $\sigma:\N_0\fromto\N_0\times\N_0$ Bijektion durch Quadratabzählen. ($c_0=a_{0} b_0$, $c_1 = a_1 b_0$, $c_2=a_1, b_1$, $c_3=a_0 b_2$)}
                \text{Partialsumme } \sum_{k=0}^{n} c_k &= \sum_{k=0}^{n} a_{\sigma_1(k)} b_{\sigma_2(k)} \text{ mit $\sigma$ Quadratabzählen }
                \intertext{Wir betrachten die Folge}
                \sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k
                \intertext{Da $\sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k$ die Summe der geschlossenen Quadrate ist, ist diese eine Teilfolge von $\sum_{k=0}^{n} c_k$ und beide haben den gleichen Grenzwert.}
                \impl s=\sum_{k=0}^{n} c_k &= \lim_{L\fromto\infty} \sum_{j=0}^{L} \sum_{k=0}^{L} a_j b_k = \lim_{L\fromto\infty} \pair{\sum_{j=0}^{L} a_j}\cdot\pair{\sum_{k=0}^{L} b_k}\\
                &= \pair{\sum_{j=0}^{\infty} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k}
                \intertext{Schritt 4: Cauchy-Produkt}
                \sum_{n=0}^{L} \sum_{\substack{0\leq j,k\\ j+k=n}}^{} a_j b_k &= \sum_{n=0}^{L} \pair{\sum_{j=0}^{L} a_j b_{L-j}}
                \intertext{ist Teilfolge der Folge $\sum_{n}^{} c_n$ mittels Schrägabzählen}
                \impl \lim_{L\fromto\infty} \sum_{n=0}^{L} \sum_{j=0}^{L} a_j b_{L-j} &= \sum_{n=0}^{\infty} c_{\sigma(n)} = s\qedhere
            \end{align*}
        \end{proof}
    \end{satz}
    \vspace{0.5cm}

    \par\noindent\rule[0.25\baselineskip]{.37\textwidth}{0.4pt}\hfill Einschub: Abzählungen\hfill\rule[0.25\baselineskip]{.37\textwidth}{0.4pt}

    \begin{definition}[Unendliche Mengen]
        Es sei $A_n\definedas\set{1,2,\dots, n}$. Eine Menge $B$ ist unendlich groß, wenn $B\neq\emptyset$ und keine Bijektion $\kappa: A_n \fromto B$ für ein beliebiges $n$ existiert.
    \end{definition}

    \begin{beispiel}[Vergleich von Kardinalitäten unendlicher Mengen]
        Wir wollen zeigen, dass $\linterv{0,1}$ und $\interv{0,1}$ gleich groß sind. Wir können alle Zahlen auf sich selber abbilden außer der 1. Wir versuchen $1\mapsto\frac{1}{2}$, $\frac{1}{2}\mapsto\frac{1}{3}$, $\frac{1}{3}\mapsto\frac{1}{4}$, \dots.\\
        Damit können wir alle rationalen Zahlen, die sich als Bruch mit 1 im Zähler darstellen lassen, verschieben. Wir definieren:
        \begin{align*}
            \sigma: \interv{0,1}&\fromto\linterv{0,1}\\
            x&\mapsto
            \begin{cases}
                \frac{1}{n+1},\quad &x=\frac{1}{n} \text{ mit } n\in\N\\
                x,\quad &x\in\interv{0,1}\exclude(\bigcup_{n\in\N} \frac{1}{n})
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{bemerkung}[Beispiel für eine Abzählung von $\N\times\N$]
        \label{bem:abzaehlen-nxn}
        Wir wollen eine bijektive Abbildung $\sigma: \N\fromto\N\times\N$ konstruieren.\\
        Level $l\in\N: A_l = \set{\pair{j,k}: j+k = l+1,~j,k\in\N}$ (schrägen Diagonalen).\\
        Anzahl Punkte in $\N\times\N$ auf Level $l\leq k$ mit
        \begin{align*}
            \sum_{l=1}^{k} l &= \frac{k(k+1)}{2}
            \intertext{Schreibe}
            n &= \frac{k(k+1)}{2} + r\quad r\in\set{0,1,2,\dots, k}, k\in\N
            \intertext{Das ist eine Eindeutige Zerlegung von $\N$. Definiere}
            \sigma{n} &= \pair{\sigma_1(n), \sigma_2(n)}\\
            &\definedas \pair{k-r, r}\\
            \sigma_1(n) &= k-r\\
            \sigma_2(n) &= r
        \end{align*}
    \end{bemerkung}

    \begin{uebung}
        Weisen Sie die Bijektivität der definierten Funktion $\sigma$ aus Bemerkung~\ref{bem:abzaehlen-nxn} nach.
    \end{uebung}

    \par\noindent\rule{\textwidth}{0.4pt}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 16. Januar 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{bemerkung}
        \marginnote{[16. Jan]}
        Letzter Schritt: Cauchy-Produkt:
        \begin{align*}
            \sum_{n=0}^{\infty} &= \sum_{n=0}^{\infty} \sum_{\nu=0}^{\infty} a_{\nu}\cdot b_{n-\nu}\\
            &= \pair{\sum_{j=0}^{n} a_j}\cdot\pair{\sum_{k=0}^{\infty} b_k}
        \end{align*}
    \end{bemerkung}

    \newpage

    \subsection{Exponentialfunktionen}

    \begin{definition}[Exponentialfunktion]
        Es sei $z\in\C$. Dann gilt
        \begin{align*}
            e^z = \exp(z)\definedas \sum_{n=0}^{\infty} \frac{z^n}{n!}
        \end{align*}
        Außerdem ist $z^0=1$.
    \end{definition}

    \begin{satz}[Eigenschaften der Exponentialfunktion]
        \theoremescape
        \begin{enumerate}[label=(\alph*)]
            \item Für alle $z\in\C$ konvergiert die obige Reihe absolut. (Wohldefiniertheit der $\exp$-Funktion)
            \item Es gilt $\exp(z_1)\cdot\exp(z_2) = \exp(z_1+z_2)$. Insbesondere ist $\exp(z)\neq 0~\forall z\in\C$ und $\exp(z)^{-1} = \exp(-z)$.
            \item $\conj{\exp(z)} = \exp(\conj{z})$
            \item $\abs{\exp(z)} = \exp(\Re(z))$
            \item $e^x = \exp(x) > 0\quad\forall x\in\R$
        \end{enumerate}

        \begin{proof}[Beweis (a)]
            Wir zeigen, dass die Reihe absolut konvergiert.
            \begin{align*}
                a_n &= \frac{1}{n!}\cdot z^n
                \intertext{Nach dem Quotientenkriterium (\ref{satz:quotientenkriterium})}
                \abs{\frac{a_{n+1}}{a_n}} &= \frac{z}{n+1}\fromto 0 \text{ für } n\fromto\infty\\
                \impl \sum_{n=0}^{\infty} a_n &= \sum_{n=0}^{\infty} \frac{z^n}{n!}\text{ konvergiert absolut}\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (b)]
            \begin{align*}
                \exp(z_1) \cdot \exp(z_2) &= \pair{\sum_{j=0}^{\infty} \frac{z^j}{j!}} \cdot \pair{\sum_{k=0}^{\infty} \frac{z^k}{k!}} \annot{=}{\ref{satz:cauchyprodukt}} \sum_{n=0}^{\infty} \sum_{\nu=0}^{n} a_{\nu} b_{n-\nu}\\
                &= \sum_{n=0}^{\infty} \sum_{\nu=0}^{n} \frac{(z_1)^{\nu}}{\nu!}\cdot \frac{(z_2)^{n-\nu}}{(n-\nu)!}\\
                &= \sum_{n=0}^{\infty} \frac{1}{n!}\cdot \underbrace{\sum_{\nu=0}^{n} \frac{n!}{\nu!\cdot(n-\nu)!}\cdot (z_1)^{\nu}\cdot (z_2)^{n-\nu}}_{\text{Binomischer Lehrsatz}}\\
                &= \sum_{n=0}^{\infty} \frac{1}{n!}\cdot(z_1+z_2)^n = \exp(z_1 + z_2)\qedhere
                \intertext{Insbesondere}
                \exp(z)\cdot \exp(-z) &= \exp(z-z) = e^0 = 1\\
                \impl \Bigg\{
                \begin{split}
                    \exp(z), \exp(-z) &\neq 0 \quad \forall z\in\C\\
                    \exp(z)^{-1} &= \exp(-z)
                \end{split}
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (c)]
            \begin{align*}
                \conj{\exp(z)} &= \conj{\sum_{k=0}^{\infty} \frac{z^k}{k!}} = \sum_{k=0}^{\infty} \conj{\frac{z^k}{k!}} = \sum_{k=0}^{\infty} \frac{\conj{z^k}}{k!} = \sum_{k=0}^{\infty} \frac{\pair{\conj{z}}^k}{k!} = \exp(\conj{z})\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (d)]
            \begin{align*}
                \abs{\exp(z)}^2 &= \conj{\exp(z)}\cdot \exp(z) = \exp(\conj{z})\cdot \exp(z)\\
                &= \exp(\conj{z} + z) = \exp(2\cdot \Re(z))\\
                &=\exp(\Re(z)+ \Re(z)) = \pair{\exp(\Re(z))}^2\\[10pt]
                \impl \abs{\exp(z)} &= \abs{\exp(\Re(z))} = \exp(\Re(z))\qedhere
            \end{align*}
        \end{proof}
        \begin{proof}[Beweis (e)]
            \begin{align*}
                \text{Ist } x \geq 0 &\impl \exp(x) = \sum_{n=0}^{\infty} \frac{x^n}{n!}= 1 + \sum_{n=1}^{\infty} \frac{x^n}{n!}\geq 1\\
                \text{Ist } x < 0 &\impl \exp(x) = \frac{1}{\exp(-x)} > 0\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Definition von Sinus und Kosinus über Expontentialfunktionen]
        Für $\alpha\in\R$ ist $\abs{\exp(i\alpha)}=1$. Wir setzen
        \begin{align*}
            \cos(\alpha) \definedas \Re (e^{i\alpha}) &= \frac{1}{2} \cdot\pair{e^{i\alpha} + e^{-i\alpha}}\\
            \sin(\alpha) \definedas \Im (e^{i\alpha}) &= \frac{1}{2i}\cdot\pair{e^{i\alpha}-e^{-i\alpha}}
            \intertext{Dann haben wir}
            -1 \leq \cos \alpha &\leq 1\\
            -1 \leq \sin \alpha &\leq 1
            \intertext{Außerdem gilt $\forall \alpha\in\R$}
            \cos(\alpha)^2 + \sin(\alpha)^2 &= 1\\
            \cos(\alpha) + i\cdot\sin(\alpha) &= e^{i\alpha} \tag{Eulersche Gleichung}
        \end{align*}

        \begin{proof}
            Es sei $\alpha\in\R$.
            \begin{align*}
                \abs{\exp(i\alpha)}^2 &= \conj{\exp(i\alpha)}\cdot \exp(i\alpha) = \exp(-i\alpha)\cdot \exp(i\alpha) = \exp(0) = 1\\[10pt]
                \Re(e^{i\alpha}) &= \frac{1}{2}\cdot\pair{e^{i\alpha} + \conj{e^{i\alpha}}} = \frac{1}{2}\cdot\pair{e^{i\alpha} + e^{-i\alpha}} \definedasbackwards \cos \alpha\\
                \Im(e^{i\alpha}) &= \frac{1}{2i}\cdot\pair{e^{i\alpha} - \conj{e^{i\alpha}}}= \frac{1}{2i}\cdot\pair{e^{i\alpha} - e^{-i\alpha}}\definedasbackwards \sin \alpha\\[10pt]
                \impl \abs{\exp(i\alpha)}^2 &= \pair{\Re(\exp(i\alpha))}^2 + \pair{\Im(\exp(i\alpha))}^2\\
                &= \pair{\cos (\alpha)}^2 + \pair{\sin (\alpha)}^2\\[10pt]
                \exp(i\alpha) &= \Re (\exp(i\alpha)) + i\cdot \Im (\exp(i\alpha)) = \cos \alpha + i \cdot \sin \alpha\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage


    \section{[*] Potenzreihen}
    \imaginarysubsection{Potenzreihen}
    \thispagestyle{pagenumberonly}

    Wir untersuchen Reihen der Form $ \sum_{n=0}^{\infty} a_n\cdot z^n$ oder $ \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n$, $z_0\in\C$ fest, $z\in\C$ oder $\R$, $a_n\in\C$.\\
    Partialsummen:
    \begin{align*}
        s_n(z) &\definedas \sum_{j=0}^{n} a_j\cdot z^j
    \end{align*}
    Frage: Konvergenz?
    \begin{beispiel}
        \begin{align*}
            \exp(z) &\definedas \sum_{n=0}^{\infty} \frac{1}{n!} z^n\\
            &= \sum_{n=0}^{\infty} n! \cdot z^n \text{ konvergiert nur für } z=0
        \end{align*}
    \end{beispiel}

    \begin{definition}[Konvergenzradius]
        \begin{align*}
            R &\definedas \sup \set{\abs{z}: z\in\C \text{ und } \sum_{n=0}^{\infty} a_n \cdot z^n \text{ konvergent } }
        \end{align*}
        $R$ ist der Konvergenzradius.
    \end{definition}

    \begin{satz}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut für jedes $z$ in der Kreisscheibe
        \begin{align*}
            B_R (a) &= \set{z\in\C: \abs{z} < R}
        \end{align*}
        Für jedes $\abs{z} > R$ divergiert $ \sum_{n=0}^{\infty} a_n \cdot z^n$.
        \begin{proof}
            Sei $z_1\neq 0$. $ \sum_{n=0}^{\infty} a_n \cdot z^n$ konvergiert.
            \begin{align*}
                \impl (a_n \cdot z^n) \text{ Nullfolge }\\
                \impl \text{ ist beschränkt }\\
                \impl K\definedas \sup_{n\in\N} \set{a_n z^n} < \infty
                \intertext{Sei $0 < r < \abs{z_1}$, $0 < \theta \definedas \frac{r}{\abs{z_1}} < 1$}
                z &\leq \conj{B_r (a)} = \set{\abs{z} \leq r}\\[10pt]
                \abs{a_n z^n} &= \abs{a_n}\abs{z^n} = \abs{a_n} \cdot \abs{z}^n &= \abs{a_n} \cdot \abs{z}^n \frac{\abs{z}}{\abs{z_1}} ^n\\
                &\leq k \theta^n\quad \forall n \geq 0\\
                \impl \sum_{n=0}^{\infty} k \theta^n \text{ konvergente Majorante für } \sum_{n=0}^{\infty} a_n z^n \text{ sofern } 0 \leq z \leq r < \abs{z}\\
                \impl \sum_{n}^{} a_n z^n \text{ konvergiert absolut }\\[12pt]
                \impl (1) \sum_{n=0}^{\infty} a_n z^n \text{ konvergiert für alle } \abs{z} \leq r\\
                \impl (2) \text{ Angenommen } \sum_{n}^{} a_n z^n \text{ konvergiert für ein } \abs{z} > R\\
                (2) \impl \text{ Widerspruch zu Definition von } R
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Konvergiere $ \sum_{n}^{} a_n z^n$ und $ \sum_{n}^{} b_n z^n$ für $\abs{z} < R$
        \begin{align*}
            \impl \sum_{n=0}^{\infty} \pair{\lambda a_n + \mu b_n} z^n &= \lambda \sum_{n=0}^{\infty} a_n z^n + \mu \sum_{n=0}^{\infty} b_n z^n
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Konvergieren $ \sum_{n=0}^{\infty} a_n z^n$, $ \sum_{n=0}^{\infty} b_n z^n$ auf $B_R (0)$
        \begin{align*}
            \impl \pair{\sum_{n=0}^{\infty} a_n z^n} \cdot \pair{\sum_{n=0}^{\infty} b_n z^n} = \sum_{n=0}^{\infty} \pair{\sum_{\nu=0}^{\infty} a_{\nu} b_{n-\nu}} z^n \tag{Cauchy-Produkt}
            \intertext{Sei $0 < r < R$ für $\abs{z} \leq r$}
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Wir können auch Potenzreihen der Form
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n, \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n \text{ mit } a_n\in\R^d \text{ oder } \C^d
        \end{align*}
        betrachten. Wir setzen
        \begin{align*}
            R &= \sup \set{\abs{z}: z\in\C und \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 2
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut $\forall z\in B_R (0)$ und divergiert für $\abs{z} > R$.

        \begin{proof}
            Abschreiben des Beweises von Satz 1.
        \end{proof}
    \end{satz}

    \begin{lemma}
        Konvergiert $ \sum_{n=0}^{\infty} a_n z^n$ für ein $z=z_1 \neq 0$ und ist $0 < r < \abs{z_r}$. So ist $ \sum_{n=0}^{\infty} a_n z^n$ auf $B_r (0) = \set{\abs{z} \leq r}$ beschränkt.\\
        Das heißt $\exists M = M_r \geq 0$ mit $\abs{\sum_{n=0}^{\infty} a_n z^n} \leq M_r~\forall \abs{z} \leq r$

        \begin{proof}
            \begin{align*}
                \theta &\definedas \frac{r}{\abs{z_1}} < 1
                \intertext{Da $ \sum_{n=0}^{\infty}  a_n z_1^n$ konvergiert ist}
                (a_n z_n^n)_n \text{ Nullfolge also beschränkt }
                \impl K &= \sup_{n\in\N_0} \abs{a_n z_1^n} = \sup_{n\in\N} \abs{a_n} \abs{z_1}^n < \infty\\
                \intertext{Ist $\abs{z} < r$}
                \abs{a_n z^n} &= \abs{a_n} \abs{z}^n = \abs{a_n} \abs{z_1}^n \abs{\frac{\abs{z}}{\abs{z_1}}}^n\\
                \impl \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq \sum_{n=0}^{\infty} \abs{a_n z}^n \leq \sum_{n=0}^{\infty} k \theta^n = \frac{k}{1-\theta} < \infty\quad \forall \abs{z} \leq r
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{lemma} % Lemma 4
        \label{lemma:temp-4}
        Annahmen wie bei vorherigem Lemma.
        \begin{align*}
            \impl \text{ Für alle } 0 &< r < \abs{z_1}\quad\forall k\in\N_0\\
            \text{ existiert } M &= M_k, r\geq 0
            \intertext{mit}
            \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}\quad\forall \abs{z} \leq r
        \end{align*}

        \begin{proof}
            \begin{align*}
                \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert auch }\\
                \impl \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} &= z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert }\\
                \impl \text{ verschobene Reihe } \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} \text{ konvergiert }\\
                \annot{\impl}{Lemma 3} \text{ Für } 0 < r < z_1  \text{ existiert ein } M = M_{k,r} \geq 0
                \intertext{sodass}
                \abs{\sum_{n=k+1}^{\infty} a_n z^{n-(k+1)}} &\leq M_r\quad\forall \abs{z} \leq r < \abs{z_1}\\
                \text{ (linke Seite) } &= \abs{z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n}\\
                &= \frac{1}{\abs{z}^{k+1}} \abs{\sum_{n=k+1}^{\infty} a_n z^n}\\
                \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{anwendung}
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n &= \underbrace{\sum_{n=0}^{k} a_n z^n}_{s_k (z)} + \underbrace{\sum_{n=k+1}^{\infty} a_n z^n}_{Fehler}\\
            \abs{Fehler} &\leq M_{k,r} \abs{z}^{k+1} \leq M_{k,r} \theta^{k+1} \tag{$\theta = \frac{r}{\abs{z_1}}$}
        \end{align*}
    \end{anwendung}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 18. Januar 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    Bessere Version von Lemma~\ref{lemma:temp-4}:

    \begin{align*}
        \varphi(z) &= \sum_{n=0}^{\infty} a_n z^n\\
        \abs{\varphi(z) - \sum_{n=k}^{\infty} a_n z^n} &= \abs{\sum_{n=0}^{k} a_n z^n} \leq M_{r,z} \cdot \abs{z}^{k+1}\quad 0< r < \abs{z_1}
        \intertext{Sei $ \sum_{n=0}^{\infty} a_n z^n$ konvergent für ein $z=z_1\neq 0$}
        \impl \forall~ 0< r < \abs{z_1}\colon \text{ existiert }  M_{r,z_1} &> 0
        \intertext{sodass}
        \forall k\in\N_0\colon \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq M_{r,z_1} \abs{\frac{z}{z_1}}^{k+1}\quad\forall \abs{z} \leq r\\
        \abs{\frac{z}{z_1}} &\leq \frac{\abs{z}}{\abs{z_1}} \leq \frac{r}{\abs{z_1}} = \theta < 1
    \end{align*}

    \begin{proof}
        \begin{align*}
            \sum_{n\geq 0}^{} a_n z_1^n \text{ konvergiert }\\
            \impl \pair{a_n z_1^n}_n \text{ ist Nullfolge }\\
            k &\definedas \sup_{n\geq 0} \abs{a_n z_1^n} &< \infty\\
            \impl \abs{a_n z^n} &= \abs{a_n z_1^n \pair{\frac{z}{z_1}}^n} = \abs{a_n z_1^n} \abs{\frac{z}{z_1}}^n\\
            \abs{\frac{z}{z_1}} &\leq \frac{r}{\abs{z_1}} = \theta < 1\\
            \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &= \sum_{n=k+1}^{\infty} \abs{a_n z^n}\\
            &\leq \sum_{n=k+1}^{\infty} K \cdot \abs{\frac{z}{z_1}}^n\\
            &= k\cdot \abs{\frac{z}{z_1}}^{k+1} \cdot \sum_{n=0}^{k} \abs{\frac{z}{z_1}}^n\\
            &= \frac{k}{1-\theta} \abs{\frac{z}{z_1}}^{k+1} = \frac{K}{1-\frac{r}{??}}\cdot ??
        \end{align*}
    \end{proof}

    \begin{satz} % Satz 5
        \marginnote{[18. Jan]}

        Sei $ \sum_{n=0}^{\infty}$ eine Potenzreihe, die für ein $z=z_1\neq 0$ konvergiert.\\
        $(z_j)_j$: Folge $0< \abs{z_j} < \abs{z_1}$, $z_j \fromto 0$, $j\fromto\infty$ mit
        \begin{align*}
            \sum_{n=0}^{\infty} a_n (z_j)^n &= 0\quad\forall j\in\N\\
            \impl a_n &= 0\quad\forall n\in\N_0
        \end{align*}
        \begin{proof}
            Angenommen nicht alle $a_n=0$
            \begin{align*}
                \impl B &\definedas \set{n\in\N_0: a_n \neq 0} \neq \emptyset\\
                \impl B \text{ hat ein kleinstes Element, nennen wir } n_0\\
                \impl a_0 &= a_1 = \dots = a_{n_0-1} = 0\quad a_{n_0}\neq 0\\
                f(z) &= \sum_{n=0}^{\infty} a_n z^n = \sum_{n=n_0}^{\infty} a_n z^n = a_{n_0} z^{n_0} + \sum_{n=n_0 + 1}^{\infty} a_n z^n\\
                f(z_1) &= 0\quad\forall j\quad z_j \neq 0\quad z_j\fromto 0\\
                \impl \abs{a_{n_0} (z_j)^{n_0}} &= \abs{- \sum_{n=n_0 + 1}^{\infty} a_n z_j^n} \leq M_{r, z_1} \pair{\frac{\abs{z_j}}{\abs{z_1}}}^{n+1}\\
                \impl \abs{a_{n_0}} \leq M_{r,z} \abs{z_1}^{-(n_0+1)}\quad \abs{z_j} \fromto 0\quad j\fromto\infty\\
                \impl a_{n_0} &= 0\tag{Widerspruch}
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz} % Satz 6
        Sei $ \sum_{n=0}^{\infty} a_n z^{n}$, $ \sum_{n=0}^{\infty} b_n z^n$ welche für ein $z=w\neq 0$ konvergieren.\\
        $(z_j)_j$ Folge in $\C$, $z_1\neq 0$, $\forall i, z_i \fromto 0$\\
        mit $ \sum_{n=0}^{\infty} a_n z^n = \sum_{n=0}^{\infty} b_n z_j^n$ für fast alle $z_j$.\\
        Dann ist $a_n = b_n~\forall n\in\N_0$.
        \begin{proof}
            \begin{align*}
                c_n &= a_n - b_n
                \intertext{\OBDA sind alle $\abs{z_1} < \abs{w}$}
                \impl h(z) &\definedas \sum_{n=0}^{\infty} c_n z^n \text{ konvergiert für } z=w\neq 0\\
                \text{ und } h(z_j) &= 0\quad \forall j\\
                \annot{\impl}{Satz 5} c_n &= 0\quad \forall n\in\N_0 \equivalent a_n = b_n \quad\forall n\in\N_0
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Hatten geg. $ \sum_{n=0}^{\infty} a_n z^n$. Dann ist der Konvergenzradius
        \begin{align*}
            R &= \sup \set{\abs{z} : z\in\C \text{ und } \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 7
        \begin{align*}
            R &= \frac{1}{\limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}}
        \end{align*}

        \begin{proof}
            Schritt 1: Zu zeigen: Für $\abs{z} < R$ konvergiert die Potenzreihe.
            \begin{align*}
                M &= \limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}\\
                \impl \forall \varepsilon > 0~\exists N \colon \sqrt[n]{\abs{a_n}} &\leq M+\varepsilon\\
                \impl \forall \varepsilon > 0 \text{ ist } \sqrt[n]{\abs{a_n}} &> M- \varepsilon \text{ für fast alle } n
            \end{align*}
            Schritt 2: Zu zeigen: Für $\abs{z} > R$ konvergiert die Potenzreihe nicht. (Übung)
        \end{proof}
    \end{satz}

    \begin{korollar}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ und $ \sum_{n=1}^{\infty} n a_n z^{n-1}$ haben den gleichen Konvergenzradius.
        \begin{proof}
            Folgt mit vorherigem Satz und $\sqrt[n]{n}\fromto 1$ für $n\fromto\infty$.
        \end{proof}
    \end{korollar}

    \newpage


    \section{Stetige Funktionen einer reellen (oder komplexen) Variablen}
    \input{Kapitel/Stetigkeit}


    \section{Der Zwischenwertsatz}
    \input{Kapitel/Zwischenwertsatz}


    \section{Der Satz von Weierstraß}
    \input{Kapitel/Satz_Weierstrass}


    \section{Grenzwerte von Funktionen}
    \imaginarysubsection{Grenzwerte von Funktionen}
    \thispagestyle{pagenumberonly}

    \begin{definition}[Häufungspunkte]
        $A\subseteq\K$ hat den Häufungspunkt $x_0\in\K$, falls
        \begin{align*}
            \forall\varepsilon > 0~\exists x\in A\exclude\set{x_0}\colon \abs{x-x_0} < \varepsilon
        \end{align*}
    \end{definition}

    \begin{definition}[Diskrete Punkte]
        Für $A\subseteq\K$ ist $x_0\in A$ ein diskreter Punkt, falls
        \begin{align*}
            \exists \varepsilon > 0\colon \abs{x-x_0} \geq \varepsilon\quad\forall x\in A\exclude\set{x_0}
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        \theoremescape
        \begin{enumerate}[label=(\roman*)]
            \item Häufungspunkte müssen keine Elemente von $A$ sein.
            \item $x_0$ ist genau dann ein Häufungspunkt von $A$, wenn $\exists$ Folge $(x_n)_n\subseteq A\exclude\set{x_0}$ mit $x_n\fromto x_0$ für $n\fromto\infty$ (weil $0<\abs{x_n-x_0}\fromto 0$)
        \end{enumerate}
    \end{bemerkung}

    \begin{definition}[Grenzwerte von Funktionen]
        Sei $f: D\fromto\R$ (oder $\R^d$) und $x_0$ Häufungspunkt von $D$. Wir sagen $f(x)$ strebt gegen $a$ bei Annäherung von $x$ gegen $x_0$ -- geschrieben $f(x)\fromto a$ für $x\fromto x_0$ oder $\biglim{x\fromto x_0} f(x) = a$ -- falls
        \begin{align*}
            \forall \varepsilon > 0~\exists \delta > 0\colon \abs{f(x)-a} < \varepsilon \text{ für alle } x\in D,~0 < \abs{x-x_0} < \delta
        \end{align*}
        Wir sagen $a$ ist der Limes oder Grenzwert von $f(x)$ oder $f(x)$ konvergiert gegen $a$ für $x\fromto x_0$.
    \end{definition}

    \begin{bemerkung}
        Es gilt $f(x)\fromto a$ für $x\fromto x_0$ genau dann, wenn
        \begin{align*}
            \forall\varepsilon > 0~\exists \delta > 0\colon \abs{f(x)-a} &< \varepsilon\quad\fa x\in D\cap \dot{B}_{\delta}(x_0)\\
            \dot{B}_{\delta}(x_0) &\definedas \set{x~\middle|~0 < \abs{x-x_0} < \delta}\\
            \dot{B}_{\delta}(x_0) &= B_{\delta}(x_0) \exclude\set{x_0}\tag{punktierter $\delta$-Ball um $x_0$}
        \end{align*}
    \end{bemerkung}

    \begin{satz}
        \label{satz:16-3}
        Sei $f: D\fromto\R$ (oder $\R^d$) und $x_0$ Häufungspunkt von $D$. Dann gilt $\biglim{x\fromto x_0} f(x) = a$ genau dann, wenn für jede Folge $(x_n)_n\subseteq D\exclude\set{x_0}$ mit $x_n\fromto x_0$ folgt $ \biglim{n\fromto\infty} f(x_n) = a$.
        \begin{proof}
            \anf{$\impl$}: Klar nach Definition. (Selber machen)\\
            \anf{$\Leftarrow$}: Kontraposition. Angenommen $ \biglim{n\fromto\infty} f(x) \neq a$.
            \begin{align*}
                \impl \exists\varepsilon > 0~\forall \delta > 0&\colon \abs{f(x)-a} \geq \varepsilon \text{ für ein } x\in D\exclude\set{x_0}\colon \abs{x-x_0} < \delta
                \intertext{Nehmen $\delta = \frac{1}{n}$}
                \impl \exists \text{ Folge } &(x_n)_n\subseteq D\exclude\set{x_0} \text{ mit } x_n\fromto x_0 \text{ und } \abs{f(x_n)-a} \geq \varepsilon\\
                \impl f(x_n) &\text{ konvergiert nicht gegen } a\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beispiel}
        Für $D = \R\exclude\set{1}$, $f(x) = \frac{x^2-1}{x-1}$ gilt $\biglim{x\fromto 1} f(x) = 2$\\
        \begin{align*}
            f(x) = \frac{x^2-1}{x-1} = \frac{(x+1)(x-1)}{x-1} = x + 1 \fromto 2 \text{ für } x\fromto 1
        \end{align*}
    \end{beispiel}

    \newpage

    \begin{beispiel}[Ausblick: Differenzierbarkeit und Ableitung]
        $f: \interv{0,T}\fromto \R^3$ Kurve.
        \begin{align*}
            \varphi(h) &= \frac{f(t+h)-f(t)}{h}\tag{$h\neq 0$}
            \intertext{Falls $\biglim{h\fromto 0} \varphi(h)$ existiert, nennen wir $f$ in $t$ differenzierbar und definieren die Ableitung}
            f'(t) &\definedas \lim_{h\fromto 0} \varphi(h)
        \end{align*}
    \end{beispiel}

    \begin{lemma} % Lemma 4
        \label{lemma:16-4}
        Für $f: D\fromto\R^d$, $f=(f_1, \dots, f_d)$, $x_0$ Häufungspunkt von $D$, $a=(a_1, \dots, a_d)$ gilt
        \begin{align*}
            \lim_{x\fromto x_0} f(x) = a\quad\equivalent\quad \lim_{n\fromto x_0} f_j(x) = a_j~~\forall 1\leq j\leq d
        \end{align*}

        \begin{proof}
            Sei $\norm{f(x)-a}$ Euklidischer Abstand von $f(x)$ zu $a$.
            \begin{align*}
                \norm{f(x)-a} &= \sqrt{\sum_{j=1}^{d} \pair{f_j(x) - a_j}^2}\\
                \impl \forall 1\leq j\leq d\colon \abs{f_j(x) - a_j} &\leq \norm{f(x) - a} \leq \sqrt{d}\cdot\max_{1\leq l\leq d} \abs{f_l(x) - a_l}\qedhere
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{satz} % Satz 5
        \label{satz:16-5}
        Es sei $D\subseteq\R$ und $f,g: D\fromto \C$. Gilt $\biglim{x\fromto x_0} f(x) = a$, $\biglim{x\fromto x_0} g(x) = b$ so folgt
        \begin{enumerate}[label=(\alph*)]
            \item $\biglim{x\fromto x_0} (\lambda f(x) + \mu g(x)) = \lambda a + \mu b\quad(\lambda, \mu\in \C)$
            \item $\biglim{x\fromto x_0} f(x)\cdot g(x) = a\cdot b$
            \item Ist $b \neq 0$ so gilt $\biglim{x\fromto x_0} \frac{f(x)}{g(x)} = \frac{a}{b}$
            \item Sind $f,g: D\fromto \R^d$ so gilt $\biglim{x\fromto x_0} (\lambda f(x) + \mu g(x)) = \lambda a + \mu b\quad(\lambda, \mu\in \R)$
        \end{enumerate}
        \begin{proof}[Beweis (c)]
            Wegen (b) reicht es zu zeigen, dass $\frac{1}{g(x)} \fromto \frac{1}{b}$ für $x\fromto x_0$
            \begin{align*}
                \abs{\frac{1}{g(x)} - \frac{1}{b}} &= \frac{\abs{b-g(x)}}{\abs{g(x)}\cdot\abs{b}}
                \intertext{Sei $\varepsilon >0$ beliebig $\impl \exists\delta > 0$ sodass für $x\in D$, $0 < \abs{x-x_0} < \delta$ auch $\abs{g(x)-b} < \min\set{\frac{\abs{b}}{2}, \frac{\abs{b}^2}{2}\cdot\varepsilon}$. Für diese $x$ gilt}
                \abs{g(x)} = \abs{b+g(x)-b} &\geq \abs{b}-\abs{g(x)-b} > \abs{b} - \frac{\abs{b}}{2} = \frac{\abs{b}}{2}
                \intertext{und somit auch}
                \abs{\frac{1}{g(x)} - \frac{1}{b}} = \frac{\abs{g(x)-b}}{\abs{g(x)}\cdot\abs{b}} &\leq \frac{2}{\abs{b}^2}\cdot\abs{g(x)-b} < \frac{2}{\abs{b}^2}\cdot \frac{\abs{b}^2}{2}\cdot\varepsilon = \varepsilon\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{uebung}
        Beweisen Sie die übrigen Aussagen des vorherigen Satzes.
    \end{uebung}

    \begin{satz}[Cauchykriterium für Existenz von $\biglim{x\fromto x_0} f(x)$] % Satz 6
        \label{satz:16-6}
        Sei $x$ Häufungspunkt von $D$ und $f: D\fromto \R$ (oder $\R^d$). Dann gilt, dass $\biglim{x\fromto x_0} f(x)$ genau dann existiert, wenn
        \begin{align*}
            \forall \varepsilon > 0~\exists\delta>0 \text{ sodass für } x,y\in D \text{ mit } 0 < \abs{x-x_0} < \delta, 0 < \abs{y-y_0} < \delta\\
            \abs{f(x)-f(y)} < \varepsilon \text{ ist }
        \end{align*}

        %%%%%%%%%%%%%%%%%%%%%%%%
        % 30. Januar 2023
        %%%%%%%%%%%%%%%%%%%%%%%%

        \begin{proof}
            \marginnote{[30. Jan]}
            \anf{$\impl$}: Wir haben $\ex a\in\R$ (oder $\R^d$) sodass
            \begin{align*}
                \fa \varepsilon > 0\ex \delta > 0\colon \abs{f(x)-a} &< \frac{\varepsilon}{2} \text{ für } 0 < \abs{x-x_0} < \delta\\
                \impl \abs{f(x)-f(y)} = \abs{f(x)-a + a - f(y)} &\leq \abs{f(x)-a} + \abs{a-f(y)} < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon
            \end{align*}
            \anf{$\Leftarrow$}: Wir müssen zeigen, dass für jede Folge $(x_n)_n\sbset D, x_n \neq x_0, x_n\fromto x_0$ folgt $f(x_0)\fromto a$ für $\ntoinf$
            \begin{align*}
                \intertext{1. Schritt: Sei $(x_n)_n\sbset D, x_n\fromto x_0, x_n\neq x_0$. Haben}
                \abs{f(x)-f(y)} &< \varepsilon\quad\forall 0 < \abs{x-x_0} < \delta~0<\abs{y-x_0} < \delta\\
                \intertext{Da $x_n\fromto x_0$}
                \impl \ex N\in\N\colon \abs{x_n - x_0} &< \delta\quad\fa n\geq N\\
                \impl \fa n,m\geq N\colon \abs{f(x_n)-f(x_m)} &< \delta\\
                \impl (f(x_n))_n &\text{ ist eine Cauchy-Folge}\\
                \impl \lim_{\ntoinf} f(x_n) &\definedasbackwards a \text{ existiert}
                \intertext{2. Schritt: $a$ ist unabhängig von der gewählten Folge $(x_n)_n$. Sei $(y_n)_n\sbset D, y_n\fromto x_0, y_n\neq x_0$}
                \impl b&\:= \lim_{\ntoinf} f(y_n) \text{ existiert auch nach Schritt 1}
                \intertext{Warum ist $a=b$? Wir basteln eine neue Folge $x_1, y_1, x_2, y_2, \dots, x_n, y_n, \dots$}
                z_{2n} &\:= y_n\\
                z_{2n+1} &\:= y_{n}\\
                \impl z_n &\fromto x_0\\
                \annot{\impl}{Schritt 1} c &\:= \lim_{\ntoinf} f(z_n) \text{ existiert}
                \intertext{Teilfolgen konvergieren auch gegen $c$}
                c &= \lim_{\ntoinf} f(z_n) = \lim_{\ntoinf} f(y_n) = b\\
                &= \lim_{\ntoinf} f(z_{2n+1}) = \lim_{\ntoinf} f(x_n) = a\\
                \impl a &= b
            \end{align*}
            Das heißt für jede Folge $(x_n)_n\sbset D, x_n\fromto x_0$ konvergiert $f(x_0)$ gegen ein eindeutiges $a$.
        \end{proof}
    \end{satz}

    \begin{definition} % Definition 7
        Sei $D\sbset\R$, $f: D \fromto \R$ (oder $\R^d$), $x_0$ Häufungspunkt in $D$. Dann heißt $a$ rechtsseitiger Grenzwert von $f$ in $x_0$, falls
        \begin{align*}
            \fa\varepsilon > 0\ex\delta > 0\colon \abs{f(x)-a} < \varepsilon \text{ für } 0 < x-x_0 < \delta, x\in D
        \end{align*}
        Wir schreiben $f(x + 0) = \biglim{x\fromto x_0^+} f(x) = \biglim{x\searrow x_0} f(x)$.\\
        $a$ heißt linksseitiger Grenzwert, falls
        \begin{align*}
            \fa\varepsilon > 0\ex\delta > 0\colon \abs{f(x)-a} < \varepsilon \text{ für } -\delta < x-x_0 < 0, x\in D
        \end{align*}
        Wir schreiben $f(x_0) - 0 = \biglim{x\fromto x_0^-} f(x) = \biglim{x\nearrow x_0} f(x)$.\\
        Wir sagen $f$ hat Grenzwert $a$ für $x\->\infty$, falls $D$ nach oben unbeschränkt ist und
        \begin{align*}
            \fa\varepsilon > 0\ex k\colon \abs{f(x)-a} < \varepsilon\quad\fa x\in D, x>k
        \end{align*}
        $a=\biglim{x\->\infty} f(x)$ und ähnlich für $\biglim{x\-> -\infty} f(x)$. ($h(x) = f(-x)$)
    \end{definition}

    \begin{satz} % Satz 8
        \label{satz:16-8}
        Sei $D\sbset \R$, $f: D\-> \R$ (oder $\R^d$), $x_0$ HP von $D$. Dann gilt
        \begin{align*}
            f \text{ ist stetig in } x_0 &\equivalent \lim_{x\fromto x_0} f(x) = f(x_0)\\
            &\equivalent \lim_{x\nearrow x_0} f(x) = \lim_{x\searrow x_0} f(x) = f(x_0)
        \end{align*}
    \end{satz}

    \begin{uebung}
        Beweisen Sie Satz~\ref{satz:16-8}.
    \end{uebung}

    \newpage


    \section{[*] Gleichmäßige Stetigkeit und gleichmäßge Konvergenz}
    \imaginarysubsection{Gleichmäßige Stetigkeit und gleichmäßge Konvergenz}
    \thispagestyle{pagenumberonly}

    \begin{definition}[Gleichmäßige Stetigkeit] % Def 1
        Sei $f: D\-> \R$ (oder $\R^d$) und $D\sbset\K$. $f$ heißt gleichmäßig stetig auf $D$, falls
        \begin{align*}
            \fa\varepsilon > 0\colon \abs{f(x)-f(y)} < \varepsilon \text{ für reelle } x,y\in D \text{ mit } \abs{x-y} < \delta
        \end{align*}
    \end{definition}

    \begin{beispiel}
        \begin{align*}
            f: \R\->\R,~x\mapsto\frac{1}{1+x^2}
        \end{align*}
        ist gleichmäßig stetig. (Übung)
    \end{beispiel}
    \begin{beispiel}
        \begin{align*}
            f: \rinterv{a,b}\-> \R,~x\mapsto \frac{1}{x}
        \end{align*}
        ist stetig, aber nicht gleichmäßig stetig.
        \begin{proof}
            Für $0 < x < y = 2x$ gilt
            \begin{align*}
                \abs{f(x)-f(y)} &= \abs{\frac{1}{x} - \frac{1}{y}} = \frac{\abs{y-x}}{xy} = \frac{1}{y}\geq 1
            \end{align*}
        \end{proof}
    \end{beispiel}

    \begin{definition}[Lipschitz-Stetigkeit]
        Eine Funktion $f: D\->\R$ (oder $\R^d$) heißt Lipschitz-stetig, falls
        \begin{align*}
            \ex L\geq 0\colon \abs{f(x)-f(y)} \leq L\cdot\abs{x-y}\quad\forall x,y\in D
        \end{align*}
        Jede Lipschitz-stetige Funktion ist gleichmäßig stetig. $(\delta = \frac{\varepsilon}{L})$
    \end{definition}

    \begin{satz}[Heine, 1872] % Satz 3
        \label{satz:17-3}
        Sei $K\sbset\R$ kompakt und $f: K\->\R$ (oder $\R^d$) stetig. Dann ist $f$ gleichmäßig stetig.
        \begin{proof}
            Angenommen $f$ ist nicht gleichmäßig stetig.
            \begin{align*}
                \impl\ex\varepsilon > 0\fa \delta > 0\ex x,y\in K\colon\abs{x-y} < \delta \text{ und } \abs{f(x)-f(y)} > \varepsilon
                \intertext{Wähle $\delta = \frac{1}{n}$}
                \impl\ex x_n, y_n\sbset K\colon \abs{x_n- y_n} < \frac{1}{n}\\
                \intertext{aber $\abs{f(x_n)-f(y_n)} \geq \varepsilon > 0$}
                \impl x_n - y_n \-> 0 \text{ für } n\->\infty
                \intertext{Da $K$ kompakt}
                \impl \ex \text{ Konvergente TF } (y_{n_l})_l \text{ von } (y_n)_n\quad (n_1 < n_2 < n_3 < \dots < n_l < n_{l+1})\\
                y\:= \lim_{l\toinf} (y_{n_l}) \text{ existiert } \in K\\
                \abs{x_{n_l} - y} = \abs{x_{n_l} - y_{n_l} + y_{n_l} - y} \leq \abs{x_{n_l} - y_{n_l}} + \abs{x_{n_l} - y}\fromto 0\\
                \impl \abs{f(x_{n_l}) - f(y_{n_l})} \geq \varepsilon > 0
                \intertext{Aber}
                \abs{f(x_{n_l}) - f(y_{n_l})} = \abs{f(x_{n_l}) - f(y) + f(y) - f(y_{n_l})} \leq \underbrace{\abs{f(x_{n_l}) - f(y)}}_{\-> 0} + \underbrace{\abs{f(y)-f(y_{n_l})}}_{\-> 0}\tag{Widerspruch}
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{definition} % Def 4
        Wir betrachten Folgen von Funktionen $f_n: D\-> \R$ (oder $\R^d$) $\leadsto$ Folge $(f_n)_n$ von Funktionen.\\
        $(f_n)_n$, $f_n: D\->\R$ (oder $\R^d$) konvergiert punktweise falls
        \begin{align*}
            \lim_{\ntoinf} f_n(x) \text{ existiert für jedes } x\in D
        \end{align*}
        Das heißt $(f_n(x))_n$ ist konvergente Folge $\fa x\in\R$.\\
        Dann setzen wir
        \begin{align*}
            f(x) \:= \lim_{\ntoinf} f_n(x)
        \end{align*}
        definiert eine Funktion $f: D\-> \R$ (oder $\R^d$). Sogar $f$ ist der punktweise Limes der Funktionenfolge $f_n$. $f_n(x)\-> f(x)~\fa x\in D$
    \end{definition}

    \begin{beispiel}
        \begin{align*}
            f_n(x) &= x^n\quad 0 \leq x \leq 1
            \intertext{konvergiert punktweise gegen}
            f(x) &= \begin{cases}
                        0\quad &\text{für } 0 \leq x < 1\\
                        1\quad &\text{für } x = 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        \begin{align*}
            f_n(x) &= x^{\frac{1}{n}}\quad 0 \leq x \leq 1
            \intertext{stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        0\quad&x = 0\\
                        1\quad&0 < x \leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        \begin{align*}
            f_n(x) &= (1-x^2)^{\frac{n}{2}}\quad -1 \leq x \leq 1
            \intertext{stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        1\quad&x = 0\\
                        0\quad&0 < \abs{x}\leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Gleichmäßige Konvergenz. Weierstraß 1841] % Definition 5
        $D\sbset\R$, Funktionenfolge $f_n: D\->\R$ (oder $\R^d$). $(f_n)_n$ konvergiert gleichmäßig gegen $f: D\->\R$ (oder $\R^d$) falls
        \begin{align*}
            \fa\varepsilon > 0\ex N\in \N \text{ mit } \abs{f_n(x) - f(x)} < \varepsilon\quad\fa n\geq N, x\in D
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        Also ist
        \begin{align*}
            \sup_{x\in D} \abs{f_n(x) - f(x)} &\leq \varepsilon\\
            \lim_{\ntoinf} \sup_{x\in D}\abs{f(_n(x) - f(x))} &= 0
        \end{align*}
    \end{bemerkung}


\end{document}
