\documentclass[11pt, twoside, a4paper]{article}

% Setup
\usepackage[margin=2.4cm, top=3.5cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}

% Package imports
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{setspace}
\usepackage{float}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[pagestyles]{titlesec}
\usepackage{fancyhdr}
\usepackage{colonequals}
\usepackage{caption}
\usepackage{tikz}
\usepackage{marginnote}
\usepackage{etoolbox}
\usepackage{mdframed}
\usepackage{aligned-overset}

% Font-Encoding
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Theorems
\newtheorem{blockelement}{Blockelement}[subsection]
\newtheoremstyle{plain}{}{}{}{}{\bfseries}{.}{ }{}
\theoremstyle{plain}
\newtheorem{bemerkung}[blockelement]{Bemerkung}
\newtheorem{definition}[blockelement]{Definition}
\newtheorem{lemma}[blockelement]{Lemma}
\newtheorem{satz}[blockelement]{Satz}
\newtheorem{notation}[blockelement]{Notation}
\newtheorem{korollar}[blockelement]{Korollar}
\newtheorem{uebung}[blockelement]{Übung}
\newtheorem{beispiel}[blockelement]{Beispiel}
\newtheorem{folgerung}[blockelement]{Folgerung}
\newtheorem{axiom}[blockelement]{Axiom}
\newtheorem{beobachtung}[blockelement]{Beobachtung}
\newtheorem{konzept}[blockelement]{Konzept}
\newtheorem{visualisierung}[blockelement]{Visualisierung}
\newtheorem{anwendung}[blockelement]{Anwendung}
\newtheorem{skizze}[blockelement]{Skizze}

% Marginnotes left
\makeatletter
\patchcmd{\@mn@@@marginnote}{\begingroup}{\begingroup\@twosidefalse}{}{\fail}
\reversemarginpar
\makeatother

% Long equations
\allowdisplaybreaks

% \left \right
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pair}[1]{\left(#1\right)}
\newcommand{\of}[1]{\mathopen{}\mathclose{}\bgroup\left(#1\aftergroup\egroup\right)}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\linterv}[1]{\left[#1\right)}
\newcommand{\rinterv}[1]{\left(#1\right]}
\newcommand{\interv}[1]{\left[#1\right]}
\newcommand{\sprod}[1]{\left<#1\right>}

% Shorten commands
\newcommand{\equivalent}[0]{\Leftrightarrow{}}
\newcommand{\impl}[0]{\Rightarrow{}}
\newcommand{\fromto}{\rightarrow{}}
\newcommand{\definedas}[0]{\coloneqq}
\newcommand{\definedasbackwards}[0]{\eqqcolon}
\newcommand{\definedasequiv}[0]{\ratio\Leftrightarrow{}}
\newcommand{\exclude}[0]{\setminus}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\sbset}{\subseteq}

\newcommand{\ntoinf}[0]{n\fromto\infty}
\newcommand{\toinf}{\fromto\infty}
\newcommand{\fa}{\;\forall\,}
\newcommand{\ex}{\;\exists\,}
\newcommand{\conj}[1]{\overline{#1}}

\newcommand{\annot}[3][]{\overset{\text{#3}}#1{#2}}
\newcommand{\biglim}[1]{{\displaystyle \lim_{#1}}}
\newcommand{\nn}[0]{\\[2\baselineskip]}
\newcommand{\anf}[1]{\glqq{}#1\grqq}
\newcommand{\OBDA}{o.B.d.A. }
\newcommand{\theoremescape}{\leavevmode}
\newcommand{\aligntoright}[2]{\hfill#1\hspace{#2\textwidth}~}
\newcommand{\horizontalline}[0]{\par\noindent\rule{0.05\textwidth}{0.1pt}\\}
\newcommand{\rgbcolor}[3]{rgb,255:red,#1;green,#2;blue,#3}
\newcommand{\fixedspace}[2]{\makebox[#1][l]{#2}}

\let\Re\relax
\let\Im\relax

% MathOperators
\DeclareMathOperator{\grad}{Grad}
\DeclareMathOperator{\bild}{Bild}
\DeclareMathOperator{\Re}{Re}
\DeclareMathOperator{\Im}{Im}

% Mengenbezeichner
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}

\newcommand\imaginarysubsection[1]{
    \refstepcounter{subsection}
    \subsectionmark{#1}
}

% Unfassbar hässlich, aber effektiv für temporäre schnelle Lösungen
\def\:={\coloneqq}
\def\->{\fromto}
\def\=>{\impl}
\def\<={\leq}
\def\>={\geq}
\def\!={\neq}

% Envs
\newenvironment{induktionsanfang}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Anfang}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}
\newenvironment{induktionsvoraussetzung}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Vor.}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}
\newenvironment{induktionsschritt}{
    \rule{0pt}{3ex}\noindent
    \begin{minipage}[t]{0.11\textwidth}
    {I-Schritt}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.89\textwidth}
    }
    {
    \end{minipage}
}

% Section style
\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\large\bfseries}

% Page styles
\newpagestyle{pagenumberonly}{
    \sethead{}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\newpagestyle{headfootdefault}{
    \sethead[][][\thesubsection~\textit{\subsectiontitle}]{\thesection~\textit{\sectiontitle}}{}{}
    \setfoot[][][\thepage]{\thepage}{}{}
}
\pagestyle{headfootdefault}

\begin{document}
    \title{\vspace{3cm} Skript zur Vorlesung\\Analysis I\\bei Prof. Dr. Dirk Hundertmark}
    \author{Karlsruher Institut für Technologie}
    \date{Wintersemester 2023/24}
    \maketitle
    \begin{center}
        Dieses Skript ist inoffiziell. Es besteht kein\\ Anspruch auf Vollständigkeit oder Korrektheit.
    \end{center}
    \thispagestyle{empty}
    \newpage

    \tableofcontents
    ~\\
    Alle mit [*] markierten Kapitel sind noch nicht korrektur gelesen und bedürfen eventuell noch Änderungen.
    \newpage


    \section{Aussagenlogik}
    \input{Kapitel/Aussagenlogik}


    \section{Mengen}
    \input{Kapitel/Mengen}


    \section{Die Axiome der reellen Zahlen}
    \input{Kapitel/Reelle_Zahlen}


    \section{Die natürlichen Zahlen $\N$ und vollständige Induktion}
    \input{Kapitel/Natuerliche_Zahlen}


    \section{Summe, Produkt, Wurzeln}
    \input{Kapitel/Summe_Produkt_Wurzeln}


    \section{Folgen und Grenzwerte}
    \input{Kapitel/Folgen_Grenzwerte}


    \section{Dichtheit von $\Q$ in $\R$}
    \input{Kapitel/Dichtheit}


    \section{Reihen (und Konvergenz von Reihen)}
    \input{Kapitel/Reihen}


    \section{[*] $\R^d$, Konvergenz im $\R^d$, die komplexen Zahlen $\C$ und der Raum $\C^d$}

    \subsection{Der Raum $\R^d$ und Normen}

    \thispagestyle{pagenumberonly}

    \begin{definition}
        \begin{align*}
            \R^d &\definedas\text{ Vektorraum der reellen $d$-Tupel}\\
            &=\set{\pair{x_1, x_2, \dots, x_d} ~\middle|~ x_j\in\R,~ j=1,\dots,d }\\
        \end{align*}
    \end{definition}

    \begin{notation}[Linearkombination von Vektoren]
        Es sei
        \begin{align*}
            x&= \pair{x_1, \dots, x_d}\\
            y&= \pair{y_1, \dots, y_d}
            \intertext{und $\alpha, \beta \in \R$, dann gilt}
            \alpha x + \beta y &\definedas \pair{\alpha x_1 + \beta y_1, \alpha x_2 + \beta y_2, \dots, \alpha x_d + \beta y_d}
        \end{align*}
    \end{notation}

    \begin{notation}[Vektorschreibweise]
        \begin{align*}
            x = \begin{pmatrix}
                    x_1 \\ \vdots \\ x_d
            \end{pmatrix}
        \end{align*}
    \end{notation}

    \horizontalline
    Im $\R$ haben wir Konvergenz über den Betrag definiert. Im $\R^d$ benötigen wir daher ein ähnliches Konzept. Wir betrachten dafür zunächst einige Beispiele solcher \textit{Normen}.

    \begin{beispiel}[Euklidische Länge eines Vektors]
        Für $d=2$ gilt für die euklidische Länge $\norm{x}$ eines Vektors $x\in\R^2$
        \begin{align*}
            \norm{x}^2 &= (x_1)^2 + (x_2)^2\\
            \norm{x} &= \sqrt{(x_1)^2 + (x_2)^2}
        \end{align*}
        Allgemein gilt
        \begin{align*}
            \norm{x} &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
            \intertext{Wir schreiben auch}
            \norm{x}_2 &\definedas \sqrt{\pair{\sum_{j=1}^{d} (x_j) ^2}}\tag{$x\in\R^d$}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}[Andere Normen]
        Neben der euklidischen lassen sich noch weitere Normen definieren. Zum Beispiel
        \begin{align*}
            \norm{x}_1 &\definedas \sum_{j=1}^{d} \abs{x_j} \tag{Manhattan-Norm}\\
            \norm{x}_{\infty} &\definedas \max_{1\leq j \leq d} \abs{x_j}\tag{Maximums-Norm}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Norm] % Definition 1
        Eine Norm auf $\R^d$ (oder einem reellen Vektorraum) ist eine Abbildung
        \begin{align*}
            \norm{.}: \R^d\fromto \R
        \end{align*}
        mit folgenden Eigenschaften:
        \begin{enumerate}[label=\alph*)]
            \item $\norm{x} \geq 0~\forall x\in\R^d$ sowie $\norm{x} = 0\impl x=0$
            \item $\forall\lambda\in\R,~x\in\R^d\colon \norm{\lambda x} = \abs{\lambda}\cdot\norm{x}$
            \item $\forall x,y\in\R^d\colon\norm{x+y} \leq \norm{x} + \norm{y}$\quad\text{(Dreiecksungleichung)}
        \end{enumerate}
    \end{definition}

    \begin{bemerkung}
        Dass a), b) und c) für $\norm{\cdot}_1$ und $\norm{\cdot}_{\infty}$ gelten, ist einfach zu zeigen. Außerdem sind a) und b) für $\norm{\cdot}_2$ einfach zu zeigen, c) ist tricky. (Übung)
    \end{bemerkung}

    \begin{definition}[Äquivalenz von Normen]
        2 Normen $\norm{\cdot}_a$ und $\norm{\cdot}_b$ sind äquivalent, falls
        \begin{align*}
            \exists c_1, c_2\in\R\colon c_1\cdot\norm{x}_a \leq \norm{x}_b \leq c_2 \norm{x}_a\quad\forall x\in V
        \end{align*}
    \end{definition}

    \begin{beispiel}[Äquivalenz von euklidischer und Maximums-Norm]
        \label{beispiel:norm-equiv}
        Wir zeigen, dass $\norm{\cdot}_{\infty}$ und $\norm{\cdot}_{2}$ äquivalent sind.
        \begin{align*}
            \abs{x_k} &\leq \sqrt{\sum_{j=1}^{d} \abs{x_j}^2} = \norm{x}_2\tag{$1\leq k \leq d$}\\
            \impl \norm{x}_{\infty} &= \max_{k=1,\dots, d} \abs{x_k} \leq \norm{x}_2\tag{1}
            \intertext{Umgekehrt}
            \norm{x}_2^2 = \sum_{j=1}^{d} \abs{x_j}^2 &\leq \sum_{j=1}^{d} \pair{\max_{k=1,\dots, d}\pair{\abs{x_k}}}^2 = d \cdot \norm{x}_{\infty}^2\\
            \impl \norm{x}_2 &\leq \sqrt {d}\cdot \norm{x}_{\infty}\tag{2}
            \intertext{Mit (1) und (2) gilt dann}
            \impl \frac{1}{\sqrt{d}}\cdot \norm{x}_2 &\leq\norm{x}_{\infty} \leq \norm{x}_2
        \end{align*}
    \end{beispiel}

    \begin{uebung}
        Weisen Sie die Äquivalenz von $\norm{x}_1$ und $\norm{x}_\infty$ analog zu Beispiel~\ref{beispiel:norm-equiv} nach.
    \end{uebung}

    \subsection{Konvergenz im $\R^d$}

    \begin{bemerkung}[Abstand zwischen 2 Vektoren im $\R^d$]
        Zu jeder Norm auf $\R^d$ (oder reellen Vektorräumen) definieren wir den Abstand von 2 Vektoren $x,y\in\R^d$ als $\norm{x-y}$.
        \begin{align*}
            d(x,y) &\definedas \norm{x-y}
            \intertext{Mit $z$ als weiterem Vektor gilt}
            \norm{x-y} &= \norm{x-z+z-y}\\
            &\leq \norm{x-z} + \norm{z-y}\\
            \norm{x-y} &= \norm{-(y-x)} = \abs{-1}\cdot \norm{y-x} = \norm{y-x}
        \end{align*}
    \end{bemerkung}

    \begin{folgerung}[Mehrdimensionale $\varepsilon$-Umgebung]
        Bisher basierte unser Konvergenz-Begriff auf dem Abstand von $(x_n)_n$ und $x$ und somit auf einer eindimensionalen $\varepsilon$-Umgebung.\\
        Wir verallgemeinern dieses Konzept für eine offene Kugel im $\R^d$ mit $x\in\R^d$
        \begin{align*}
            B_\varepsilon(x) \definedas \set{y\in\R^d\middle |~ \norm{x-y}_2 < \varepsilon}
        \end{align*}
    \end{folgerung}

    \begin{visualisierung}[Zweidimensionale $\varepsilon$-Umgebung]
        Wir formen die Bedingung um
        \begin{align*}
            \norm{x-y}_2 &< \varepsilon\\
            \impl \sqrt{(x_1-y_1)^2 + (x_2 - y_2)^2} &< \varepsilon\\
            \impl \pair{x_1-y_1}^2 + \pair{x_2-y_2}^2 &< \varepsilon^2
        \end{align*}
        In der Visualisierung erhalten wir einen offenen Ball um $x$ mit Radius $\varepsilon$.

        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (0,0) circle (0.75cm);
                \draw[fill=\rgbcolor{230}{230}{230}, dashed] (2,1) circle (0.75cm);
                \draw[->] (-3,0) -- (3,0);
                \draw[->] (0,-3) -- (0,3);
                \draw[->] (0,0) node {$\times$} -- (0.52, 0.52) node[below, pos=0.8] {$\varepsilon$};
                \draw[->] (2,1) node {$\times$} -- (2, 1.75) node[right, pos=0.5] {$\varepsilon$};
                \draw (-0.25, 0.35) -- (-1.5, 0.35) node[left] {$B_{\varepsilon}\pair{(0,0)}$};
                \draw (1.75, 1.35) -- (-1.5, 1.35) node[left] {$B_{\varepsilon}\pair{(x_1,x_2)}$};
                \node at (-0.75,-0.75) {1.};
                \node at (2.75,0.25) {2.};
                \node at (3,-2) {\begin{tabular}{l}
                                     1. $x=(0,0)$ \\ 2. $x=(x_1, x_2)$
                \end{tabular}};
            \end{tikzpicture}
            \caption{Zweidimensionale $\varepsilon$-Umgebungen}
        \end{figure}
    \end{visualisierung}

    \begin{definition}[Konvergenz im $\R^d$] % Definition 2
        Sei $(x_n)_n$ eine Folge in $\R^d$ mit $x_n\in\R^d~\forall n$. Dann konvergiert $(x_n)_n$ gegen $x\in\R^d$, falls
        \begin{alignat*}{2}
            \forall\varepsilon > 0~\exists N\in\N\colon& \norm{x_n-x}_2 <\varepsilon\quad&&\forall n\geq N
            \intertext{Das heißt}
            \forall\varepsilon > 0~\exists N\in\N\colon& x_n\in B_{\varepsilon}(x)\quad&&\forall n\geq N
        \end{alignat*}
    \end{definition}

    \begin{beobachtung}
        \label{beobachtung:rd-konvergenz}
        Es sei ${x_n}\in\R^d$ mit $x_n = \pair{x_n^1, x_n^2, \dots, x_n^d}$\footnote{Koordinaten von $(x_n)_n$}. Damit ergeben sich die Folgen $(x_n^1)_n$, $(x_n^2)_n$, \dots, $(x_n^d)_n$ in $\R$.
        Angenommen $(x_n)_n$ konvergiert gegen $x\in\R^d$. Dann konvergieren alle Folgen $(x_n^l)_n$ in $\R$ und $\biglim{\ntoinf} x_n^l = x^l$

        \begin{proof}
            \begin{align*}
                \abs{x_n^{l} - x^{l}}^2 &\leq \sum_{j=1}^{d} \abs{x_n^{j}-x^{j}}^2 = \norm{x_n -x}_2^2\quad \forall l=1,\dots, d\\
                \impl \abs{x_n^l-x^l} &\leq \norm{x_n-x}_2 \fromto 0\text{ für } n\fromto\infty
            \end{align*}
            Also konvergiert $(x_n^l)$ gegen $x^l$ in $\R$ für alle $l=1,\dots,d$.\qedhere
        \end{proof}
    \end{beobachtung}

    \noindent Es gilt sogar die Umkehrung:

    \begin{satz}[Konvergenz in $\R$ und $\R^d$]
        \label{satz:Rd-R-konvergenz}
        Eine Folge $(x_n)_n$ in $\R^d$ konvergiert genau dann, wenn jede der Koordinatenfolge $(x_n^l)_n$ in $\R$ konvergiert $\forall l=1,\dots, d$.

        \begin{proof}
            \theoremescape
            \anf{$\impl$} Siehe Beobachtung~\ref{beobachtung:rd-konvergenz}.\\
            \anf{$\Leftarrow$} Angenommen
            \begin{alignat*}{3}
                \exists x^l &\definedas \lim_{\ntoinf} x^l_n\quad&&\forall l=1,\dots, d\\
                \impl \abs{x_n^l - x^l} &\fromto 0 \text{ für }\ntoinf\quad&&\forall l=1,\dots, d\\
                \intertext{Das heißt}
                \forall\varepsilon > 0~\exists N_l\in\N&\colon \abs{x_n^l - x^l} < \frac{\varepsilon}{\sqrt{d}}\quad&&\forall n\geq N_{l}
                \intertext{Wir definieren $N\definedas\max\pair{N_1, N_2, \dots, N_d}$. Dann gilt}
                \norm{x_n-x}^2_2 &= \sum_{j=1}^{d} \abs{x_n^j - x^j}^2 < \sum_{j=1}^{d} \pair{\frac{\varepsilon}{\sqrt{d}}}^2\quad&&\forall n\geq N\\
                &= d\cdot\frac{\varepsilon^2}{d} = \varepsilon^2\\
                \impl \norm{x_n-x}_2 &< \varepsilon\quad&&\forall n\geq N
                \intertext{Wir definieren den Grenzwert}
                x&\definedas (x^1, x^2, \dots, x^d)\\
                x^j&\definedas \lim_{\ntoinf} x_n^j&&&\qedhere
            \end{alignat*}
        \end{proof}
    \end{satz}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 19. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{bemerkung}[Reihen im $\R^d$]
        \marginnote{[19. Dez]}
        Sei $(a_n)_n\sbset\R^d$ mit $a_n = \pair{a_n^1, a_n^2, \dots, a_n^d}$. Wie können wir die Reihe $\sum_{n=1}^{\infty} a_n$ dann definieren?. Wir betrachten die Partialsummen
        \begin{align*}
            s_n &\definedas \sum_{j=1}^{n} a_j
        \end{align*}
        und können damit die Konvergenz definieren.
    \end{bemerkung}

    \begin{definition}[Konvergenz von Reihen im $\R^d$]
        Die Reihe $\sum_{n} a_n$ konvergiert, falls die Folge der Partialsummen $(s_n)_n$ im $\R^d$ konvergiert.
    \end{definition}

    \begin{satz}[Cauchy-Kriterium für Konvergenz im $\R^d$]
        \label{satz:cauchy-Rd}
        Eine Folge $(x_n)_n$ ist genau dann in $\R^d$ konvergent, wenn $(x_n)_n$ eine Cauchy-Folge ist. Das heißt
        \begin{align*}
            \forall\varepsilon > 0~\exists N\in\N\colon \norm{x_n-x_m}_2 < \varepsilon\quad\forall n,m\geq N
        \end{align*}

        \begin{proof}
            \anf{$\impl$}: Wie im Fall $\R$.\\
            \anf{$\Leftarrow$}: Sei $(x_n)_n$ Cauchy-Folge. Dann sind alle Koordinaten $(x_n^j)_n$ Cauchy-Folgen in $\R$, weil
            \begin{align*}
                \abs{x_n^j-x_m^j} = \sqrt {\abs{x_n^j-x_m^j}^2} &\leq \sqrt {\sum_{l=1}^{d} \abs{x_n^l - x_m^l}^2} = \norm{x_1-x_m}_2\\
                \impl x_n &\definedas \lim_{\ntoinf} x_n^j\text{ existiert}\\
                \impl x &= \lim_{\ntoinf} x_n\text{ existiert}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{beobachtung}[Bolzano-Weierstraß im $\R^d$]
        Wir wollen Satz~\ref{satz:bolzano-weierstrass} im $\R^d$ zeigen:
        Jede beschränkte Folge $(x_n)_n$ in $\R^d$ besitzt eine konvergente Teilfolge. Wir sagen $(x_n)_n$ ist im $\R^d$ beschränkt, wenn
        \begin{align*}
            \exists R\geq 0\colon \norm{x_n}_2 \leq R\quad\forall n\in\N\\
            \text{bzw.} \quad x_n\in\set{y\in\R^d \middle|~ \norm{y}_2 \leq R}
        \end{align*}
        \begin{proof}
            \begin{align*}
                \forall j=1,\dots, d\colon &(x_n^j)_n\text{ beschränkte Folge}\\
                \impl \exists\text{ Teilfolge } &(x_n^1)_k\text{ von } (x_n^1)_n\text{, welche in }\R\text{ konvergiert}
                \intertext{Das heißt es gibt eine Ausdünnung $\sigma: \N\fromto\N$ mit $\sigma(k) < \sigma(k+1)$. Dann existiert der Grenzwert}
                x_1 &\definedas \lim_{\ntoinf} x_{\sigma(k)}
                \intertext{Genauso für $(x^2_n)_n$}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists \kappa\colon \N\fromto\N\colon &(x^2_{\kappa(k)})_k\text{ konvergent}
                \intertext{Catch: $(x^1_{\sigma(k)}, x^2_{\kappa(k)})_k$ ist im Allgemeinen keine Teilfolge von $(x^1_n, x^2_n)_n$. Lösung: Betrachte}
                \pair{x_{\sigma(k)}}_k\text{ Teilfolge von }&(x_n)_n = \pair{x^1_{\sigma(k)}, \dots, x^d_{\sigma(k)}}
                \intertext{Mache mit $(x^2_{\sigma(k)})_k$ weiter}
                \annot{\impl}{\ref{satz:bolzano-weierstrass}} \exists\text{ konvergente} &\text{ Teilfolge von } (x^2_{\sigma(k)})_k\\
                \intertext{Wir erhalten eine Ausdünnung $\sigma_2: \N\fromto\N$}
                \impl &\pair{x^2_{\sigma(\sigma_2(k))}}_k\text{ konvergent}\\
                \kappa_2 &\definedas \sigma \circ \sigma_{2}\\
                \impl\text{ Neue Teilfolge } &(x_{\kappa_{2}(k)}) = (x^1_{\kappa_{2}(k)},\dots, x^d_{\kappa_{2}(k)})
            \end{align*}
            Für die Teilfolge existieren $\biglim{k\fromto\infty} x^1_{\kappa_{2}(k)}$ und $\biglim{k\fromto\infty} x^2_{\kappa_{2}(k)}$. Wir machen induktiv so weiter, nach maximal $d$ Schritten sind wir fertig.
        \end{proof}
    \end{beobachtung}

    \begin{beobachtung}[Beschränktheit von Cauchy-Folgen im $\R^d$]
        Jede Cauchy-Folge in $\R^d$ ist beschränkt.
        \begin{proof}
            Sei $\varepsilon = 1$
            \begin{align*}
                \impl \exists N\colon\norm{x_n-x_m}_2 &\leq 1\quad\forall n,m\geq N\\
                \impl \forall n,m\geq N\colon \norm{x_n}_2 &= \norm{x_n-x_N+x_N}_2\\
                &\leq \norm{x_n-x_N}_2 + \norm{x_N}_2 < 1 + \norm{x_N}\\
                \impl \norm{x}_2 &\leq \max\pair{\norm{x_1}_2, \norm{x_2}_2,\dots\norm{x_{N-1}}_2, 1+\norm{x_N}_2}\qedhere
            \end{align*}
        \end{proof}
    \end{beobachtung}

    \begin{bemerkung}
        Außerdem gilt: Eine Cauchy-Folge im $\R^d$ ist genau dann konvergent, wenn sie eine konvergente Teilfolge besitzt. (Beweis wie im Fall $d=1$).\\
        Alle bisherigen Konvergenz-Sätze, welche keine Anordnung benötigen, übertragen sich auf $\R^d$.\\
        Insbesondere: Reihe $\sum_{n=1}^{\infty} a_n$ ist absolut konvergent, falls $\sum_{n=1}^{\infty} \norm{a_n}_2 < \infty$.\\
        Ist eine Reihe $\sum_{n=1}^{\infty} a_n$ in $\R^d$ absolut konvergent, so konvergieren alle Umordnungen gegen den selben Wert. Und es gilt die Umkehrung! (Satz von Dirichlet in $\R^d$)
    \end{bemerkung}

    \subsection{Die Komplexen Zahlen $\C$}

    Was sind die komplexen Zahlen?\\
    $x^2+1$ ist nie Null $\forall x\in\R$. Wir definieren eine Zahl $i$ mit $i^2=-1$ und schreiben $x+iy$ mit $x,y\in\R$. Dann ergeben sich folgende Rechenregeln:
    \begin{align*}
    (x_1 + y_1\cdot i)
        \cdot (x_2 + y_2\cdot i) &= x_1\cdot x_2 + x_1\cdot y_2\cdot i + y_1 \cdot x_2 \cdot i + y_1\cdot y_2\cdot i^2\\
        &= x_1\cdot x_2 - y_1\cdot y_2 + \pair{x_1\cdot y_2 + y_1\cdot x_2}\cdot i\\
        (x_1+y_1\cdot i) + (x_2 + y_2\cdot i) &= x_1 + x_2 + \pair{y_1+y_2}\cdot i
    \end{align*}

    \begin{definition}[Rechenregeln von Komplexen Zahlen]
        Wir betrachten die euklidische Ebene $\R^2 \definedas \set{(x,y) ~\middle|~ x,y\in\R}$.
        \begin{align*}
            z &= (x,y)\in\R^2\\
            z_1 + z_2 &\definedas (x_1, y_1) + (x_2,y_2)\\
            &\definedas (x_1 + x_2, y_1 + y_2)
            \intertext{Wir definieren eine \anf{seltsame} Multiplikation}
            z_1 \cdot z_2 &\definedas (x_1, y_1)\cdot (x_2, y_2)\\
            &\definedas \pair{x_1 x_2 - y_1 y_2,~x_1 y_2 + x_2 y_1}
            \intertext{Wir definieren den Betrag}
            \abs{z} &\definedas\text{ Länge des Vektors } (x,y) = \sqrt {x^2+y^2}\\
            \intertext{Wir nennen $x$ den Realteil von $z$ und $y$ den Imaginärteil von $z$ und schreiben}
            \Re\of{z} &= x\\
            \Im\of{z} &= y
        \end{align*}
    \end{definition}

    \begin{visualisierung}[Euklidische Ebene]
        \theoremescape
        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[->] (-3,0) -- (3,0) node[below] {$\Re$};
                \draw[->] (0,-3) -- (0,3) node[right] {$\Im$};
                \draw (0.5,0.1) -- (0.5,-0.1) node[below] {$1$};
                \draw (0.1,0.5) -- (-0.1,0.5) node[left] {$1$};
                \draw[->, blue] (0,0) -- (1,1) node[right, black] {$\pair{2+2i}$};
                \draw[->, blue] (0,0) -- (-2,0) node[below, black] {$\pair{-4+0i}$};
                \draw[->, blue] (0,0) -- (-1,-2.5) node[below, black] {$\pair{-1-5i}$};
            \end{tikzpicture}
            \caption{Komplexe Zahlen in der Euklidischen Ebene}
        \end{figure}
    \end{visualisierung}

    \newpage

    \begin{bemerkung}
        Man rechnet einfach nach, dass Multiplikation und Addition die Assoziativität, Kommutativität und Distributivität erfüllen. (Übung)\\
        Außerdem lässt sich zeigen, dass $(1,0)$ das neutrale Element der Multiplikation ist:
        \begin{align*}
        (1,0)
            \cdot (1,0) &= (1,0)\\
            z\cdot (1,0) &= (x,y)\cdot(1,0)= (x,y) = z
            \intertext{Wir definieren $e_1\definedas \pair{1,0}$, $e_2\definedas\pair{0,1}$ und erhalten}
            \pair{x,y} &= x\cdot e_1 + y\cdot e_{2}
            \intertext{Außerdem gilt}
            \pair{e_1}^2 &= e_1\\
            \pair{e_2}^2 &= -e_2
            \intertext{Zur Vereinfachung schreiben wir $1$ für $e_1$ und $i$ für $e_2$}
            z &= (x,y) = x\cdot e_1 + y\cdot e_2\\
            &= x\cdot 1 + y\cdot i\\
            &= x + y\cdot i
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        $\C = \R^2$ mit obiger Multiplikation und Addition. Wir identifizieren $\R$ mit $\R\times\set{0}$ als Teilmenge von $\C$.
    \end{bemerkung}

    \begin{definition}[Komplexe Konjugation]
        Was ist das Inverse von $z=x+y\cdot i$? Wir definieren
        \begin{align*}
            \overline{z} &\definedas \overline{x+yi} \definedas x-yi
            \intertext{Damit gilt}
            z\cdot\overline{z} &= (x+yi) \cdot (x-yi)\\
            &= (x^2-(yi)^2) = x^2+y^2 = \abs{z}^2\\
            \impl \abs{z} &= \sqrt{z\cdot\overline{z}}\\[10pt]
            \frac{1}{z} &= \frac{\overline{z}}{z\cdot\overline{z}} = \frac{z}{\abs{z}^2} = \frac{x-yi}{x^2+y^2} = \frac{x}{x^2+y^2} - \frac{y}{x^2+y^2}\cdot i
        \end{align*}
    \end{definition}

    \begin{visualisierung}[Komplexe Konjugation]
        \theoremescape
        \begin{figure}[H]
            \centering
            \begin{tikzpicture}
                \draw[->] (-3,0) -- (3,0) node[below] {$\Re$};
                \draw[->] (0,-3) -- (0,3) node[right] {$\Im$};
                \draw[->, blue] (0,0) -- (1,1.5) node[right, black] {$z_1$};
                \draw[->, blue] (0,0) -- (1,-1.5) node[right, black] {$\overline{z_1}$};
            \end{tikzpicture}
            \caption{Komplexe Konjugation in der Euklidischen Ebene}
        \end{figure}
    \end{visualisierung}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 21. Dezember 2023
    %%%%%%%%%%%%%%%%%%%%%%%%

    \subsection{[*] Der Raum $\C^d$}

    \marginnote{[21. Dez]}
    Wie $\R^d$ wollen wir nun auch $\C^d$ definieren.

    \begin{definition}[Der Raum $\C^d$]
        \begin{align*}
            \C^d &\definedas \set{\pair{z_1, \dots, z_d} ~\middle | ~ z_j \in\C}\\
            u &= \pair{u_1, \dots, u_d} \in\R^d\\
            w &= \pair{w_1, \dots, w_d} \in\R^d\\
            u+w &= \pair{u_1+w_1,\dots,u_d+w_d}\\
            \lambda\cdot u &= \pair{\lambda u_1,\dots,\lambda u_d}\tag{$\lambda\in\C$}
        \end{align*}
        $\C^d$ ist ein komplexer Vektorraum.

        \begin{align*}
            \abs{u} &\definedas \sqrt{\pair{\sum_{j=1}^{d} \abs{u_j}^2}}\tag{Euklidische Länge}\\
            u &= \pair{u_1, \dots, u_d}\\
            &= \pair{x_1+y_1i, x_2 + y_2 i,\dots, x_d + y_d i}\\
            &= \pair{x_1, x_2,\dots,x_d} + \pair{y_1,y_2,\dots,y_d}i\\
            ???
        \end{align*}
    \end{definition}

    \begin{definition}[]
        \begin{align*}
            \overline{u} &\definedas x - yi\quad (u=x+iy, x,y\in\R^d)\\
            \C^d &= \R^{2d}\\[10pt]
            u &= x + yi\\
            x &= \frac{1}{2}\pair{u+\overline{u}}\quad y = \frac{1}{2i}\pair{u-\overline{u}}
        \end{align*}
    \end{definition}

    Zu ?? im $\R^d$
    \begin{align*}
        \norm{x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{x_j}^2}} \geq c\\
        \norm{\lambda x}_2 &= \sqrt{\pair{\sum_{j=1}^{d} \abs{\lambda x_j}^2}} = \abs{\lambda}\norm{x}_2
    \end{align*}

    Wann gilt die Dreiecksungleichung?\\
    Auf $\R^d$ gibt es ein Skalarprodukt.\\
    \begin{align*}
        \sprod{x,y} &\definedas \sum_{j=1}^{d} x_j\cdot y_j\tag{$x,y\in\R^d$}\\
        \impl \sprod{x,x} &\definedas \sum_{j=1}^{d} \pair{x_j}^2 = \norm{x}^2_2\\
        \norm{x}_2 &= \sqrt {\sprod{x,x}}
        \intertext{Auch}
        \sprod{x_1+x_2,y} &= \sprod{x_1,y} + \sprod{x_2,y}\\
        \sprod{x,y_1+y_2} &= \sprod{x,y_1} + \sprod{x,y_2}\\
        \sprod{\alpha x,y} &= \alpha \sprod{x,y}\\
        \sprod{x,\alpha y} &= \alpha \sprod{x,y}
    \end{align*}

    \begin{uebung}
        Rechnen Sie die vorherigen Eigenschaften des Skalarprodukts nach.
    \end{uebung}

    \begin{align*}
        \norm{x}_2^2 &= \sprod{x,x}\quad\forall x\in\R^d
        \intertext{Es sei $t\in\R$}
        \norm{x+ty}^2_2 &= \sprod{x+ty, x+ty}\\
        &= \sprod{x,x+ty} + \sprod{ty,x+ty}\\
        &= \sprod{x,x} + \sprod{x+ty} + \sprod{ty,x} + \sprod{ty+ty}\\
        &= t\sprod{x,y}\\
        &= \sprod{x,x} + 2t\sprod{x,y} + t^2\sprod{y,y}
        \intertext{Genauso}
        \norm{x-ty}_2^2 &= \sprod{x-ty, x-ty}\\
        &= \sprod{x,x} - 2t\sprod{x,y} + t^2\sprod{y,y}\\
        &= \norm{x}_2^2 t^2 - 2\sprod{x,y}t + \norm{x}_2^2
        \intertext{Sei $y\neq 0$}
        &= \norm{x}_2^2 \cdot\pair{t^2 - \frac{2\sprod{x,y}}{\norm{y}^2} + \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2 - \pair{\frac{\sprod{x,y}}{\norm{y}^2}}^2} + \norm{x}_2^2\\
        \intertext{Wir erhalten im Sinne eines Polynoms $a = \norm{y}_2^2\quad b= \sprod{x,y}\quad c= \norm{x}_2^2$}
        &= a\cdot\pair{t^2 - \frac{2b}{a}t + \pair{\frac{b}{a}}^2} + c\\
        &= a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c
        \intertext{Da wir am Anfang der Rechnung eine Norm verwendet haben, muss der Ausdruck nicht-negativ sein}
        a\cdot\pair{t-b}^2 - \frac{b^2}{a}+c &\geq 0\quad\forall t\in\R
        \intertext{Das heißt wir müssen haben}
        \frac{b^2}{a} + c &\geq 0\\
        \equivalent b^2 \leq ac\\
        \equivalent \sprod{x,y}^2 &\leq \norm{y}_2^2 \cdot\norm{x}_2^2\\
        \equivalent \abs{\sprod{x,y}} &\leq \norm{y}_2 \norm{x}_2\tag{Cauchy-Schwarzer-Ungl.}
    \end{align*}

    Und ist $y \neq 0$ und gilt $\abs{\prod{x+y}} = \norm{x}_2 \norm{y}_2$. Dann sind $x$ und $y$ linear abhängig. Das heißt
    \begin{align*}
        \exists t\in\R \text{ mit } x = ty
    \end{align*}
    \begin{proof}
        Dann gilt
        \begin{align*}
            b^2 &= ac\quad \frac{b^2}{a} ac = 0\\
            \impl 0 &\leq \norm{x-ty}^2_2 = a\abs{t-b}^2\\
            &= 0 \text{ für $t=b$ }\\
            \impl \norm{x-ty}_2 &= 0 \text{ für } t=b\\
            \impl x-ty &= 0\\
            \impl x&= ty\qedhere
        \end{align*}
    \end{proof}
    Erkentnis: Aus Cauchy-Schwarzer folgt die Dreiecksungleichung für die Euklidische Norm.

    \begin{align*}
        \norm{x+y}_2^2 &= \sprod{x+y,x+y}\\
        &= \sprod{x,x+y}+ \sprod{y,x+y}\\
        &= \sprod{x,x} + 2 \sprod{x,y} + \sprod{y,y}\\
        &= \norm{x}_2^2 + 2\sprod{x,y} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\abs{\sprod{x,y}} + \norm{y}_2^2\\
        &\leq \norm{x}_2^2 + 2\norm{x}_2 \norm{y}_2 + \norm{y}^2\\
        &= \pair{\norm{x}_2 + \norm{y}_2}^2\\
        \impl \norm{x+y}_2 &\leq \norm{x}_2 + \norm{y}_2\tag{Dreiecksungleichung für Eukl. Norm}
    \end{align*}

    \noindent Frage: Was passiert, wenn $\norm{x+y}_2 = \norm{x}_2 + \norm{y}_2$?\\
    (Später)

    \newpage


    \section{Polynome}
    \input{Kapitel/Polynome}


    \section{Cauchyprodukt und Exponentialfunktionen}
    \input{Kapitel/Cauchyprodukt}


    \section{[*] Potenzreihen}
    \imaginarysubsection{Potenzreihen}
    \thispagestyle{pagenumberonly}

    Wir untersuchen Reihen der Form $ \sum_{n=0}^{\infty} a_n\cdot z^n$ oder $ \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n$, $z_0\in\C$ fest, $z\in\C$ oder $\R$, $a_n\in\C$.\\
    Partialsummen:
    \begin{align*}
        s_n(z) &\definedas \sum_{j=0}^{n} a_j\cdot z^j
    \end{align*}
    Frage: Konvergenz?
    \begin{beispiel}
        \begin{align*}
            \exp(z) &\definedas \sum_{n=0}^{\infty} \frac{1}{n!} z^n\\
            &= \sum_{n=0}^{\infty} n! \cdot z^n \text{ konvergiert nur für } z=0
        \end{align*}
    \end{beispiel}

    \begin{definition}[Konvergenzradius]
        \begin{align*}
            R &\definedas \sup \set{\abs{z}: z\in\C \text{ und } \sum_{n=0}^{\infty} a_n \cdot z^n \text{ konvergent } }
        \end{align*}
        $R$ ist der Konvergenzradius.
    \end{definition}

    \begin{satz}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut für jedes $z$ in der Kreisscheibe
        \begin{align*}
            B_R (a) &= \set{z\in\C: \abs{z} < R}
        \end{align*}
        Für jedes $\abs{z} > R$ divergiert $ \sum_{n=0}^{\infty} a_n \cdot z^n$.
        \begin{proof}
            Sei $z_1\neq 0$. $ \sum_{n=0}^{\infty} a_n \cdot z^n$ konvergiert.
            \begin{align*}
                \impl (a_n \cdot z^n) \text{ Nullfolge }\\
                \impl \text{ ist beschränkt }\\
                \impl K\definedas \sup_{n\in\N} \set{a_n z^n} < \infty
                \intertext{Sei $0 < r < \abs{z_1}$, $0 < \theta \definedas \frac{r}{\abs{z_1}} < 1$}
                z &\leq \conj{B_r (a)} = \set{\abs{z} \leq r}\\[10pt]
                \abs{a_n z^n} &= \abs{a_n}\abs{z^n} = \abs{a_n} \cdot \abs{z}^n &= \abs{a_n} \cdot \abs{z}^n \frac{\abs{z}}{\abs{z_1}} ^n\\
                &\leq k \theta^n\quad \forall n \geq 0\\
                \impl \sum_{n=0}^{\infty} k \theta^n \text{ konvergente Majorante für } \sum_{n=0}^{\infty} a_n z^n \text{ sofern } 0 \leq z \leq r < \abs{z}\\
                \impl \sum_{n}^{} a_n z^n \text{ konvergiert absolut }\\[12pt]
                \impl (1) \sum_{n=0}^{\infty} a_n z^n \text{ konvergiert für alle } \abs{z} \leq r\\
                \impl (2) \text{ Angenommen } \sum_{n}^{} a_n z^n \text{ konvergiert für ein } \abs{z} > R\\
                (2) \impl \text{ Widerspruch zu Definition von } R
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Konvergiere $ \sum_{n}^{} a_n z^n$ und $ \sum_{n}^{} b_n z^n$ für $\abs{z} < R$
        \begin{align*}
            \impl \sum_{n=0}^{\infty} \pair{\lambda a_n + \mu b_n} z^n &= \lambda \sum_{n=0}^{\infty} a_n z^n + \mu \sum_{n=0}^{\infty} b_n z^n
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Konvergieren $ \sum_{n=0}^{\infty} a_n z^n$, $ \sum_{n=0}^{\infty} b_n z^n$ auf $B_R (0)$
        \begin{align*}
            \impl \pair{\sum_{n=0}^{\infty} a_n z^n} \cdot \pair{\sum_{n=0}^{\infty} b_n z^n} = \sum_{n=0}^{\infty} \pair{\sum_{\nu=0}^{\infty} a_{\nu} b_{n-\nu}} z^n \tag{Cauchy-Produkt}
            \intertext{Sei $0 < r < R$ für $\abs{z} \leq r$}
        \end{align*}
    \end{bemerkung}

    \begin{bemerkung}
        Wir können auch Potenzreihen der Form
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n, \sum_{n=0}^{\infty} a_n \cdot \pair{z-z_0}^n \text{ mit } a_n\in\R^d \text{ oder } \C^d
        \end{align*}
        betrachten. Wir setzen
        \begin{align*}
            R &= \sup \set{\abs{z}: z\in\C und \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 2
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ konvergiert absolut $\forall z\in B_R (0)$ und divergiert für $\abs{z} > R$.

        \begin{proof}
            Abschreiben des Beweises von Satz 1.
        \end{proof}
    \end{satz}

    \begin{lemma}
        Konvergiert $ \sum_{n=0}^{\infty} a_n z^n$ für ein $z=z_1 \neq 0$ und ist $0 < r < \abs{z_r}$. So ist $ \sum_{n=0}^{\infty} a_n z^n$ auf $B_r (0) = \set{\abs{z} \leq r}$ beschränkt.\\
        Das heißt $\exists M = M_r \geq 0$ mit $\abs{\sum_{n=0}^{\infty} a_n z^n} \leq M_r~\forall \abs{z} \leq r$

        \begin{proof}
            \begin{align*}
                \theta &\definedas \frac{r}{\abs{z_1}} < 1
                \intertext{Da $ \sum_{n=0}^{\infty}  a_n z_1^n$ konvergiert ist}
                (a_n z_n^n)_n \text{ Nullfolge also beschränkt }
                \impl K &= \sup_{n\in\N_0} \abs{a_n z_1^n} = \sup_{n\in\N} \abs{a_n} \abs{z_1}^n < \infty\\
                \intertext{Ist $\abs{z} < r$}
                \abs{a_n z^n} &= \abs{a_n} \abs{z}^n = \abs{a_n} \abs{z_1}^n \abs{\frac{\abs{z}}{\abs{z_1}}}^n\\
                \impl \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq \sum_{n=0}^{\infty} \abs{a_n z}^n \leq \sum_{n=0}^{\infty} k \theta^n = \frac{k}{1-\theta} < \infty\quad \forall \abs{z} \leq r
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{lemma} % Lemma 4
        \label{lemma:temp-4}
        Annahmen wie bei vorherigem Lemma.
        \begin{align*}
            \impl \text{ Für alle } 0 &< r < \abs{z_1}\quad\forall k\in\N_0\\
            \text{ existiert } M &= M_k, r\geq 0
            \intertext{mit}
            \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}\quad\forall \abs{z} \leq r
        \end{align*}

        \begin{proof}
            \begin{align*}
                \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert auch }\\
                \impl \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} &= z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n \text{ konvergiert }\\
                \impl \text{ verschobene Reihe } \sum_{n=k+1}^{\infty} a_n z^{n-(k+1)} \text{ konvergiert }\\
                \annot{\impl}{Lemma 3} \text{ Für } 0 < r < z_1  \text{ existiert ein } M = M_{k,r} \geq 0
                \intertext{sodass}
                \abs{\sum_{n=k+1}^{\infty} a_n z^{n-(k+1)}} &\leq M_r\quad\forall \abs{z} \leq r < \abs{z_1}\\
                \text{ (linke Seite) } &= \abs{z^{-(k+1)} \sum_{n=k+1}^{\infty} a_n z^n}\\
                &= \frac{1}{\abs{z}^{k+1}} \abs{\sum_{n=k+1}^{\infty} a_n z^n}\\
                \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M_{k,r} \abs{z}^{k+1}
            \end{align*}
        \end{proof}
    \end{lemma}

    \begin{anwendung}
        \begin{align*}
            \sum_{n=0}^{\infty} a_n z^n &= \underbrace{\sum_{n=0}^{k} a_n z^n}_{s_k (z)} + \underbrace{\sum_{n=k+1}^{\infty} a_n z^n}_{Fehler}\\
            \abs{Fehler} &\leq M_{k,r} \abs{z}^{k+1} \leq M_{k,r} \theta^{k+1} \tag{$\theta = \frac{r}{\abs{z_1}}$}
        \end{align*}
    \end{anwendung}

    \newpage

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 18. Januar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    Bessere Version von Lemma~\ref{lemma:temp-4}:

    \begin{align*}
        \varphi(z) &= \sum_{n=0}^{\infty} a_n z^n\\
        \abs{\varphi(z) - \sum_{n=k}^{\infty} a_n z^n} &= \abs{\sum_{n=0}^{k} a_n z^n} \leq M_{r,z} \cdot \abs{z}^{k+1}\quad 0< r < \abs{z_1}
        \intertext{Sei $ \sum_{n=0}^{\infty} a_n z^n$ konvergent für ein $z=z_1\neq 0$}
        \impl \forall~ 0< r < \abs{z_1}\colon \text{ existiert }  M_{r,z_1} &> 0
        \intertext{sodass}
        \forall k\in\N_0\colon \abs{\sum_{n=0}^{\infty} a_n z^n} &\leq M_{r,z_1} \abs{\frac{z}{z_1}}^{k+1}\quad\forall \abs{z} \leq r\\
        \abs{\frac{z}{z_1}} &\leq \frac{\abs{z}}{\abs{z_1}} \leq \frac{r}{\abs{z_1}} = \theta < 1
    \end{align*}

    \begin{proof}
        \begin{align*}
            \sum_{n\geq 0}^{} a_n z_1^n \text{ konvergiert }\\
            \impl \pair{a_n z_1^n}_n \text{ ist Nullfolge }\\
            k &\definedas \sup_{n\geq 0} \abs{a_n z_1^n} &< \infty\\
            \impl \abs{a_n z^n} &= \abs{a_n z_1^n \pair{\frac{z}{z_1}}^n} = \abs{a_n z_1^n} \abs{\frac{z}{z_1}}^n\\
            \abs{\frac{z}{z_1}} &\leq \frac{r}{\abs{z_1}} = \theta < 1\\
            \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} &= \sum_{n=k+1}^{\infty} \abs{a_n z^n}\\
            &\leq \sum_{n=k+1}^{\infty} K \cdot \abs{\frac{z}{z_1}}^n\\
            &= K\cdot \abs{\frac{z}{z_1}}^{k+1} \cdot \sum_{n=0}^{k} \abs{\frac{z}{z_1}}^n\\
            &= \frac{K}{1-\theta} \abs{\frac{z}{z_1}}^{k+1} = \underbrace{ \frac{K}{1-\abs{\frac{r}{z_1}}} }_{M_{r,z_1}}\cdot \pair{\frac{\abs{z}}{\abs{z_1}}}^{k+1}
        \end{align*}
    \end{proof}

    \begin{satz} % Satz 5
        \marginnote{[18. Jan]}

        Sei $ \sum_{n=0}^{\infty}$ eine Potenzreihe, die für ein $z=z_1\neq 0$ konvergiert.\\
        $(z_j)_j$: Folge $0< \abs{z_j} < \abs{z_1}$, $z_j \fromto 0$, $j\fromto\infty$ mit
        \begin{align*}
            \sum_{n=0}^{\infty} a_n (z_j)^n &= 0\quad\forall j\in\N\\
            \impl a_n &= 0\quad\forall n\in\N_0
        \end{align*}
        \begin{proof}
            Angenommen nicht alle $a_n=0$
            \begin{align*}
                \impl B &\definedas \set{n\in\N_0: a_n \neq 0} \neq \emptyset\\
                \impl B \text{ hat ein kleinstes Element, nennen wir } n_0\\
                \impl a_0 &= a_1 = \dots = a_{n_0-1} = 0\quad a_{n_0}\neq 0\\
                f(z) &= \sum_{n=0}^{\infty} a_n z^n = \sum_{n=n_0}^{\infty} a_n z^n = a_{n_0} z^{n_0} + \sum_{n=n_0 + 1}^{\infty} a_n z^n\\
                f(z_1) &= 0\quad\forall j\quad z_j \neq 0\quad z_j\fromto 0\\
                \impl \abs{a_{n_0} (z_j)^{n_0}} &= \abs{- \sum_{n=n_0 + 1}^{\infty} a_n z_j^n} \leq M_{r, z_1} \pair{\frac{\abs{z_j}}{\abs{z_1}}}^{n_0 +1}\\
                \impl \abs{a_{n_0}} \leq M_{r,z} \abs{z_1}^{-(n_0+1)} \abs{z_j} \fromto 0\quad j\fromto\infty\\
                \impl a_{n_0} &= 0\tag{Widerspruch}
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz} % Satz 6
        Sei $ \sum_{n=0}^{\infty} a_n z^{n}$, $ \sum_{n=0}^{\infty} b_n z^n$ welche für ein $z=w\neq 0$ konvergieren.\\
        $(z_j)_j$ Folge in $\C$, $z_1\neq 0$, $\forall i, z_i \fromto 0$\\
        mit $ \sum_{n=0}^{\infty} a_n z^n = \sum_{n=0}^{\infty} b_n z_j^n$ für fast alle $z_j$.\\
        Dann ist $a_n = b_n~\forall n\in\N_0$.
        \begin{proof}
            \begin{align*}
                c_n &= a_n - b_n
                \intertext{\OBDA sind alle $\abs{z_1} < \abs{w}$}
                \impl h(z) &\definedas \sum_{n=0}^{\infty} c_n z^n \text{ konvergiert für } z=w\neq 0\\
                \text{ und } h(z_j) &= 0\quad \forall j\\
                \annot{\impl}{Satz 5} c_n &= 0\quad \forall n\in\N_0 \equivalent a_n = b_n \quad\forall n\in\N_0
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{bemerkung}
        Hatten geg. $ \sum_{n=0}^{\infty} a_n z^n$. Dann ist der Konvergenzradius
        \begin{align*}
            R &= \sup \set{\abs{z} : z\in\C \text{ und } \sum_{n=0}^{\infty} a_n z^n \text{ konvergent } }
        \end{align*}
    \end{bemerkung}

    \begin{satz} % Satz 7
        \begin{align*}
            R &= \frac{1}{\limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}}
        \end{align*}

        \begin{proof}
            Schritt 1: Zu zeigen: Für $\abs{z} < R$ konvergiert die Potenzreihe.
            \begin{align*}
                M &= \limsup_{n\fromto\infty}\sqrt[n]{\abs{a_n}}\\
                \impl \forall \varepsilon > 0~\exists N \colon \sqrt[n]{\abs{a_n}} &\leq M+\varepsilon\\
                \impl \forall \varepsilon > 0 \text{ ist } \sqrt[n]{\abs{a_n}} &> M- \varepsilon \text{ für fast alle } n
            \end{align*}
            Schritt 2: Zu zeigen: Für $\abs{z} > R$ konvergiert die Potenzreihe nicht. (Übung)
        \end{proof}
    \end{satz}

    \begin{korollar}
        Die Potenzreihe $ \sum_{n=0}^{\infty} a_n z^n$ und $ \sum_{n=1}^{\infty} n a_n z^{n-1}$ haben den gleichen Konvergenzradius.
        \begin{proof}
            Folgt mit vorherigem Satz und $\sqrt[n]{n}\fromto 1$ für $n\fromto\infty$.
        \end{proof}
    \end{korollar}

    \newpage


    \section{Stetige Funktionen einer reellen (oder komplexen) Variablen}
    \input{Kapitel/Stetigkeit}


    \section{Der Zwischenwertsatz}
    \input{Kapitel/Zwischenwertsatz}


    \section{Der Satz von Weierstraß}
    \input{Kapitel/Satz_Weierstrass}


    \section{Grenzwerte von Funktionen}
    \input{Kapitel/Grenzwerte_Funktionen}


    \section{[*] Gleichmäßige Stetigkeit und gleichmäßge Konvergenz}

    \subsection{Gleichmäßige und Lipschitz-Stetigkeit}
    \thispagestyle{pagenumberonly}

    \begin{definition}[Gleichmäßige Stetigkeit] % Def 1
        Sei $f: D\fromto \R$ (oder $\R^d$) und $D\sbset\K$. $f$ heißt gleichmäßig stetig auf $D$, falls
        \begin{align*}
            \fa\varepsilon > 0\ex\delta\colon \abs{f(x)-f(y)} < \varepsilon\quad\fa x,y\in D \text{ mit } \abs{x-y} < \delta
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        Gleichmäßige Stetigkeit ist nach der Definition eine strengere Eigenschaft als Stetigkeit auf $D$. Das heißt jede gleichmäßig stetige Funktion ist auch stetig, aber nicht umgekehrt.
    \end{bemerkung}

    \begin{beispiel}
        \begin{align*}
            f: \R\fromto\R,~x\mapsto\frac{1}{1+x^2}
        \end{align*}
        ist gleichmäßig stetig. (Übung)
    \end{beispiel}
    \begin{beispiel}
        \begin{align*}
            f: \rinterv{0,1}\fromto \R,~x\mapsto \frac{1}{x}
        \end{align*}
        ist stetig, aber nicht gleichmäßig stetig.
        \begin{proof}
            Für $0 < x < y = 2x$ gilt
            \begin{align*}
                \abs{f(x)-f(y)} &= \abs{\frac{1}{x} - \frac{1}{y}} = \frac{\abs{y-x}}{xy} = \frac{1}{y}\geq 1\qedhere
            \end{align*}
        \end{proof}
    \end{beispiel}

    \begin{definition}[Lipschitz-Stetigkeit]
        Eine Funktion $f: D\fromto\R$ (oder $\R^d$) heißt Lipschitz-stetig, falls
        \begin{align*}
            \ex L\geq 0\colon \abs{f(x)-f(y)} \leq L\cdot\abs{x-y}\quad\forall x,y\in D
        \end{align*}
        Jede Lipschitz-stetige Funktion ist gleichmäßig stetig. $(\delta = \frac{\varepsilon}{L})$
    \end{definition}

    \begin{satz}[Heine, 1872] % Satz 3
        \label{satz:17-3}
        Sei $K\sbset\R$ kompakt und $f: K\fromto\R$ (oder $\R^d$) stetig. Dann ist $f$ gleichmäßig stetig.
        \begin{proof}
            Angenommen $f$ ist nicht gleichmäßig stetig.
            \begin{align*}
                \impl\ex\varepsilon > 0\fa \delta > 0\ex x,y\in &K\colon\abs{x-y} < \delta \text{ und } \abs{f(x)-f(y)} > \varepsilon
                \intertext{Wähle $\delta = \frac{1}{n}$}
                \impl\ex x_n, y_n\sbset K\colon \abs{x_n- y_n} &< \frac{1}{n} \text{ aber } \abs{f(x_n)-f(y_n)} \geq \varepsilon > 0\\
                \impl x_n - y_n &\fromto 0 \text{ für } n\fromto\infty
                \intertext{Da $K$ kompakt $\ex$Konvergente TF $(y_{n_l})_l$ von $(y_n)_n$ nach Satz~\ref{satz:bolzano-weierstrass}}
                y &\definedas \lim_{l\toinf} (y_{n_l}) \text{ existiert in } K
                \intertext{Für eine Teilfolge $(x_{n_l})_l$ von $(x_n)_n$ gilt}
                \abs{x_{n_l} - y} &= \abs{x_{n_l} - y_{n_l} + y_{n_l} - y}\\
                &\leq \underbrace{\abs{x_{n_l} - y_{n_l}}}_{<\frac{1}{n}\fromto 0} + \underbrace{\abs{y_{n_l} - y}}_{\fromto 0}\fromto 0\\
                \impl \abs{f(x_{n_l}) - f(y_{n_l})} &\geq \varepsilon > 0
                \intertext{Aber}
                \abs{f(x_{n_l}) - f(y_{n_l})} &= \abs{f(x_{n_l}) - f(y) + f(y) - f(y_{n_l})}\\
                &\leq \underbrace{\abs{f(x_{n_l}) - f(y)}}_{\fromto 0} + \underbrace{\abs{f(y)-f(y_{n_l})}}_{\fromto 0}
            \end{align*}
            Damit ergibt sich ein Widerspruch zur Stetigkeit von $f$ und $f$ ist damit gleichmäßig stetig.
        \end{proof}
    \end{satz}

    \subsection{[*] Punktweise und gleichmäßige Konvergenz von Funktionenfolgen}

    Wir betrachten Folgen von Funktionen. $f_n: D\fromto \R$ (oder $\R^d$) $\leadsto$ Folge $(f_n)_n$ von Funktionen.

    \begin{definition}[Punktweise Konvergenz] % Def 4
        Eine Funktionenfolge $(f_n)_n$, $f_n: D\fromto\R$ (oder $\R^d$) konvergiert punktweise falls
        \begin{align*}
            \lim_{\ntoinf} f_n(x) \text{ existiert für jedes } x\in D
        \end{align*}
        Das heißt $(f_n(x))_n$ ist eine konvergente Folge $\fa x\in\R$. Dann definieren wir
        \begin{align*}
            f(x) \definedas \lim_{\ntoinf} f_n(x)
        \end{align*}
        eine Funktion $f: D\fromto \R$ (oder $\R^d$). Und sagen $f$ ist der punktweise Limes der Funktionenfolge $f_n(x) \fromto f(x)~\fa x\in D$.
    \end{definition}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= x^n\quad 0 \leq x \leq 1
            \intertext{konvergiert punktweise gegen}
            f(x) &= \begin{cases}
                        0\quad &0 \leq x < 1\\
                        1\quad &x = 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= x^{\frac{1}{n}}\quad 0 \leq x \leq 1
            \intertext{ist stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        0\quad&x = 0\\
                        1\quad&0 < x \leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{beispiel}
        Die Funktion
        \begin{align*}
            f_n(x) &= \pair{1-x^2}^{\frac{n}{2}}\quad -1 \leq x \leq 1
            \intertext{ist stetig und punktweise konvergent gegen}
            f(x) &= \begin{cases}
                        1\quad&x = 0\\
                        0\quad&0 < \abs{x}\leq 1
            \end{cases}
        \end{align*}
    \end{beispiel}

    \begin{definition}[Gleichmäßige Konvergenz - Weierstraß 1841] % Definition 5
        $D\sbset\R$, Funktionenfolge $f_n: D\fromto\R$ (oder $\R^d$). $(f_n)_n$ konvergiert gleichmäßig gegen $f: D\fromto\R$ (oder $\R^d$) falls
        \begin{align*}
            \fa\varepsilon > 0\ex N\in \N \text{ mit } \abs{f_n(x) - f(x)} < \varepsilon\quad\fa n\geq N, x\in D
        \end{align*}
    \end{definition}

    \begin{bemerkung}
        Also gilt bei gleichmäßiger Konvergenz
        \begin{align*}
            \sup_{x\in D} \abs{f_n(x) - f(x)} &\leq \varepsilon\\
            \impl \lim_{\ntoinf} \sup_{x\in D}\abs{f_n(x) - f(x))} &= 0\\
            \equivalent \limsup_{\ntoinf} \pair{\abs{f_n(x) - f(x)}} &= 0
        \end{align*}
    \end{bemerkung}

    %%%%%%%%%%%%%%%%%%%%%%%%
    % 01. Februar 2024
    %%%%%%%%%%%%%%%%%%%%%%%%

    \begin{notation}[Supremumsnorm]
        \marginnote{[01. Feb]}
        Es sei $f: D\fromto \R$ (oder $\R^d$, $\C$). Dann schreiben wir
        \begin{align*}
            \norm{f}_{\infty} &\definedas \norm{f}_{D,\infty} = \norm{f}_{?}\\
            &= \sup_{x\in D} \abs{f(x)}
        \end{align*}
        Norm auf dem Vektorraum der beschränkten Funktionen auf $D$.
    \end{notation}

    \begin{satz}[Cauchy-Kriterium für gleichmäßige Konvergenz]
        Es sei $(f_n)_n$, $f_n: D\fromto \R$ (oder $\R^d$). Dann konvergiert $(f_n)_n$ genau dann gleichmäßig gegen $f$, wenn
        \begin{align*}
            \fa\varepsilon > 0\ex N\in\N\colon \abs{f_n(x) - f_m(x)} < \varepsilon\quad\forall x\in D, n,m\geq N
        \end{align*}
        \begin{proof}
            \anf{$\impl$}: $f(x) = \biglim{\ntoinf} f_n(x)$ existiert $\fa x\in D$.
            \begin{align*}
                \impl \abs{f_n(x) - f_m(x)} \leq \underbrace{\abs{f_n(x) - f(x)}}_{<\frac{\varepsilon}{2}} + \underbrace{\abs{f(x) - f_n(x)}}_{<\frac{\varepsilon}{2}} < \varepsilon\quad\fa n,m\geq N
            \end{align*}
            unabhängig von $x\in D$.\\
            \anf{$\Leftarrow$}: Für $x\in D$ ist $(f_n(x))_n$ eine Cauchy-Folge. Und $f(x) = \biglim{\ntoinf} f_n(x)$ existiert $\fa x\in D$.
            \begin{align*}
                \abs{f_n(x) - f(x)} &= \lim_{\ntoinf} \abs{f_n(x) - f_m(x)} < \varepsilon\quad n\geq N
                \intertext{Sei $\varepsilon > 0$}
                \impl \ex N\in\N\colon \abs{f_n(x) - f_m(x)} &< \varepsilon\quad\fa n,m\geq N\\
                \impl \abs{f_n(x) - f(x)} &= \lim_{\ntoinf} \abs{f_n(x) - f_m(x)} < \varepsilon\quad\fa n\geq N\\
                \impl \sup_{x\in D} \abs{f_n(x) - f(x)} &\leq \varepsilon\quad\fa n\geq N\\
                \impl (f_n)_n &\text{ geht gleichmäíg gegen } f\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Weierstraß 1861] % Satz 7
        \label{satz:17-7}
        Seien $f_n: D \fromto \R$ (oder $\R^d$, $\C$) stetige Funktionen, welche gleichmäßig gegen eine Funktion $f$ konvergieren. Dann ist $f$ stetig!
        \begin{proof}
            Geg. $x_0\in D, x\in D$.
            \begin{align*}
                \abs{f(x) - f(x_0)} &= \abs{f(x) - f_n(x) + f_n(x) - f(x_0)}\\
                &\leq \abs{f(x) - f_n(x)} + \abs{f_n(x) - f_n(x_0)} + \abs{f_n(x) - f(x_0)}
                \intertext{$\frac{\varepsilon}{3}$-Trick}
                \fa\varepsilon > 0\ex N\in \N\colon \abs{f_n(y) - f(y)} < \frac{\varepsilon}{3}\quad\forall y\in D, n\geq N
                \intertext{Wir fixieren $n=N$. Dann ist $f_n$ stetig}
                \impl \text{ Geg. }\varepsilon > 0\ex \delta > 0\colon \abs{f_n(x) - f_n(x)} &< \frac{\varepsilon}{3}\quad \text{ für } \abs{x-x_0} < \delta\\
                \intertext{Für $x\in D$, $\abs{x-x_0} < \delta$ gilt}
                \abs{f(x) - f(x_0)} \leq \abs{f(x) - f_n(x)} + \abs{f_n(x) - f_n(x)} + \abs{f_n(x) - f(x_0)} &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \varepsilon\\
                \impl f & \text{ ist stetig } \qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{satz}[Weierstraß' M-Test] % Satz 8
        \label{satz:17-8}
        Eine Reihe $ \sum_{n=0}^{\infty} f_n$ von Funktionen $f_n: D\fromto \R$ (oder $\R^d$) konvergiert gleichmäßig, wenn sie eine konvergente Majorante hat, das heißt $\ex M_n\geq 0, N_0\in \N$ mit
        \begin{align*}
            \abs{f_n(x)} &\leq M_n\quad\forall x\in D, n\geq N_0
            \intertext{und}
            \sum_{n=0}^{\infty} N_n &< \infty
        \end{align*}
        \begin{proof}
            Partialsummen
            \begin{align*}
                s_n(x) &\definedas \sum_{j=0}^{n}  f_j(x)
                \intertext{Wir betrachten $n,m\geq N_0$}
                \abs{s_n(x) - s_m(x)} &= \abs{\sum_{j=m+1}^{n} f_j(x)} \leq \sum_{j=m+1}^{n} \underbrace{\abs{f_j(x)}}_{\leq M_j}\\
                &\leq \sum_{j=m+1}^{n} M_j\\
                \impl \abs{s_n(x) - s_m(x)} &\leq \underbrace{\sum_{j=m+1}^{n} M_j}_{\fromto 0}
                \intertext{Haben}
                \impl \sup_{n\geq m} \sup_{x\in D} \abs{s_n(x) - s_m(x)} &\fromto 0 \text{ für } m\fromto\infty\\
                \equivalent s_{n} \text{ konvergiert gleichmäßig auf } &D
                \intertext{$s_n(x)$ stetig, da endliche Summen von stetigen Funktionen stetig sind}
                \impl s(x) &= \lim_{\ntoinf} s_n(x) \text{ ist stetig nach Satz~\ref{satz:17-7}}\qedhere
            \end{align*}
        \end{proof}
    \end{satz}

    \begin{anwendung}[Potenzreihen]
        Satz~\ref{satz:17-7} und Satz~\ref{satz:17-8} gelten auch für Funktionen $f_n: D\fromto \C$, $D\sbset \C$. Potenzreihe
        \begin{align*}
            f(x) &= \sum_{n=0}^{\infty} a_n x^n\\
            s_n(x) &= \sum_{j=0}^{n} \underbrace{a_{j} x^j}_{\text{Polynom, daher stetig}}
            \intertext{Wir wollen Weierstraß' M-Test anwenden. Sei $R > 0$ Konvergenzradius der Potenzreihe}
            \impl \forall \abs{z} < R \text{ existiert } f(z) &= \sum_{n=0}^{\infty} a_n z^n
            \intertext{Geg. $\delta > 0, R-\delta > 0$ sei $z_1\in \C$}
            \abs{z_1} &= R - \frac{\delta}{2} < R
            \intertext{Aus der Verbesserung von Lemma~\ref{lemma:temp-4} folgt}
            \ex M \geq 0\colon \abs{\sum_{n=k+1}^{\infty} a_n z^n} &\leq M\cdot \abs{\frac{z}{z_1}}^{k+1}\quad\fa \abs{z}< \abs{z_1} = R - \frac{\delta}{2}\\
            \abs{z} &\leq R- \delta\\
            \impl \frac{\abs{z}}{\abs{z_1}} \leq \frac{R-\delta}{R-\frac{\delta}{2}} = q < 1\\
            \impl \abs{\sum_{n=k+1}^{\infty} a_n z^n} \leq M \cdot q^{k+1}\\
            \impl \abs{s(z) - s_k(z)} &= \abs{\sum_{n=k+1}^{\infty} a_n z^n}\\
            &\leq M \cdot q^{k+1} \fromto 0 \text{ für } k\fromto \infty\\
            \sup_{\abs{z} < R - \delta} \abs{s(z) - s_k(z)} &\leq M \cdot q^{k+1} \fromto 0 \text{ für } k\fromto\infty
            \intertext{Partialsummen}
            s_k(z) &= \sum_{n=0}^{k} a_n z^n \text{ konvergiert gleichmäßig gegen } s(z) \text{ für alle } \abs{z} \leq R-\delta
        \end{align*}
        liefert Stetigkeit.
    \end{anwendung}

    \begin{satz}[Weierstraß] % Satz 9
        \label{satz:17-9}
        Sei $a <b$, $f: \interv{a,b}\fromto \R$ stetig. Dann gilt es existiert eine Folge von Polynomen $(P_n)_n$, welche gleichmäßig auf $\interv{a,b}$ gegen $f$ konvergiert. Das heißt $\norm{f-P_n}_{\infty}  = \biglim{\ntoinf} \sup_{a \leq x \leq b} \abs{f(x) - P_n(x)} = 0$

        \begin{proof}
            O.B.d.A. $a=0$, $b=1$ -- sonst ist $g: \interv{0,1} \fromto \interv{a,b}, x\mapsto (b-a)x + a$ stetig und bijektiv und wir haben $h: \interv{0,1} \fromto \R, x\mapsto h(x) = f(g(x))$.\\
            Def. Bernstein Polynome
            \begin{align*}
                P_n(x) &\definedas \sum_{k=0}^{n} \binom{n}{k} x^k \cdot\pair{1-x}^{n-k} \cdot f\of{\frac{k}{n}}\tag{$n\in\N$}
                \intertext{Haben}
                a)&\quad\sum_{k=0}^{n} \binom{n}{k}x^k \cdot \pair{1-x}^{n-k} = \pair{x+(1-x)}^n = 1\tag{Bernoulli}\\
                b)&\quad \sum_{k=0}^{n} k\binom{n}{k}x^k\cdot (1-x)^{n-k} = n\cdot x\\
                c)&\quad \sum_{k=0}^{n} k\cdot(k-1)\binom{n}{k}x^k \cdot\pair{1-x}^{n-k} = n\cdot(n-1) \cdot x^2\\
                b)&\quad k\binom{n}{k} = k\cdot\frac{n!}{k!\cdot(n-k)!} = n\cdot\frac{(n-1)!}{(k-1)!(n+1-(k-1))!} = n\binom{n-1}{k-1}\\
                \impl \sum_{k=0}^{n} k\binom{n}{k}x^k \cdot (1-x)^{n-k} &= \sum_{k=1}^{n} n \binom{n-1}{k-1} x^k \cdot (1-x)^{n-k}\\
                &= n\cdot x\cdot \sum_{k=1}^{n} \binom{n-1}{k-1} x^{k-1} (1-x)^{n-1-(k-1)}\\
                &= \sum_{j=0}^{n-1} \binom{n-1}{j} x^j \cdot (1-x)^{n-1-j} = nx = 1\\
                c)&\quad \text{ Bernoulli: } k\cdot(k+1) \binom{n}{k} = n\cdot (n-1) \binom{n-2}{k-2}\tag{$k\geq 2$}\\
                \sum_{k=0}^{n} k(k+1) \binom{n}{k} x^k (1-x)^{n-k} &= n(n-1) x^{k-2} \underbrace{\sum_{k=2}^{n} \binom{n-2}{k-2} x^{k-2} (1-x)^{n-2-(k-2)}}_{=(1+(1-x))^{k-2} = 1}
            \end{align*}

            \begin{align*}
                \abs{f(x) - P_n(x)} &= \abs{\sum_{k=0}^{n} \binom{n}{k} x^k\pair{1-x}^{n-k}f(x) - \sum_{k=0}^{n}\binom{n}{k}x^k (1-x)^{n-k} f(\frac{n}{k}) }\\
                &\leq \sum_{k=0}^{n} \binom{k}{k} x^k (1-k)^{n-k} \cdot \abs{f(x)- f\of{\frac{n}{k}}}
                \intertext{Nach dem Satz von Heine ist $f$ stetig auf $\interv{0,1}$ das heißt}
                \fa\varepsilon > 0\ex\delta > 0\colon\abs{f(x)-f(y)} < \varepsilon \text{ für } x,y\in\interv{0,1}, \abs{x-y} < \delta
                \intertext{Teilen Summen in 2 Gebiete auf}
                A_1 &\definedas \set{0 \leq k \leq n: \abs{x-\frac{k}{n}} < \delta}\\
                A_2 &\definedas \set{0 \leq k \leq n: \abs{x-\frac{k}{n}} \geq \delta}\\
                \impl \abs{f(x) - P_n(x)} \leq \underbrace{\sum_{k<A_1}^{} \binom{n}{k} x^k (1-k)^{n-k} \abs{f(x) - f(\frac{k}{n})}}_{\definedasbackwards \delta_1}\\
                + \underbrace{\sum_{k<A_2}^{} \binom{n}{k} x^k (1-k)^{n-k} \abs{f(x) - f(\frac{k}{n})}}_{\definedasbackwards \delta_2}\\
                s_1 < \varepsilon \sum_{k < A1}^{} \binom{n}{k} x^k (1-x)^{n-k} < \varepsilon\\
                \intertext{$S2$}
                \abs{x-\frac{k}{n}} < \delta\quad\equivalent\quad \frac{\abs{x-\frac{k}{n}}}{\delta^2} \geq 1
                \intertext{mit}
                \abs{f(x)-f(\frac{k}{n})} \leq \abs{f(x)} + \abs{f(\frac{k}{n})} \leq 2\cdot\sup_{0\leq x \leq 1} (f(x)) < \infty\\
                \impl s_2 &\leq 2 \cdot\norm{f}_{\infty} \cdot \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \frac{\abs{x-\frac{k}{n}}}{\delta^2}\\
                &\leq 2 \norm{f}_{\infty} \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \frac{\abs{x-\frac{k}{n}}}{\delta^2}\\
                &= \frac{2\norm{f}}{\delta^2 \cdot n^2} \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} \abs{nx -k}^2\\
                \impl \sum_{k=0}^{n} \binom{n}{k} x^k (1-x)^{n-k} (k^2)\\
                \vdots\quad ???\\
                \vdots\quad ???\\
                \impl \abs{f(x)-P_n(x)} \leq \varepsilon + \frac{\norm{f}_{\infty}}{2\delta^2 n}\\
                \impl \sup_{0\leq x \leq 1} \abs{f(x) - P_n(x)} \leq \varepsilon + \frac{\norm{f}_{\infty}}{2\delta^2 n}\\
                \impl \limsup_{\ntoinf} \norm{f-P_n}_{\infty} \leq \varepsilon\quad\fa \varepsilon > 0\\
                ????
            \end{align*}
        \end{proof}
    \end{satz}

    \newpage


    \section{Ableitung (engl. Differention)}
    \input{Kapitel/Ableitung}


    \section{Konvexität}
    \input{Kapitel/Konvexitaet}

    \vfill

    \begin{center}
        \textbf{\LARGE Pause bis zum Sommersemester 2024}
    \end{center}

    \vfill

\end{document}
